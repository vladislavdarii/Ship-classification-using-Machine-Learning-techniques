{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNcpvU0bu4I1pZFU5v3Q6OS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladislavdarii/Ship-classification-using-Machine-Learning-techniques/blob/main/06_Convolutional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.0 Imports for Model Training\n",
        "#Train and test data variables have been saved executing 0.5 to 3.2\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import scipy.signal\n",
        "\n",
        "#Machine learning\n",
        "from keras import models,  layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LeakyReLU\n",
        "from keras.layers import Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "import librosa\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "#Writing and loading variables\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from tensorflow.keras.layers import BatchNormalization, Lambda\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import backend as K\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "#Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHTaeDVKsxd5",
        "outputId": "4d707ca5-f371-4957-f7ec-1f9efb639a43",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.1 Function: Class Accuracy Plot and Metrics\n",
        "\n",
        "def plot_class_acc(y_val, y_pred, strr):\n",
        "\n",
        "  # Initialize the lists for correctly and incorrectly predicted values\n",
        "  correct_preds = [0, 0, 0, 0]\n",
        "  incorrect_preds = [0, 0, 0, 0]\n",
        "\n",
        "  # Loop over the samples in y_test and y_pred\n",
        "  for i in range(len(y_val)):\n",
        "      if y_val[i] == y_pred[i]:\n",
        "          correct_preds[y_val[i]] += 1\n",
        "      else:\n",
        "          incorrect_preds[y_val[i]] += 1\n",
        "\n",
        "  # Set the colors for the bars\n",
        "  bar_colors = ['#009965', '#a52a2b']\n",
        "\n",
        "  # Create the bar chart with two parts for each bar\n",
        "  fig, ax = plt.subplots(figsize=(8, 5))\n",
        "  ax.bar(range(len(correct_preds)), correct_preds, color=bar_colors[0], label='Correct Predictions')\n",
        "  ax.bar(range(len(incorrect_preds)), incorrect_preds, bottom=correct_preds, color=bar_colors[1], label='Incorrect Predictions')\n",
        "\n",
        "  for i, (corr, incorr) in enumerate(zip(correct_preds, incorrect_preds)):\n",
        "      ax.text(i, corr/2, str(corr), ha='center', va='center', color='white', fontsize=10, fontweight='bold')\n",
        "      ax.text(i, corr + incorr/2, str(incorr), ha='center', va='center', color='white', fontsize=10, fontweight='bold')\n",
        "\n",
        "  # Set the x-ticks and labels\n",
        "  ax.set_xticks(range(len(correct_preds)))\n",
        "  ax.set_xticklabels(['Class A', 'Class B', 'Class C', 'Class D'])\n",
        "\n",
        "  # Set the labels and title\n",
        "  ax.set_xlabel('Boat Type')\n",
        "  ax.set_ylabel('Count')\n",
        "  ax.set_title(strr)\n",
        "\n",
        "  # Add the legend\n",
        "  ax.legend()\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()\n",
        "\n",
        "  # #Metric calculation\n",
        "  # Create confusion matrix\n",
        "  cm = confusion_matrix(y_val, y_pred)\n",
        "\n",
        "  # Convert the confusion matrix to a pandas DataFrame\n",
        "  confusion_matrix_df = pd.DataFrame(cm, columns=['Class A', 'Class B', 'Class C', 'Class D'])\n",
        "\n",
        "  # Calculate metrics\n",
        "  metrics_df = calculate_metrics(confusion_matrix_df.values)\n",
        "\n",
        "  # Print the results\n",
        "  print(\"Confusion Matrix:\")\n",
        "  print(confusion_matrix_df)\n",
        "  print(\"\\nMetrics:\")\n",
        "  print(metrics_df)\n",
        "\n",
        "  return metrics_df, confusion_matrix_df\n",
        "\n",
        "def calculate_metrics(confusion_matrix):\n",
        "    tp = np.diagonal(confusion_matrix)\n",
        "    fp = confusion_matrix.sum(axis=0) - tp\n",
        "    fn = confusion_matrix.sum(axis=1) - tp\n",
        "    tn = confusion_matrix.sum() - (tp + fp + fn)\n",
        "\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "    accuracy = np.trace(confusion_matrix) / confusion_matrix.sum()\n",
        "\n",
        "    metrics_dict = {\n",
        "        'Class': ['Class 0', 'Class 1', 'Class 2', 'Class 3'],\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1_score,\n",
        "        'Accuracy': accuracy\n",
        "    }\n",
        "    #Get rid of NaN values\n",
        "    metrics_dict = pd.DataFrame(metrics_dict)\n",
        "    metrics_dict.fillna(0, inplace=True)\n",
        "    return metrics_dict\n",
        "\n",
        "#@title 5.1 Get final metrics\n",
        "\n",
        "def metrics_avg_var(metrics):\n",
        " row = [0,1,2,3]\n",
        " Precision = []\n",
        " Recall = []\n",
        " F1_Score = []\n",
        " Accuracy = []\n",
        " Precision_var = []\n",
        " Recall_var = []\n",
        " F1_Score_var = []\n",
        " Accuracy_var = []\n",
        "\n",
        " for a in row:\n",
        "  Precision.append(np.average([df.loc[a, 'Precision'] for df in metrics]))\n",
        "  Recall.append(np.average([df.loc[a, 'Recall'] for df in metrics]))\n",
        "  F1_Score.append(np.average([df.loc[a, 'F1 Score'] for df in metrics]))\n",
        "  Accuracy.append(np.average([df.loc[a, 'Accuracy'] for df in metrics]))\n",
        "  Precision_var.append(np.std([df.loc[a, 'Precision'] for df in metrics]))\n",
        "  Recall_var.append(np.std([df.loc[a, 'Recall'] for df in metrics]))\n",
        "  F1_Score_var.append(np.std([df.loc[a, 'F1 Score'] for df in metrics]))\n",
        "  Accuracy_var.append(np.std([df.loc[a, 'Accuracy'] for df in metrics]))\n",
        "\n",
        " metrics_dict = {\n",
        "        'Class': ['Class 0', 'Class 1', 'Class 2', 'Class 3'],\n",
        "        'Precision': Precision,\n",
        "        'P_std' : Precision_var,\n",
        "        'Recall': Recall,\n",
        "        'R_std' : Recall_var,\n",
        "        'F1 Score': F1_Score,\n",
        "        'F1_std': F1_Score_var,\n",
        "        'Accuracy': Accuracy,\n",
        "        'Acc_std': Accuracy_var\n",
        "    }\n",
        "\n",
        "\n",
        " return pd.DataFrame(metrics_dict)\n",
        "\n",
        "#@title 2.1 Data Load\n",
        "\n",
        "def dataload(datax):\n",
        "  # Define the directory where the file is saved\n",
        "  directory = \"./drive/MyDrive/TFG/Data/\"\n",
        "\n",
        "  # Load the variables from the file\n",
        "  with open(os.path.join(directory, datax), \"rb\") as f:\n",
        "      X_train, X_test, X_val, y_train, y_test, y_val = pickle.load(f)\n",
        "\n",
        "  y_train = np.array(y_train)\n",
        "  y_val = np.array(y_val)\n",
        "  y_test = np.array(y_test)\n",
        "  return X_train, X_test, X_val, y_train, y_test, y_val\n",
        "\n",
        "def save_model(model,modeltype,n):\n",
        "\n",
        "  model_filename = \"decision_tree_\" + str(modeltype) +  \"_\" + str(n) + \".pkl\"\n",
        "\n",
        "  # Define the directory where you want to save the file\n",
        "  directory = \"./drive/MyDrive/TFG/Models/\"  #change to /DTs to actually overwrite stored models\n",
        "  if 1 == 0:\n",
        "    # Save the variables to a file\n",
        "    with open(os.path.join(directory, model_filename), \"wb\") as f:\n",
        "        pickle.dump((model), f)\n",
        "    return\n",
        "\n",
        "#@title 3.1 Feature extraction: PSD\n",
        "\n",
        "def get_psd():\n",
        "\n",
        "  psd_train = []\n",
        "  psd_test = []\n",
        "  psd_val = []\n",
        "\n",
        "  # Calculate the zero-crossing rate for X_train\n",
        "  for audio in X_train:\n",
        "    (f, S)= scipy.signal.welch(audio, 5000, nperseg=2*1024) # best so far 2*1024\n",
        "    psd_train.append(S/max(S))\n",
        "\n",
        "  psd_train = np.array(psd_train)\n",
        "\n",
        "  # Calculate the zero-crossing rate for X_val\n",
        "  for audio in X_val:\n",
        "    (f, S)= scipy.signal.welch(audio, 5000, nperseg=2*1024)\n",
        "    psd_val.append(S/max(S))\n",
        "\n",
        "  psd_val = np.array(psd_val)\n",
        "\n",
        "  # Calculate the zero-crossing rate for X_test\n",
        "  for audio in X_test:\n",
        "    (f, S)= scipy.signal.welch(audio, 5000, nperseg=2*1024)\n",
        "    psd_test.append(S/max(S))\n",
        "\n",
        "  psd_test = np.array(psd_test)\n",
        "  return psd_train, psd_val, psd_test\n",
        "\n",
        "#@title 3.2 Feature extraction: MFCC\n",
        "def get_mfcc():\n",
        "# Define the frame length and hop length in samples\n",
        "  frame_length = 2000\n",
        "  hop_length =  1000\n",
        "\n",
        "  # Define the number of MFCCs to extract\n",
        "  num_mfcc = 15\n",
        "\n",
        "  # Define the sampling rate of the audio signals\n",
        "  sr = 52734\n",
        "\n",
        "  mfcc_train = []\n",
        "  mfcc_val = []\n",
        "  mfcc_test = []\n",
        "\n",
        "  # Extract MFCC features for the training set\n",
        "  for audio in X_train:\n",
        "      audio = np.asarray(audio, dtype=float)\n",
        "      mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=num_mfcc,\n",
        "                                  n_fft=frame_length, hop_length=hop_length)#, fmin = 25, fmax = 7500)\n",
        "      mfcc_train.append(mfcc.flatten())\n",
        "\n",
        "  # Convert the list of MFCCs to a NumPy array and squeeze the dimensions\n",
        "  mfcc_train = np.array(mfcc_train)\n",
        "\n",
        "\n",
        "  # Extract MFCC features for the validation set\n",
        "  for audio in X_val:\n",
        "      audio = np.asarray(audio, dtype=float)\n",
        "      mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=num_mfcc,\n",
        "                                  n_fft=frame_length, hop_length=hop_length)#, fmin = 25, fmax = 7500)\n",
        "      mfcc_val.append(mfcc.flatten())\n",
        "\n",
        "\n",
        "  # Convert the list of MFCCs to a NumPy array and squeeze the dimensions\n",
        "  mfcc_val = np.array(mfcc_val)\n",
        "\n",
        "  # Extract MFCC features for the test set\n",
        "  for audio in X_test:\n",
        "      audio = np.asarray(audio, dtype=float)\n",
        "      mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=num_mfcc,\n",
        "                                  n_fft=frame_length, hop_length=hop_length )#,fmin = 25, fmax = 7500)\n",
        "      mfcc_test.append(mfcc.flatten())\n",
        "\n",
        "  # Convert the list of MFCCs to a NumPy array and squeeze the dimensions\n",
        "  mfcc_test = np.array(mfcc_test)\n",
        "  return  mfcc_train, mfcc_val, mfcc_test"
      ],
      "metadata": {
        "cellView": "form",
        "id": "IjyKI0XSMBW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYbLhJkcTBbg",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 2.1 Data Load\n",
        "\n",
        "def dataload(datax):\n",
        "  # Define the directory where the file is saved\n",
        "  directory = \"./drive/MyDrive/TFG/Data/\"\n",
        "\n",
        "  # Load the variables from the file\n",
        "  with open(os.path.join(directory, datax), \"rb\") as f:\n",
        "      X_train, X_test, X_val, y_train, y_test, y_val = pickle.load(f)\n",
        "\n",
        "  y_train = np.array(y_train)\n",
        "  y_val = np.array(y_val)\n",
        "  y_test = np.array(y_test)\n",
        "  return X_train, X_test, X_val, y_train, y_test, y_val\n",
        "\n",
        "def save_model(model,modeltype,n):\n",
        "\n",
        "  model_filename = \"CNN_\" + str(modeltype) +  \"_\" + str(n) + \".pkl\"\n",
        "\n",
        "  # Define the directory where you want to save the file\n",
        "  directory = \"./drive/MyDrive/TFG/Models/CNN/\"  #change to /RF to actually overwrite stored models\n",
        "\n",
        "  # Save the variables to a file\n",
        "  with open(os.path.join(directory, model_filename), \"wb\") as f:\n",
        "      pickle.dump((model), f)\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksB9YhNmAM4Z",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 3.1 Feature extraction: PSD\n",
        "\n",
        "def get_psd():\n",
        "\n",
        "  psd_train = []\n",
        "  psd_test = []\n",
        "  psd_val = []\n",
        "\n",
        "  # Calculate the zero-crossing rate for X_train\n",
        "  for audio in X_train:\n",
        "    (f, S)= scipy.signal.welch(audio, 5000, nperseg=2*1024) # best so far 2*1024\n",
        "    psd_train.append(S/max(S))\n",
        "\n",
        "  psd_train = np.array(psd_train)\n",
        "\n",
        "  # Calculate the zero-crossing rate for X_val\n",
        "  for audio in X_val:\n",
        "    (f, S)= scipy.signal.welch(audio, 5000, nperseg=2*1024)\n",
        "    psd_val.append(S/max(S))\n",
        "\n",
        "  psd_val = np.array(psd_val)\n",
        "\n",
        "  # Calculate the zero-crossing rate for X_test\n",
        "  for audio in X_test:\n",
        "    (f, S)= scipy.signal.welch(audio, 5000, nperseg=2*1024)\n",
        "    psd_test.append(S/max(S))\n",
        "\n",
        "  psd_test = np.array(psd_test)\n",
        "  return psd_train, psd_val, psd_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "O0nB9pSB7Sx0",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 3.2 Feature extraction: MFCC\n",
        "def get_mfcc():\n",
        "# Define the frame length and hop length in samples\n",
        "  frame_length = 2000\n",
        "  hop_length =  1000\n",
        "\n",
        "  # Define the number of MFCCs to extract\n",
        "  num_mfcc = 15\n",
        "\n",
        "  # Define the sampling rate of the audio signals\n",
        "  sr = 52734\n",
        "\n",
        "  mfcc_train = []\n",
        "  mfcc_val = []\n",
        "  mfcc_test = []\n",
        "\n",
        "  # Extract MFCC features for the training set\n",
        "  for audio in X_train:\n",
        "      audio = np.asarray(audio, dtype=float)\n",
        "      mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=num_mfcc,\n",
        "                                  n_fft=frame_length, hop_length=hop_length)#, fmin = 25, fmax = 7500)\n",
        "      mfcc_train.append(mfcc.flatten())\n",
        "\n",
        "  # Convert the list of MFCCs to a NumPy array and squeeze the dimensions\n",
        "  mfcc_train = np.array(mfcc_train)\n",
        "\n",
        "\n",
        "  # Extract MFCC features for the validation set\n",
        "  for audio in X_val:\n",
        "      audio = np.asarray(audio, dtype=float)\n",
        "      mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=num_mfcc,\n",
        "                                  n_fft=frame_length, hop_length=hop_length)#, fmin = 25, fmax = 7500)\n",
        "      mfcc_val.append(mfcc.flatten())\n",
        "\n",
        "\n",
        "  # Convert the list of MFCCs to a NumPy array and squeeze the dimensions\n",
        "  mfcc_val = np.array(mfcc_val)\n",
        "\n",
        "  # Extract MFCC features for the test set\n",
        "  for audio in X_test:\n",
        "      audio = np.asarray(audio, dtype=float)\n",
        "      mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=num_mfcc,\n",
        "                                  n_fft=frame_length, hop_length=hop_length )#,fmin = 25, fmax = 7500)\n",
        "      mfcc_test.append(mfcc.flatten())\n",
        "\n",
        "  # Convert the list of MFCCs to a NumPy array and squeeze the dimensions\n",
        "  mfcc_test = np.array(mfcc_test)\n",
        "  return  mfcc_train, mfcc_val, mfcc_test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Get CNN Raw data\n",
        "\n",
        "def get_CNN_raw(n):\n",
        "\n",
        "  m_raw = Sequential()\n",
        "  m_raw.add(Conv1D(64,\n",
        "                input_shape=[5000, 1],\n",
        "                kernel_size=80,\n",
        "                strides=2,\n",
        "                padding='same',\n",
        "                kernel_initializer='glorot_uniform',\n",
        "                kernel_regularizer=regularizers.l2(l=0.0001),\n",
        "                activation='relu'))\n",
        "  m_raw.add(BatchNormalization())\n",
        "  m_raw.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "  m_raw.add(Conv1D(128,\n",
        "                kernel_size=3,\n",
        "                strides=1,\n",
        "                padding='same',\n",
        "                kernel_initializer='glorot_uniform',\n",
        "                kernel_regularizer=regularizers.l2(l=0.0001),\n",
        "                activation='relu'))\n",
        "  m_raw.add(BatchNormalization())\n",
        "  m_raw.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "  m_raw.add(Conv1D(256,\n",
        "                kernel_size=3,\n",
        "                strides=1,\n",
        "                padding='same',\n",
        "                kernel_initializer='glorot_uniform',\n",
        "                kernel_regularizer=regularizers.l2(l=0.0001),\n",
        "                activation='relu'))\n",
        "  m_raw.add(BatchNormalization())\n",
        "  m_raw.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "  m_raw.add(Conv1D(512, #original 512\n",
        "                kernel_size=3,\n",
        "                strides=1,\n",
        "                padding='same',\n",
        "                kernel_initializer='glorot_uniform',\n",
        "                kernel_regularizer=regularizers.l2(l=0.0001),\n",
        "                activation='relu'))\n",
        "  m_raw.add(BatchNormalization())\n",
        "  m_raw.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "  m_raw.add(Dense(16, activation='relu')) #vlad added\n",
        "  m_raw.add(Lambda(lambda x: K.mean(x, axis=1)))  # Same as GAP for 1D Conv Layer\n",
        "  m_raw.add(Dense(4, activation='softmax'))\n",
        "  m_raw.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  print(m_raw.summary())\n",
        "  reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=10, min_lr=0.00005, verbose=1)\n",
        "  m_raw.fit(X_train, y_train, batch_size = 128, epochs = 110, validation_split=0.2, callbacks = [reduce_lr])\n",
        "\n",
        "  y_pred = m_raw.predict(X_test)\n",
        "  y_pred = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\n",
        "  metrics, matrix = plot_class_acc(y_test,y_pred,'CNN')\n",
        "\n",
        "  save_model(m_raw,\"raw\",n)\n",
        "\n",
        "  return metrics, matrix"
      ],
      "metadata": {
        "collapsed": true,
        "id": "k9F9jFVFO74Q",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Get CNN MFCC\n",
        "\n",
        "def get_CNN_mfcc(n):\n",
        "  m_mfcc = Sequential()\n",
        "  m_mfcc.add(Conv1D(64,\n",
        "                input_shape=[90, 1],\n",
        "                kernel_size=20,\n",
        "                strides=1,\n",
        "                padding='same',\n",
        "                kernel_initializer='glorot_uniform',\n",
        "                kernel_regularizer=regularizers.l2(l=0.0001),\n",
        "                activation='relu'))\n",
        "  m_mfcc.add(BatchNormalization())\n",
        "  m_mfcc.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "  m_mfcc.add(Conv1D(128,\n",
        "                kernel_size=3,\n",
        "                strides=1,\n",
        "                padding='same',\n",
        "                kernel_initializer='glorot_uniform',\n",
        "                kernel_regularizer=regularizers.l2(l=0.0001),\n",
        "                activation='relu'))\n",
        "  m_mfcc.add(BatchNormalization())\n",
        "  m_mfcc.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "  m_mfcc.add(Conv1D(256,\n",
        "                kernel_size=3,\n",
        "                strides=1,\n",
        "                padding='same',\n",
        "                kernel_initializer='glorot_uniform',\n",
        "                kernel_regularizer=regularizers.l2(l=0.0001),\n",
        "                activation='relu'))\n",
        "  m_mfcc.add(BatchNormalization())\n",
        "  m_mfcc.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "  m_mfcc.add(Dense(16, activation='relu')) #vlad added\n",
        "  m_mfcc.add(Lambda(lambda x: K.mean(x, axis=1)))  # Same as GAP for 1D Conv Layer\n",
        "  m_mfcc.add(Dense(4, activation='softmax'))\n",
        "  m_mfcc.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  print(m_mfcc.summary())\n",
        "  reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=10, min_lr=0.00005, verbose=1)\n",
        "  m_mfcc.fit(mfcc_train, y_train, batch_size = 128, epochs = 110, validation_split=0.2, callbacks = [reduce_lr])\n",
        "\n",
        "  y_pred = m_mfcc.predict(mfcc_test)\n",
        "  y_pred = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\n",
        "  metrics, matrix = plot_class_acc(y_test,y_pred,'CNN')\n",
        "\n",
        "  save_model(m_mfcc,\"mfcc\",n)\n",
        "\n",
        "  return metrics, matrix"
      ],
      "metadata": {
        "id": "r_aE503uWE6B",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Get CNN PSD\n",
        "\n",
        "def get_CNN_psd(n):\n",
        "  m_psd = Sequential()\n",
        "  m_psd.add(Conv1D(64,\n",
        "                input_shape=[1025, 1],\n",
        "                kernel_size=80,\n",
        "                strides=4,\n",
        "                padding='same',\n",
        "                kernel_initializer='glorot_uniform',\n",
        "                kernel_regularizer=regularizers.l2(l=0.0001),\n",
        "                activation='relu'))\n",
        "  m_psd.add(BatchNormalization())\n",
        "  m_psd.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "  m_psd.add(Conv1D(128,\n",
        "                kernel_size=3,\n",
        "                strides=1,\n",
        "                padding='same',\n",
        "                kernel_initializer='glorot_uniform',\n",
        "                kernel_regularizer=regularizers.l2(l=0.0001),\n",
        "                activation='relu'))\n",
        "  m_psd.add(BatchNormalization())\n",
        "  m_psd.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "  m_psd.add(Conv1D(256,\n",
        "                kernel_size=3,\n",
        "                strides=1,\n",
        "                padding='same',\n",
        "                kernel_initializer='glorot_uniform',\n",
        "                kernel_regularizer=regularizers.l2(l=0.0001),\n",
        "                activation='relu'))\n",
        "  m_psd.add(BatchNormalization())\n",
        "  m_psd.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "  m_psd.add(Conv1D(512,\n",
        "                kernel_size=3,\n",
        "                strides=1,\n",
        "                padding='same',\n",
        "                kernel_initializer='glorot_uniform',\n",
        "                kernel_regularizer=regularizers.l2(l=0.0001),\n",
        "                activation='relu'))\n",
        "  m_psd.add(BatchNormalization())\n",
        "  m_psd.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "  m_psd.add(Dense(16, activation='relu')) #vlad added\n",
        "  m_psd.add(Lambda(lambda x: K.mean(x, axis=1)))  # Same as GAP for 1D Conv Layer\n",
        "  m_psd.add(Dense(4, activation='softmax'))\n",
        "  m_psd.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  print(m_psd.summary())\n",
        "  reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=10, min_lr=0.00005, verbose=1)\n",
        "\n",
        "  psd_train, psd_val, psd_test = get_psd()\n",
        "  m_psd.fit(psd_train, y_train, batch_size = 128, epochs = 90, validation_split=0.2, callbacks = [reduce_lr])\n",
        "\n",
        "  y_pred = m_psd.predict(psd_test)\n",
        "  y_pred = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\n",
        "  metrics, matrix = plot_class_acc(y_test,y_pred,'CNN')\n",
        "  save_model(m_psd,\"psd\",n)\n",
        "\n",
        "  return metrics, matrix"
      ],
      "metadata": {
        "id": "FWxII_3e5yv5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "RpxT-DJk3dg7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "03b207ee-3e51-491a-ed3f-64e0162f301f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_51\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_184 (Conv1D)         (None, 257, 64)           5184      \n",
            "                                                                 \n",
            " batch_normalization_184 (Ba  (None, 257, 64)          256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_184 (MaxPooli  (None, 64, 64)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_185 (Conv1D)         (None, 64, 128)           24704     \n",
            "                                                                 \n",
            " batch_normalization_185 (Ba  (None, 64, 128)          512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_185 (MaxPooli  (None, 16, 128)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_186 (Conv1D)         (None, 16, 256)           98560     \n",
            "                                                                 \n",
            " batch_normalization_186 (Ba  (None, 16, 256)          1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_186 (MaxPooli  (None, 4, 256)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_187 (Conv1D)         (None, 4, 512)            393728    \n",
            "                                                                 \n",
            " batch_normalization_187 (Ba  (None, 4, 512)           2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_187 (MaxPooli  (None, 1, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_94 (Dense)            (None, 1, 16)             8208      \n",
            "                                                                 \n",
            " lambda_47 (Lambda)          (None, 16)                0         \n",
            "                                                                 \n",
            " dense_95 (Dense)            (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 534,292\n",
            "Trainable params: 532,372\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/90\n",
            "35/35 [==============================] - 5s 21ms/step - loss: 1.0508 - accuracy: 0.6234 - val_loss: 1.6624 - val_accuracy: 0.1873 - lr: 0.0010\n",
            "Epoch 2/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.5563 - accuracy: 0.8192 - val_loss: 1.9241 - val_accuracy: 0.1873 - lr: 0.0010\n",
            "Epoch 3/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.4100 - accuracy: 0.8724 - val_loss: 2.0984 - val_accuracy: 0.1873 - lr: 0.0010\n",
            "Epoch 4/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.3362 - accuracy: 0.8988 - val_loss: 2.3529 - val_accuracy: 0.1873 - lr: 0.0010\n",
            "Epoch 5/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.2712 - accuracy: 0.9279 - val_loss: 2.5966 - val_accuracy: 0.1873 - lr: 0.0010\n",
            "Epoch 6/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.2302 - accuracy: 0.9418 - val_loss: 3.2570 - val_accuracy: 0.1873 - lr: 0.0010\n",
            "Epoch 7/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.2287 - accuracy: 0.9395 - val_loss: 2.5713 - val_accuracy: 0.1873 - lr: 0.0010\n",
            "Epoch 8/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1985 - accuracy: 0.9527 - val_loss: 1.8188 - val_accuracy: 0.2255 - lr: 0.0010\n",
            "Epoch 9/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1781 - accuracy: 0.9586 - val_loss: 3.3700 - val_accuracy: 0.1918 - lr: 0.0010\n",
            "Epoch 10/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1534 - accuracy: 0.9709 - val_loss: 1.9442 - val_accuracy: 0.2500 - lr: 0.0010\n",
            "Epoch 11/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1343 - accuracy: 0.9750 - val_loss: 2.1852 - val_accuracy: 0.2782 - lr: 0.0010\n",
            "Epoch 12/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1205 - accuracy: 0.9802 - val_loss: 2.3543 - val_accuracy: 0.2900 - lr: 0.0010\n",
            "Epoch 13/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1152 - accuracy: 0.9811 - val_loss: 2.3510 - val_accuracy: 0.3109 - lr: 0.0010\n",
            "Epoch 14/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1221 - accuracy: 0.9804 - val_loss: 1.7682 - val_accuracy: 0.4682 - lr: 0.0010\n",
            "Epoch 15/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1124 - accuracy: 0.9839 - val_loss: 2.3619 - val_accuracy: 0.3655 - lr: 0.0010\n",
            "Epoch 16/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1003 - accuracy: 0.9870 - val_loss: 2.3753 - val_accuracy: 0.4145 - lr: 0.0010\n",
            "Epoch 17/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0901 - accuracy: 0.9925 - val_loss: 1.9097 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 18/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0816 - accuracy: 0.9943 - val_loss: 1.6178 - val_accuracy: 0.5918 - lr: 0.0010\n",
            "Epoch 19/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0921 - accuracy: 0.9898 - val_loss: 0.8221 - val_accuracy: 0.7864 - lr: 0.0010\n",
            "Epoch 20/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0921 - accuracy: 0.9895 - val_loss: 0.7444 - val_accuracy: 0.7945 - lr: 0.0010\n",
            "Epoch 21/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0849 - accuracy: 0.9920 - val_loss: 0.9784 - val_accuracy: 0.7873 - lr: 0.0010\n",
            "Epoch 22/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1203 - accuracy: 0.9800 - val_loss: 1.1348 - val_accuracy: 0.7682 - lr: 0.0010\n",
            "Epoch 23/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1626 - accuracy: 0.9634 - val_loss: 2.8502 - val_accuracy: 0.5273 - lr: 0.0010\n",
            "Epoch 24/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1481 - accuracy: 0.9700 - val_loss: 4.3956 - val_accuracy: 0.4382 - lr: 0.0010\n",
            "Epoch 25/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1352 - accuracy: 0.9741 - val_loss: 1.6111 - val_accuracy: 0.6800 - lr: 0.0010\n",
            "Epoch 26/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1053 - accuracy: 0.9861 - val_loss: 0.7023 - val_accuracy: 0.8382 - lr: 0.0010\n",
            "Epoch 27/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0835 - accuracy: 0.9936 - val_loss: 0.6182 - val_accuracy: 0.8709 - lr: 0.0010\n",
            "Epoch 28/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0872 - accuracy: 0.9932 - val_loss: 0.8231 - val_accuracy: 0.8345 - lr: 0.0010\n",
            "Epoch 29/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0874 - accuracy: 0.9916 - val_loss: 0.6195 - val_accuracy: 0.8455 - lr: 0.0010\n",
            "Epoch 30/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0925 - accuracy: 0.9911 - val_loss: 0.7739 - val_accuracy: 0.8336 - lr: 0.0010\n",
            "Epoch 31/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0785 - accuracy: 0.9961 - val_loss: 0.6675 - val_accuracy: 0.8591 - lr: 0.0010\n",
            "Epoch 32/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0731 - accuracy: 0.9975 - val_loss: 0.6031 - val_accuracy: 0.8700 - lr: 0.0010\n",
            "Epoch 33/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0676 - accuracy: 0.9989 - val_loss: 0.5775 - val_accuracy: 0.8836 - lr: 0.0010\n",
            "Epoch 34/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0674 - accuracy: 0.9982 - val_loss: 0.5686 - val_accuracy: 0.8818 - lr: 0.0010\n",
            "Epoch 35/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0653 - accuracy: 0.9991 - val_loss: 0.9602 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 36/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0650 - accuracy: 0.9991 - val_loss: 0.8326 - val_accuracy: 0.8227 - lr: 0.0010\n",
            "Epoch 37/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0684 - accuracy: 0.9973 - val_loss: 1.4733 - val_accuracy: 0.7164 - lr: 0.0010\n",
            "Epoch 38/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0696 - accuracy: 0.9973 - val_loss: 0.6344 - val_accuracy: 0.8873 - lr: 0.0010\n",
            "Epoch 39/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0641 - accuracy: 0.9989 - val_loss: 1.3464 - val_accuracy: 0.7645 - lr: 0.0010\n",
            "Epoch 40/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0625 - accuracy: 0.9991 - val_loss: 0.6355 - val_accuracy: 0.8664 - lr: 0.0010\n",
            "Epoch 41/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0608 - accuracy: 0.9991 - val_loss: 0.5532 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 42/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0584 - accuracy: 0.9998 - val_loss: 0.6181 - val_accuracy: 0.8855 - lr: 0.0010\n",
            "Epoch 43/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.5692 - val_accuracy: 0.8927 - lr: 0.0010\n",
            "Epoch 44/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0588 - accuracy: 0.9993 - val_loss: 0.6240 - val_accuracy: 0.8736 - lr: 0.0010\n",
            "Epoch 45/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0612 - accuracy: 0.9989 - val_loss: 0.6911 - val_accuracy: 0.8645 - lr: 0.0010\n",
            "Epoch 46/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0587 - accuracy: 0.9989 - val_loss: 0.5935 - val_accuracy: 0.8891 - lr: 0.0010\n",
            "Epoch 47/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0566 - accuracy: 0.9993 - val_loss: 0.5992 - val_accuracy: 0.8791 - lr: 0.0010\n",
            "Epoch 48/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0551 - accuracy: 0.9995 - val_loss: 0.5685 - val_accuracy: 0.8791 - lr: 0.0010\n",
            "Epoch 49/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.6395 - val_accuracy: 0.8645 - lr: 0.0010\n",
            "Epoch 50/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 0.6077 - val_accuracy: 0.8900 - lr: 0.0010\n",
            "Epoch 51/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0518 - accuracy: 1.0000 - val_loss: 0.6201 - val_accuracy: 0.8845 - lr: 0.0010\n",
            "Epoch 52/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0520 - accuracy: 0.9998 - val_loss: 0.8227 - val_accuracy: 0.8500 - lr: 0.0010\n",
            "Epoch 53/90\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0516 - accuracy: 0.9997\n",
            "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0515 - accuracy: 0.9998 - val_loss: 0.8589 - val_accuracy: 0.8564 - lr: 0.0010\n",
            "Epoch 54/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0513 - accuracy: 0.9998 - val_loss: 0.7608 - val_accuracy: 0.8691 - lr: 5.0000e-04\n",
            "Epoch 55/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0499 - accuracy: 1.0000 - val_loss: 0.6974 - val_accuracy: 0.8818 - lr: 5.0000e-04\n",
            "Epoch 56/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.6521 - val_accuracy: 0.8909 - lr: 5.0000e-04\n",
            "Epoch 57/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0489 - accuracy: 1.0000 - val_loss: 0.6286 - val_accuracy: 0.8936 - lr: 5.0000e-04\n",
            "Epoch 58/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 0.6184 - val_accuracy: 0.8982 - lr: 5.0000e-04\n",
            "Epoch 59/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0482 - accuracy: 1.0000 - val_loss: 0.6165 - val_accuracy: 0.8973 - lr: 5.0000e-04\n",
            "Epoch 60/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.6190 - val_accuracy: 0.8991 - lr: 5.0000e-04\n",
            "Epoch 61/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0474 - accuracy: 1.0000 - val_loss: 0.6227 - val_accuracy: 0.8991 - lr: 5.0000e-04\n",
            "Epoch 62/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.6232 - val_accuracy: 0.9018 - lr: 5.0000e-04\n",
            "Epoch 63/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 0.6295 - val_accuracy: 0.9000 - lr: 5.0000e-04\n",
            "Epoch 64/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 0.6244 - val_accuracy: 0.8982 - lr: 5.0000e-04\n",
            "Epoch 65/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.6208 - val_accuracy: 0.8991 - lr: 5.0000e-04\n",
            "Epoch 66/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.6211 - val_accuracy: 0.8973 - lr: 5.0000e-04\n",
            "Epoch 67/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.6255 - val_accuracy: 0.8964 - lr: 5.0000e-04\n",
            "Epoch 68/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0448 - accuracy: 1.0000 - val_loss: 0.6286 - val_accuracy: 0.8973 - lr: 5.0000e-04\n",
            "Epoch 69/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0444 - accuracy: 1.0000 - val_loss: 0.6284 - val_accuracy: 0.8973 - lr: 5.0000e-04\n",
            "Epoch 70/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.6273 - val_accuracy: 0.8973 - lr: 5.0000e-04\n",
            "Epoch 71/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0436 - accuracy: 1.0000 - val_loss: 0.6280 - val_accuracy: 0.8964 - lr: 5.0000e-04\n",
            "Epoch 72/90\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0432 - accuracy: 1.0000\n",
            "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.6296 - val_accuracy: 0.8973 - lr: 5.0000e-04\n",
            "Epoch 73/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.6342 - val_accuracy: 0.8973 - lr: 2.5000e-04\n",
            "Epoch 74/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.6354 - val_accuracy: 0.8982 - lr: 2.5000e-04\n",
            "Epoch 75/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.6359 - val_accuracy: 0.9000 - lr: 2.5000e-04\n",
            "Epoch 76/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.6361 - val_accuracy: 0.8991 - lr: 2.5000e-04\n",
            "Epoch 77/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.6372 - val_accuracy: 0.8982 - lr: 2.5000e-04\n",
            "Epoch 78/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 0.6373 - val_accuracy: 0.8982 - lr: 2.5000e-04\n",
            "Epoch 79/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.6389 - val_accuracy: 0.8982 - lr: 2.5000e-04\n",
            "Epoch 80/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 0.6402 - val_accuracy: 0.9000 - lr: 2.5000e-04\n",
            "Epoch 81/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.6401 - val_accuracy: 0.9000 - lr: 2.5000e-04\n",
            "Epoch 82/90\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0411 - accuracy: 1.0000\n",
            "Epoch 82: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.6400 - val_accuracy: 0.9000 - lr: 2.5000e-04\n",
            "Epoch 83/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.6419 - val_accuracy: 0.9009 - lr: 1.2500e-04\n",
            "Epoch 84/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.6430 - val_accuracy: 0.9000 - lr: 1.2500e-04\n",
            "Epoch 85/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.6442 - val_accuracy: 0.9000 - lr: 1.2500e-04\n",
            "Epoch 86/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0406 - accuracy: 1.0000 - val_loss: 0.6459 - val_accuracy: 0.9009 - lr: 1.2500e-04\n",
            "Epoch 87/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.6468 - val_accuracy: 0.9009 - lr: 1.2500e-04\n",
            "Epoch 88/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.6462 - val_accuracy: 0.9009 - lr: 1.2500e-04\n",
            "Epoch 89/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.6477 - val_accuracy: 0.9009 - lr: 1.2500e-04\n",
            "Epoch 90/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 0.6478 - val_accuracy: 0.9000 - lr: 1.2500e-04\n",
            "54/54 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "   Class A  Class B  Class C  Class D\n",
            "0      340        7       19       17\n",
            "1        3      277       25        6\n",
            "2       15       22      498       19\n",
            "3        8        5        6      451\n",
            "\n",
            "Metrics:\n",
            "     Class  Precision  Recall  F1 Score  Accuracy\n",
            "0  Class 0      0.929   0.888     0.908     0.912\n",
            "1  Class 1      0.891   0.891     0.891     0.912\n",
            "2  Class 2      0.909   0.899     0.904     0.912\n",
            "3  Class 3      0.915   0.960     0.937     0.912\n",
            "Model: \"sequential_52\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_188 (Conv1D)         (None, 257, 64)           5184      \n",
            "                                                                 \n",
            " batch_normalization_188 (Ba  (None, 257, 64)          256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_188 (MaxPooli  (None, 64, 64)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_189 (Conv1D)         (None, 64, 128)           24704     \n",
            "                                                                 \n",
            " batch_normalization_189 (Ba  (None, 64, 128)          512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_189 (MaxPooli  (None, 16, 128)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_190 (Conv1D)         (None, 16, 256)           98560     \n",
            "                                                                 \n",
            " batch_normalization_190 (Ba  (None, 16, 256)          1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_190 (MaxPooli  (None, 4, 256)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_191 (Conv1D)         (None, 4, 512)            393728    \n",
            "                                                                 \n",
            " batch_normalization_191 (Ba  (None, 4, 512)           2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_191 (MaxPooli  (None, 1, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_96 (Dense)            (None, 1, 16)             8208      \n",
            "                                                                 \n",
            " lambda_48 (Lambda)          (None, 16)                0         \n",
            "                                                                 \n",
            " dense_97 (Dense)            (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 534,292\n",
            "Trainable params: 532,372\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/90\n",
            "35/35 [==============================] - 6s 21ms/step - loss: 1.1393 - accuracy: 0.5677 - val_loss: 1.6466 - val_accuracy: 0.1964 - lr: 0.0010\n",
            "Epoch 2/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.7196 - accuracy: 0.7551 - val_loss: 1.9336 - val_accuracy: 0.1964 - lr: 0.0010\n",
            "Epoch 3/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.5188 - accuracy: 0.8322 - val_loss: 2.2553 - val_accuracy: 0.1964 - lr: 0.0010\n",
            "Epoch 4/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.4134 - accuracy: 0.8722 - val_loss: 2.2817 - val_accuracy: 0.1964 - lr: 0.0010\n",
            "Epoch 5/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.3539 - accuracy: 0.8949 - val_loss: 2.7387 - val_accuracy: 0.1964 - lr: 0.0010\n",
            "Epoch 6/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.2593 - accuracy: 0.9345 - val_loss: 2.1614 - val_accuracy: 0.1964 - lr: 0.0010\n",
            "Epoch 7/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.2273 - accuracy: 0.9418 - val_loss: 2.4060 - val_accuracy: 0.2055 - lr: 0.0010\n",
            "Epoch 8/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1711 - accuracy: 0.9654 - val_loss: 2.6468 - val_accuracy: 0.1964 - lr: 0.0010\n",
            "Epoch 9/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1851 - accuracy: 0.9529 - val_loss: 1.8389 - val_accuracy: 0.2418 - lr: 0.0010\n",
            "Epoch 10/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1980 - accuracy: 0.9529 - val_loss: 2.3261 - val_accuracy: 0.3873 - lr: 0.0010\n",
            "Epoch 11/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1421 - accuracy: 0.9763 - val_loss: 3.1053 - val_accuracy: 0.2091 - lr: 0.0010\n",
            "Epoch 12/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1170 - accuracy: 0.9818 - val_loss: 3.3063 - val_accuracy: 0.2555 - lr: 0.0010\n",
            "Epoch 13/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1056 - accuracy: 0.9854 - val_loss: 3.1230 - val_accuracy: 0.3191 - lr: 0.0010\n",
            "Epoch 14/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1204 - accuracy: 0.9818 - val_loss: 1.9525 - val_accuracy: 0.4400 - lr: 0.0010\n",
            "Epoch 15/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0973 - accuracy: 0.9879 - val_loss: 2.3828 - val_accuracy: 0.4555 - lr: 0.0010\n",
            "Epoch 16/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0979 - accuracy: 0.9895 - val_loss: 1.3269 - val_accuracy: 0.5982 - lr: 0.0010\n",
            "Epoch 17/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0951 - accuracy: 0.9895 - val_loss: 0.9818 - val_accuracy: 0.7145 - lr: 0.0010\n",
            "Epoch 18/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0956 - accuracy: 0.9902 - val_loss: 1.0196 - val_accuracy: 0.7327 - lr: 0.0010\n",
            "Epoch 19/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1099 - accuracy: 0.9834 - val_loss: 1.7938 - val_accuracy: 0.6082 - lr: 0.0010\n",
            "Epoch 20/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1134 - accuracy: 0.9829 - val_loss: 1.5526 - val_accuracy: 0.6445 - lr: 0.0010\n",
            "Epoch 21/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1275 - accuracy: 0.9804 - val_loss: 3.2103 - val_accuracy: 0.5064 - lr: 0.0010\n",
            "Epoch 22/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1266 - accuracy: 0.9786 - val_loss: 1.2986 - val_accuracy: 0.6764 - lr: 0.0010\n",
            "Epoch 23/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1028 - accuracy: 0.9877 - val_loss: 1.0483 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 24/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0988 - accuracy: 0.9891 - val_loss: 0.8706 - val_accuracy: 0.7991 - lr: 0.0010\n",
            "Epoch 25/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0974 - accuracy: 0.9898 - val_loss: 1.4418 - val_accuracy: 0.6836 - lr: 0.0010\n",
            "Epoch 26/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0977 - accuracy: 0.9866 - val_loss: 0.6881 - val_accuracy: 0.8400 - lr: 0.0010\n",
            "Epoch 27/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0835 - accuracy: 0.9939 - val_loss: 0.9050 - val_accuracy: 0.7800 - lr: 0.0010\n",
            "Epoch 28/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0770 - accuracy: 0.9968 - val_loss: 0.4926 - val_accuracy: 0.8982 - lr: 0.0010\n",
            "Epoch 29/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0746 - accuracy: 0.9968 - val_loss: 0.5151 - val_accuracy: 0.8818 - lr: 0.0010\n",
            "Epoch 30/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0671 - accuracy: 0.9991 - val_loss: 0.4192 - val_accuracy: 0.9191 - lr: 0.0010\n",
            "Epoch 31/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0681 - accuracy: 0.9980 - val_loss: 0.4564 - val_accuracy: 0.8927 - lr: 0.0010\n",
            "Epoch 32/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0671 - accuracy: 0.9989 - val_loss: 0.4167 - val_accuracy: 0.9136 - lr: 0.0010\n",
            "Epoch 33/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0667 - accuracy: 0.9986 - val_loss: 0.3928 - val_accuracy: 0.9155 - lr: 0.0010\n",
            "Epoch 34/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0694 - accuracy: 0.9975 - val_loss: 0.5201 - val_accuracy: 0.9055 - lr: 0.0010\n",
            "Epoch 35/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0706 - accuracy: 0.9968 - val_loss: 0.4704 - val_accuracy: 0.9064 - lr: 0.0010\n",
            "Epoch 36/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0628 - accuracy: 0.9989 - val_loss: 0.6508 - val_accuracy: 0.8545 - lr: 0.0010\n",
            "Epoch 37/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0600 - accuracy: 0.9998 - val_loss: 0.4553 - val_accuracy: 0.9164 - lr: 0.0010\n",
            "Epoch 38/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0594 - accuracy: 0.9995 - val_loss: 0.4044 - val_accuracy: 0.9218 - lr: 0.0010\n",
            "Epoch 39/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0589 - accuracy: 0.9995 - val_loss: 0.4046 - val_accuracy: 0.9209 - lr: 0.0010\n",
            "Epoch 40/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0572 - accuracy: 0.9998 - val_loss: 0.4275 - val_accuracy: 0.9273 - lr: 0.0010\n",
            "Epoch 41/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0580 - accuracy: 0.9989 - val_loss: 1.0911 - val_accuracy: 0.7891 - lr: 0.0010\n",
            "Epoch 42/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0561 - accuracy: 0.9995 - val_loss: 0.7476 - val_accuracy: 0.8464 - lr: 0.0010\n",
            "Epoch 43/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0549 - accuracy: 0.9998 - val_loss: 0.5963 - val_accuracy: 0.8664 - lr: 0.0010\n",
            "Epoch 44/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0554 - accuracy: 0.9995 - val_loss: 0.4351 - val_accuracy: 0.9127 - lr: 0.0010\n",
            "Epoch 45/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0542 - accuracy: 0.9998 - val_loss: 0.4779 - val_accuracy: 0.8973 - lr: 0.0010\n",
            "Epoch 46/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0561 - accuracy: 0.9986 - val_loss: 0.4962 - val_accuracy: 0.9100 - lr: 0.0010\n",
            "Epoch 47/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0650 - accuracy: 0.9957 - val_loss: 1.0679 - val_accuracy: 0.8345 - lr: 0.0010\n",
            "Epoch 48/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1132 - accuracy: 0.9804 - val_loss: 3.7094 - val_accuracy: 0.4955 - lr: 0.0010\n",
            "Epoch 49/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.2727 - accuracy: 0.9245 - val_loss: 2.3062 - val_accuracy: 0.6482 - lr: 0.0010\n",
            "Epoch 50/90\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.1931 - accuracy: 0.9522\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1924 - accuracy: 0.9529 - val_loss: 2.0324 - val_accuracy: 0.6400 - lr: 0.0010\n",
            "Epoch 51/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1094 - accuracy: 0.9829 - val_loss: 1.0853 - val_accuracy: 0.7555 - lr: 5.0000e-04\n",
            "Epoch 52/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0752 - accuracy: 0.9959 - val_loss: 0.8821 - val_accuracy: 0.8036 - lr: 5.0000e-04\n",
            "Epoch 53/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0674 - accuracy: 0.9995 - val_loss: 0.6204 - val_accuracy: 0.8545 - lr: 5.0000e-04\n",
            "Epoch 54/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0662 - accuracy: 0.9991 - val_loss: 0.3930 - val_accuracy: 0.9073 - lr: 5.0000e-04\n",
            "Epoch 55/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0636 - accuracy: 0.9998 - val_loss: 0.3876 - val_accuracy: 0.9191 - lr: 5.0000e-04\n",
            "Epoch 56/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0631 - accuracy: 0.9998 - val_loss: 0.3375 - val_accuracy: 0.9282 - lr: 5.0000e-04\n",
            "Epoch 57/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0633 - accuracy: 0.9993 - val_loss: 0.4123 - val_accuracy: 0.9109 - lr: 5.0000e-04\n",
            "Epoch 58/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0618 - accuracy: 0.9998 - val_loss: 0.5026 - val_accuracy: 0.8891 - lr: 5.0000e-04\n",
            "Epoch 59/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0613 - accuracy: 0.9998 - val_loss: 0.3470 - val_accuracy: 0.9227 - lr: 5.0000e-04\n",
            "Epoch 60/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0607 - accuracy: 0.9998 - val_loss: 0.4498 - val_accuracy: 0.9091 - lr: 5.0000e-04\n",
            "Epoch 61/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0603 - accuracy: 0.9995 - val_loss: 0.3826 - val_accuracy: 0.9182 - lr: 5.0000e-04\n",
            "Epoch 62/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0603 - accuracy: 0.9993 - val_loss: 0.3456 - val_accuracy: 0.9327 - lr: 5.0000e-04\n",
            "Epoch 63/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0590 - accuracy: 0.9998 - val_loss: 0.3768 - val_accuracy: 0.9191 - lr: 5.0000e-04\n",
            "Epoch 64/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0583 - accuracy: 0.9998 - val_loss: 0.3430 - val_accuracy: 0.9273 - lr: 5.0000e-04\n",
            "Epoch 65/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.3666 - val_accuracy: 0.9227 - lr: 5.0000e-04\n",
            "Epoch 66/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0573 - accuracy: 0.9998 - val_loss: 0.3447 - val_accuracy: 0.9291 - lr: 5.0000e-04\n",
            "Epoch 67/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0568 - accuracy: 0.9995 - val_loss: 0.4173 - val_accuracy: 0.9136 - lr: 5.0000e-04\n",
            "Epoch 68/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0568 - accuracy: 0.9995 - val_loss: 0.4045 - val_accuracy: 0.9173 - lr: 5.0000e-04\n",
            "Epoch 69/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0562 - accuracy: 0.9998 - val_loss: 0.3581 - val_accuracy: 0.9300 - lr: 5.0000e-04\n",
            "Epoch 70/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0570 - accuracy: 0.9991 - val_loss: 0.4111 - val_accuracy: 0.9118 - lr: 5.0000e-04\n",
            "Epoch 71/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.4294 - val_accuracy: 0.9064 - lr: 5.0000e-04\n",
            "Epoch 72/90\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0544 - accuracy: 1.0000\n",
            "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0551 - accuracy: 0.9995 - val_loss: 0.4339 - val_accuracy: 0.9018 - lr: 5.0000e-04\n",
            "Epoch 73/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0540 - accuracy: 1.0000 - val_loss: 0.3706 - val_accuracy: 0.9227 - lr: 2.5000e-04\n",
            "Epoch 74/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.3516 - val_accuracy: 0.9273 - lr: 2.5000e-04\n",
            "Epoch 75/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0533 - accuracy: 1.0000 - val_loss: 0.3523 - val_accuracy: 0.9255 - lr: 2.5000e-04\n",
            "Epoch 76/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 0.3516 - val_accuracy: 0.9309 - lr: 2.5000e-04\n",
            "Epoch 77/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.3527 - val_accuracy: 0.9300 - lr: 2.5000e-04\n",
            "Epoch 78/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 0.3554 - val_accuracy: 0.9327 - lr: 2.5000e-04\n",
            "Epoch 79/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0523 - accuracy: 1.0000 - val_loss: 0.3540 - val_accuracy: 0.9291 - lr: 2.5000e-04\n",
            "Epoch 80/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.3523 - val_accuracy: 0.9264 - lr: 2.5000e-04\n",
            "Epoch 81/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0518 - accuracy: 1.0000 - val_loss: 0.3656 - val_accuracy: 0.9336 - lr: 2.5000e-04\n",
            "Epoch 82/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0519 - accuracy: 0.9998 - val_loss: 0.3605 - val_accuracy: 0.9227 - lr: 2.5000e-04\n",
            "Epoch 83/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0513 - accuracy: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.9227 - lr: 2.5000e-04\n",
            "Epoch 84/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.3642 - val_accuracy: 0.9291 - lr: 2.5000e-04\n",
            "Epoch 85/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0506 - accuracy: 1.0000 - val_loss: 0.3745 - val_accuracy: 0.9291 - lr: 2.5000e-04\n",
            "Epoch 86/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.3704 - val_accuracy: 0.9300 - lr: 2.5000e-04\n",
            "Epoch 87/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.3732 - val_accuracy: 0.9291 - lr: 2.5000e-04\n",
            "Epoch 88/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0498 - accuracy: 1.0000 - val_loss: 0.3614 - val_accuracy: 0.9282 - lr: 2.5000e-04\n",
            "Epoch 89/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.3666 - val_accuracy: 0.9282 - lr: 2.5000e-04\n",
            "Epoch 90/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.3676 - val_accuracy: 0.9291 - lr: 2.5000e-04\n",
            "54/54 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "   Class A  Class B  Class C  Class D\n",
            "0      338        2       13       17\n",
            "1       16      252       29        6\n",
            "2       19       14      478       15\n",
            "3        7        1       14      497\n",
            "\n",
            "Metrics:\n",
            "     Class  Precision  Recall  F1 Score  Accuracy\n",
            "0  Class 0      0.889   0.914     0.901     0.911\n",
            "1  Class 1      0.937   0.832     0.881     0.911\n",
            "2  Class 2      0.895   0.909     0.902     0.911\n",
            "3  Class 3      0.929   0.958     0.943     0.911\n",
            "Model: \"sequential_53\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_192 (Conv1D)         (None, 257, 64)           5184      \n",
            "                                                                 \n",
            " batch_normalization_192 (Ba  (None, 257, 64)          256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_192 (MaxPooli  (None, 64, 64)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_193 (Conv1D)         (None, 64, 128)           24704     \n",
            "                                                                 \n",
            " batch_normalization_193 (Ba  (None, 64, 128)          512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_193 (MaxPooli  (None, 16, 128)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_194 (Conv1D)         (None, 16, 256)           98560     \n",
            "                                                                 \n",
            " batch_normalization_194 (Ba  (None, 16, 256)          1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_194 (MaxPooli  (None, 4, 256)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_195 (Conv1D)         (None, 4, 512)            393728    \n",
            "                                                                 \n",
            " batch_normalization_195 (Ba  (None, 4, 512)           2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_195 (MaxPooli  (None, 1, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_98 (Dense)            (None, 1, 16)             8208      \n",
            "                                                                 \n",
            " lambda_49 (Lambda)          (None, 16)                0         \n",
            "                                                                 \n",
            " dense_99 (Dense)            (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 534,292\n",
            "Trainable params: 532,372\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/90\n",
            "35/35 [==============================] - 5s 20ms/step - loss: 1.2099 - accuracy: 0.5779 - val_loss: 1.5553 - val_accuracy: 0.3000 - lr: 0.0010\n",
            "Epoch 2/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.6692 - accuracy: 0.7758 - val_loss: 1.6297 - val_accuracy: 0.3255 - lr: 0.0010\n",
            "Epoch 3/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.4622 - accuracy: 0.8604 - val_loss: 1.7210 - val_accuracy: 0.3255 - lr: 0.0010\n",
            "Epoch 4/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.3766 - accuracy: 0.8886 - val_loss: 1.8658 - val_accuracy: 0.3255 - lr: 0.0010\n",
            "Epoch 5/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.3079 - accuracy: 0.9106 - val_loss: 1.9345 - val_accuracy: 0.3255 - lr: 0.0010\n",
            "Epoch 6/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.2517 - accuracy: 0.9318 - val_loss: 1.8512 - val_accuracy: 0.3255 - lr: 0.0010\n",
            "Epoch 7/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.2107 - accuracy: 0.9481 - val_loss: 2.0966 - val_accuracy: 0.1882 - lr: 0.0010\n",
            "Epoch 8/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1645 - accuracy: 0.9650 - val_loss: 2.4055 - val_accuracy: 0.1709 - lr: 0.0010\n",
            "Epoch 9/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1400 - accuracy: 0.9736 - val_loss: 3.0749 - val_accuracy: 0.2064 - lr: 0.0010\n",
            "Epoch 10/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1290 - accuracy: 0.9777 - val_loss: 3.7250 - val_accuracy: 0.2600 - lr: 0.0010\n",
            "Epoch 11/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1211 - accuracy: 0.9807 - val_loss: 3.6953 - val_accuracy: 0.2955 - lr: 0.0010\n",
            "Epoch 12/90\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.1284 - accuracy: 0.9791\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1322 - accuracy: 0.9777 - val_loss: 4.0757 - val_accuracy: 0.2682 - lr: 0.0010\n",
            "Epoch 13/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1074 - accuracy: 0.9841 - val_loss: 3.4664 - val_accuracy: 0.3373 - lr: 5.0000e-04\n",
            "Epoch 14/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0900 - accuracy: 0.9911 - val_loss: 3.0904 - val_accuracy: 0.3945 - lr: 5.0000e-04\n",
            "Epoch 15/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0846 - accuracy: 0.9934 - val_loss: 3.0924 - val_accuracy: 0.4264 - lr: 5.0000e-04\n",
            "Epoch 16/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0740 - accuracy: 0.9964 - val_loss: 2.9539 - val_accuracy: 0.4600 - lr: 5.0000e-04\n",
            "Epoch 17/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0716 - accuracy: 0.9975 - val_loss: 2.6411 - val_accuracy: 0.4818 - lr: 5.0000e-04\n",
            "Epoch 18/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0711 - accuracy: 0.9968 - val_loss: 2.2524 - val_accuracy: 0.5182 - lr: 5.0000e-04\n",
            "Epoch 19/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0695 - accuracy: 0.9975 - val_loss: 1.5356 - val_accuracy: 0.6218 - lr: 5.0000e-04\n",
            "Epoch 20/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0674 - accuracy: 0.9984 - val_loss: 1.5333 - val_accuracy: 0.6573 - lr: 5.0000e-04\n",
            "Epoch 21/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0741 - accuracy: 0.9961 - val_loss: 1.3746 - val_accuracy: 0.6700 - lr: 5.0000e-04\n",
            "Epoch 22/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0668 - accuracy: 0.9982 - val_loss: 0.9951 - val_accuracy: 0.7573 - lr: 5.0000e-04\n",
            "Epoch 23/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0686 - accuracy: 0.9980 - val_loss: 0.6518 - val_accuracy: 0.8418 - lr: 5.0000e-04\n",
            "Epoch 24/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0652 - accuracy: 0.9993 - val_loss: 0.4945 - val_accuracy: 0.8855 - lr: 5.0000e-04\n",
            "Epoch 25/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0691 - accuracy: 0.9970 - val_loss: 0.8353 - val_accuracy: 0.8164 - lr: 5.0000e-04\n",
            "Epoch 26/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0659 - accuracy: 0.9975 - val_loss: 0.4698 - val_accuracy: 0.8973 - lr: 5.0000e-04\n",
            "Epoch 27/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0668 - accuracy: 0.9970 - val_loss: 0.4670 - val_accuracy: 0.8891 - lr: 5.0000e-04\n",
            "Epoch 28/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0639 - accuracy: 0.9989 - val_loss: 0.4688 - val_accuracy: 0.8809 - lr: 5.0000e-04\n",
            "Epoch 29/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0618 - accuracy: 0.9993 - val_loss: 0.4671 - val_accuracy: 0.8909 - lr: 5.0000e-04\n",
            "Epoch 30/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0655 - accuracy: 0.9975 - val_loss: 0.4386 - val_accuracy: 0.8991 - lr: 5.0000e-04\n",
            "Epoch 31/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0631 - accuracy: 0.9986 - val_loss: 0.8107 - val_accuracy: 0.8136 - lr: 5.0000e-04\n",
            "Epoch 32/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0659 - accuracy: 0.9973 - val_loss: 0.5648 - val_accuracy: 0.8845 - lr: 5.0000e-04\n",
            "Epoch 33/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0658 - accuracy: 0.9975 - val_loss: 0.6583 - val_accuracy: 0.8700 - lr: 5.0000e-04\n",
            "Epoch 34/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0636 - accuracy: 0.9984 - val_loss: 0.8115 - val_accuracy: 0.8173 - lr: 5.0000e-04\n",
            "Epoch 35/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0677 - accuracy: 0.9966 - val_loss: 0.4670 - val_accuracy: 0.8909 - lr: 5.0000e-04\n",
            "Epoch 36/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0624 - accuracy: 0.9986 - val_loss: 0.6246 - val_accuracy: 0.8718 - lr: 5.0000e-04\n",
            "Epoch 37/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0606 - accuracy: 0.9989 - val_loss: 0.8707 - val_accuracy: 0.8164 - lr: 5.0000e-04\n",
            "Epoch 38/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0586 - accuracy: 0.9995 - val_loss: 0.5517 - val_accuracy: 0.8827 - lr: 5.0000e-04\n",
            "Epoch 39/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0637 - accuracy: 0.9973 - val_loss: 0.5754 - val_accuracy: 0.8773 - lr: 5.0000e-04\n",
            "Epoch 40/90\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0620 - accuracy: 0.9976\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0623 - accuracy: 0.9975 - val_loss: 0.5904 - val_accuracy: 0.8764 - lr: 5.0000e-04\n",
            "Epoch 41/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0608 - accuracy: 0.9980 - val_loss: 0.5648 - val_accuracy: 0.8718 - lr: 2.5000e-04\n",
            "Epoch 42/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0570 - accuracy: 1.0000 - val_loss: 0.4694 - val_accuracy: 0.8955 - lr: 2.5000e-04\n",
            "Epoch 43/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0563 - accuracy: 0.9993 - val_loss: 0.5114 - val_accuracy: 0.8891 - lr: 2.5000e-04\n",
            "Epoch 44/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0561 - accuracy: 0.9998 - val_loss: 0.4849 - val_accuracy: 0.8982 - lr: 2.5000e-04\n",
            "Epoch 45/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0559 - accuracy: 0.9993 - val_loss: 0.4799 - val_accuracy: 0.8955 - lr: 2.5000e-04\n",
            "Epoch 46/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0557 - accuracy: 0.9993 - val_loss: 0.4738 - val_accuracy: 0.9009 - lr: 2.5000e-04\n",
            "Epoch 47/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0550 - accuracy: 0.9998 - val_loss: 0.4802 - val_accuracy: 0.9000 - lr: 2.5000e-04\n",
            "Epoch 48/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0544 - accuracy: 1.0000 - val_loss: 0.4841 - val_accuracy: 0.8936 - lr: 2.5000e-04\n",
            "Epoch 49/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0541 - accuracy: 1.0000 - val_loss: 0.4800 - val_accuracy: 0.8982 - lr: 2.5000e-04\n",
            "Epoch 50/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0546 - accuracy: 0.9995 - val_loss: 0.4845 - val_accuracy: 0.8964 - lr: 2.5000e-04\n",
            "Epoch 51/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 0.4803 - val_accuracy: 0.9000 - lr: 2.5000e-04\n",
            "Epoch 52/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0533 - accuracy: 1.0000 - val_loss: 0.4774 - val_accuracy: 0.9000 - lr: 2.5000e-04\n",
            "Epoch 53/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.4795 - val_accuracy: 0.9000 - lr: 2.5000e-04\n",
            "Epoch 54/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 0.4796 - val_accuracy: 0.9009 - lr: 2.5000e-04\n",
            "Epoch 55/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 0.4848 - val_accuracy: 0.9000 - lr: 2.5000e-04\n",
            "Epoch 56/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0523 - accuracy: 1.0000 - val_loss: 0.4871 - val_accuracy: 0.9027 - lr: 2.5000e-04\n",
            "Epoch 57/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0536 - accuracy: 0.9995 - val_loss: 0.4953 - val_accuracy: 0.9009 - lr: 2.5000e-04\n",
            "Epoch 58/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0543 - accuracy: 0.9991 - val_loss: 0.5064 - val_accuracy: 0.8918 - lr: 2.5000e-04\n",
            "Epoch 59/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0522 - accuracy: 0.9998 - val_loss: 0.4874 - val_accuracy: 0.8900 - lr: 2.5000e-04\n",
            "Epoch 60/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 0.4774 - val_accuracy: 0.9000 - lr: 2.5000e-04\n",
            "Epoch 61/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 0.4843 - val_accuracy: 0.8973 - lr: 2.5000e-04\n",
            "Epoch 62/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0515 - accuracy: 0.9998 - val_loss: 0.5230 - val_accuracy: 0.8936 - lr: 2.5000e-04\n",
            "Epoch 63/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0504 - accuracy: 1.0000 - val_loss: 0.5016 - val_accuracy: 0.9000 - lr: 2.5000e-04\n",
            "Epoch 64/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0502 - accuracy: 1.0000 - val_loss: 0.5078 - val_accuracy: 0.9055 - lr: 2.5000e-04\n",
            "Epoch 65/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0529 - accuracy: 0.9991 - val_loss: 0.7931 - val_accuracy: 0.8555 - lr: 2.5000e-04\n",
            "Epoch 66/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0506 - accuracy: 1.0000 - val_loss: 0.7259 - val_accuracy: 0.8582 - lr: 2.5000e-04\n",
            "Epoch 67/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0517 - accuracy: 0.9991 - val_loss: 0.5661 - val_accuracy: 0.8855 - lr: 2.5000e-04\n",
            "Epoch 68/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0493 - accuracy: 0.9998 - val_loss: 0.5162 - val_accuracy: 0.8945 - lr: 2.5000e-04\n",
            "Epoch 69/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 0.5336 - val_accuracy: 0.8945 - lr: 2.5000e-04\n",
            "Epoch 70/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0507 - accuracy: 0.9993 - val_loss: 0.5251 - val_accuracy: 0.8873 - lr: 2.5000e-04\n",
            "Epoch 71/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0494 - accuracy: 0.9998 - val_loss: 0.5318 - val_accuracy: 0.8891 - lr: 2.5000e-04\n",
            "Epoch 72/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0503 - accuracy: 0.9991 - val_loss: 0.5855 - val_accuracy: 0.8773 - lr: 2.5000e-04\n",
            "Epoch 73/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0520 - accuracy: 0.9984 - val_loss: 0.5474 - val_accuracy: 0.8945 - lr: 2.5000e-04\n",
            "Epoch 74/90\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.0490 - accuracy: 0.9993\n",
            "Epoch 74: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0489 - accuracy: 0.9993 - val_loss: 0.5964 - val_accuracy: 0.8755 - lr: 2.5000e-04\n",
            "Epoch 75/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0474 - accuracy: 1.0000 - val_loss: 0.5715 - val_accuracy: 0.8791 - lr: 1.2500e-04\n",
            "Epoch 76/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.5454 - val_accuracy: 0.8900 - lr: 1.2500e-04\n",
            "Epoch 77/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0470 - accuracy: 1.0000 - val_loss: 0.5371 - val_accuracy: 0.8900 - lr: 1.2500e-04\n",
            "Epoch 78/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 0.5228 - val_accuracy: 0.8936 - lr: 1.2500e-04\n",
            "Epoch 79/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.9009 - lr: 1.2500e-04\n",
            "Epoch 80/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 0.4914 - val_accuracy: 0.8991 - lr: 1.2500e-04\n",
            "Epoch 81/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0462 - accuracy: 1.0000 - val_loss: 0.4867 - val_accuracy: 0.9018 - lr: 1.2500e-04\n",
            "Epoch 82/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0461 - accuracy: 1.0000 - val_loss: 0.4965 - val_accuracy: 0.9027 - lr: 1.2500e-04\n",
            "Epoch 83/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0461 - accuracy: 1.0000 - val_loss: 0.5670 - val_accuracy: 0.8882 - lr: 1.2500e-04\n",
            "Epoch 84/90\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.0474 - accuracy: 0.9995\n",
            "Epoch 84: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0473 - accuracy: 0.9995 - val_loss: 0.5737 - val_accuracy: 0.8900 - lr: 1.2500e-04\n",
            "Epoch 85/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0468 - accuracy: 0.9995 - val_loss: 0.5498 - val_accuracy: 0.8855 - lr: 6.2500e-05\n",
            "Epoch 86/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0463 - accuracy: 0.9998 - val_loss: 0.5201 - val_accuracy: 0.8964 - lr: 6.2500e-05\n",
            "Epoch 87/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0457 - accuracy: 1.0000 - val_loss: 0.4888 - val_accuracy: 0.9000 - lr: 6.2500e-05\n",
            "Epoch 88/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.4871 - val_accuracy: 0.9018 - lr: 6.2500e-05\n",
            "Epoch 89/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.4868 - val_accuracy: 0.9036 - lr: 6.2500e-05\n",
            "Epoch 90/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 0.4856 - val_accuracy: 0.9036 - lr: 6.2500e-05\n",
            "54/54 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "   Class A  Class B  Class C  Class D\n",
            "0      334       12       13       21\n",
            "1       18      283       14        7\n",
            "2       26       19      471       20\n",
            "3       14        4        7      455\n",
            "\n",
            "Metrics:\n",
            "     Class  Precision  Recall  F1 Score  Accuracy\n",
            "0  Class 0      0.852   0.879     0.865     0.898\n",
            "1  Class 1      0.890   0.879     0.884     0.898\n",
            "2  Class 2      0.933   0.879     0.905     0.898\n",
            "3  Class 3      0.905   0.948     0.926     0.898\n",
            "Model: \"sequential_54\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_196 (Conv1D)         (None, 257, 64)           5184      \n",
            "                                                                 \n",
            " batch_normalization_196 (Ba  (None, 257, 64)          256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_196 (MaxPooli  (None, 64, 64)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_197 (Conv1D)         (None, 64, 128)           24704     \n",
            "                                                                 \n",
            " batch_normalization_197 (Ba  (None, 64, 128)          512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_197 (MaxPooli  (None, 16, 128)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_198 (Conv1D)         (None, 16, 256)           98560     \n",
            "                                                                 \n",
            " batch_normalization_198 (Ba  (None, 16, 256)          1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_198 (MaxPooli  (None, 4, 256)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_199 (Conv1D)         (None, 4, 512)            393728    \n",
            "                                                                 \n",
            " batch_normalization_199 (Ba  (None, 4, 512)           2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_199 (MaxPooli  (None, 1, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_100 (Dense)           (None, 1, 16)             8208      \n",
            "                                                                 \n",
            " lambda_50 (Lambda)          (None, 16)                0         \n",
            "                                                                 \n",
            " dense_101 (Dense)           (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 534,292\n",
            "Trainable params: 532,372\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/90\n",
            "35/35 [==============================] - 5s 20ms/step - loss: 1.2562 - accuracy: 0.4912 - val_loss: 1.9238 - val_accuracy: 0.2927 - lr: 0.0010\n",
            "Epoch 2/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.7996 - accuracy: 0.7105 - val_loss: 2.3721 - val_accuracy: 0.2927 - lr: 0.0010\n",
            "Epoch 3/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.6259 - accuracy: 0.7917 - val_loss: 2.7523 - val_accuracy: 0.2927 - lr: 0.0010\n",
            "Epoch 4/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.5106 - accuracy: 0.8372 - val_loss: 2.6298 - val_accuracy: 0.2927 - lr: 0.0010\n",
            "Epoch 5/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.3645 - accuracy: 0.8849 - val_loss: 2.3431 - val_accuracy: 0.2445 - lr: 0.0010\n",
            "Epoch 6/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.3159 - accuracy: 0.9122 - val_loss: 2.0576 - val_accuracy: 0.2491 - lr: 0.0010\n",
            "Epoch 7/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.2837 - accuracy: 0.9222 - val_loss: 1.9421 - val_accuracy: 0.2464 - lr: 0.0010\n",
            "Epoch 8/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.2258 - accuracy: 0.9454 - val_loss: 1.8733 - val_accuracy: 0.2627 - lr: 0.0010\n",
            "Epoch 9/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.2000 - accuracy: 0.9504 - val_loss: 1.7816 - val_accuracy: 0.3445 - lr: 0.0010\n",
            "Epoch 10/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1645 - accuracy: 0.9673 - val_loss: 1.5127 - val_accuracy: 0.2855 - lr: 0.0010\n",
            "Epoch 11/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1885 - accuracy: 0.9559 - val_loss: 1.3183 - val_accuracy: 0.4018 - lr: 0.0010\n",
            "Epoch 12/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1623 - accuracy: 0.9659 - val_loss: 1.2696 - val_accuracy: 0.5218 - lr: 0.0010\n",
            "Epoch 13/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1388 - accuracy: 0.9748 - val_loss: 1.3400 - val_accuracy: 0.4236 - lr: 0.0010\n",
            "Epoch 14/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1214 - accuracy: 0.9804 - val_loss: 1.6034 - val_accuracy: 0.3155 - lr: 0.0010\n",
            "Epoch 15/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1232 - accuracy: 0.9807 - val_loss: 1.1857 - val_accuracy: 0.5845 - lr: 0.0010\n",
            "Epoch 16/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1147 - accuracy: 0.9836 - val_loss: 1.5454 - val_accuracy: 0.6664 - lr: 0.0010\n",
            "Epoch 17/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1036 - accuracy: 0.9870 - val_loss: 1.2963 - val_accuracy: 0.6064 - lr: 0.0010\n",
            "Epoch 18/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1007 - accuracy: 0.9884 - val_loss: 0.8764 - val_accuracy: 0.7336 - lr: 0.0010\n",
            "Epoch 19/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0979 - accuracy: 0.9886 - val_loss: 1.4759 - val_accuracy: 0.6318 - lr: 0.0010\n",
            "Epoch 20/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0956 - accuracy: 0.9902 - val_loss: 1.0082 - val_accuracy: 0.7491 - lr: 0.0010\n",
            "Epoch 21/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0943 - accuracy: 0.9916 - val_loss: 1.1275 - val_accuracy: 0.7609 - lr: 0.0010\n",
            "Epoch 22/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1140 - accuracy: 0.9825 - val_loss: 0.8969 - val_accuracy: 0.7773 - lr: 0.0010\n",
            "Epoch 23/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1380 - accuracy: 0.9750 - val_loss: 0.9925 - val_accuracy: 0.7973 - lr: 0.0010\n",
            "Epoch 24/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1328 - accuracy: 0.9750 - val_loss: 0.8663 - val_accuracy: 0.7809 - lr: 0.0010\n",
            "Epoch 25/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1301 - accuracy: 0.9773 - val_loss: 0.7043 - val_accuracy: 0.8455 - lr: 0.0010\n",
            "Epoch 26/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1022 - accuracy: 0.9877 - val_loss: 0.9227 - val_accuracy: 0.7991 - lr: 0.0010\n",
            "Epoch 27/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1020 - accuracy: 0.9879 - val_loss: 3.6218 - val_accuracy: 0.5782 - lr: 0.0010\n",
            "Epoch 28/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0989 - accuracy: 0.9891 - val_loss: 1.4601 - val_accuracy: 0.7455 - lr: 0.0010\n",
            "Epoch 29/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0963 - accuracy: 0.9902 - val_loss: 1.4527 - val_accuracy: 0.7509 - lr: 0.0010\n",
            "Epoch 30/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1000 - accuracy: 0.9886 - val_loss: 2.8986 - val_accuracy: 0.5964 - lr: 0.0010\n",
            "Epoch 31/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0865 - accuracy: 0.9927 - val_loss: 1.2602 - val_accuracy: 0.7455 - lr: 0.0010\n",
            "Epoch 32/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0802 - accuracy: 0.9941 - val_loss: 0.7931 - val_accuracy: 0.8300 - lr: 0.0010\n",
            "Epoch 33/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0829 - accuracy: 0.9925 - val_loss: 0.5654 - val_accuracy: 0.8700 - lr: 0.0010\n",
            "Epoch 34/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0780 - accuracy: 0.9945 - val_loss: 0.6841 - val_accuracy: 0.8664 - lr: 0.0010\n",
            "Epoch 35/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0792 - accuracy: 0.9948 - val_loss: 0.7017 - val_accuracy: 0.8536 - lr: 0.0010\n",
            "Epoch 36/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0803 - accuracy: 0.9939 - val_loss: 1.2581 - val_accuracy: 0.7882 - lr: 0.0010\n",
            "Epoch 37/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0771 - accuracy: 0.9943 - val_loss: 0.8531 - val_accuracy: 0.8655 - lr: 0.0010\n",
            "Epoch 38/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0789 - accuracy: 0.9939 - val_loss: 1.3167 - val_accuracy: 0.7555 - lr: 0.0010\n",
            "Epoch 39/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0882 - accuracy: 0.9902 - val_loss: 1.1174 - val_accuracy: 0.7755 - lr: 0.0010\n",
            "Epoch 40/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0950 - accuracy: 0.9884 - val_loss: 0.9206 - val_accuracy: 0.8427 - lr: 0.0010\n",
            "Epoch 41/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0950 - accuracy: 0.9884 - val_loss: 1.1405 - val_accuracy: 0.8082 - lr: 0.0010\n",
            "Epoch 42/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1142 - accuracy: 0.9839 - val_loss: 1.0723 - val_accuracy: 0.8073 - lr: 0.0010\n",
            "Epoch 43/90\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0918 - accuracy: 0.9900\n",
            "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0904 - accuracy: 0.9907 - val_loss: 0.9322 - val_accuracy: 0.8509 - lr: 0.0010\n",
            "Epoch 44/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0756 - accuracy: 0.9955 - val_loss: 0.6143 - val_accuracy: 0.8755 - lr: 5.0000e-04\n",
            "Epoch 45/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0666 - accuracy: 0.9991 - val_loss: 0.4970 - val_accuracy: 0.8918 - lr: 5.0000e-04\n",
            "Epoch 46/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0649 - accuracy: 0.9995 - val_loss: 0.4696 - val_accuracy: 0.9018 - lr: 5.0000e-04\n",
            "Epoch 47/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0633 - accuracy: 0.9995 - val_loss: 0.4354 - val_accuracy: 0.9136 - lr: 5.0000e-04\n",
            "Epoch 48/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0623 - accuracy: 0.9998 - val_loss: 0.4290 - val_accuracy: 0.9155 - lr: 5.0000e-04\n",
            "Epoch 49/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.4150 - val_accuracy: 0.9200 - lr: 5.0000e-04\n",
            "Epoch 50/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0613 - accuracy: 0.9995 - val_loss: 0.4649 - val_accuracy: 0.9100 - lr: 5.0000e-04\n",
            "Epoch 51/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0612 - accuracy: 0.9993 - val_loss: 0.4555 - val_accuracy: 0.9055 - lr: 5.0000e-04\n",
            "Epoch 52/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0613 - accuracy: 0.9989 - val_loss: 0.5039 - val_accuracy: 0.8964 - lr: 5.0000e-04\n",
            "Epoch 53/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0717 - accuracy: 0.9970 - val_loss: 0.5614 - val_accuracy: 0.9045 - lr: 5.0000e-04\n",
            "Epoch 54/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0641 - accuracy: 0.9986 - val_loss: 0.5365 - val_accuracy: 0.9036 - lr: 5.0000e-04\n",
            "Epoch 55/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0604 - accuracy: 0.9991 - val_loss: 0.5525 - val_accuracy: 0.9082 - lr: 5.0000e-04\n",
            "Epoch 56/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0598 - accuracy: 0.9993 - val_loss: 0.4585 - val_accuracy: 0.9064 - lr: 5.0000e-04\n",
            "Epoch 57/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0579 - accuracy: 1.0000 - val_loss: 0.4498 - val_accuracy: 0.9064 - lr: 5.0000e-04\n",
            "Epoch 58/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0572 - accuracy: 1.0000 - val_loss: 0.4480 - val_accuracy: 0.9045 - lr: 5.0000e-04\n",
            "Epoch 59/90\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0567 - accuracy: 1.0000\n",
            "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0567 - accuracy: 1.0000 - val_loss: 0.4500 - val_accuracy: 0.9073 - lr: 5.0000e-04\n",
            "Epoch 60/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0563 - accuracy: 1.0000 - val_loss: 0.4535 - val_accuracy: 0.9082 - lr: 2.5000e-04\n",
            "Epoch 61/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0561 - accuracy: 1.0000 - val_loss: 0.4577 - val_accuracy: 0.9073 - lr: 2.5000e-04\n",
            "Epoch 62/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0559 - accuracy: 1.0000 - val_loss: 0.4548 - val_accuracy: 0.9109 - lr: 2.5000e-04\n",
            "Epoch 63/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 0.4570 - val_accuracy: 0.9109 - lr: 2.5000e-04\n",
            "Epoch 64/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.4584 - val_accuracy: 0.9109 - lr: 2.5000e-04\n",
            "Epoch 65/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.4598 - val_accuracy: 0.9109 - lr: 2.5000e-04\n",
            "Epoch 66/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.4596 - val_accuracy: 0.9109 - lr: 2.5000e-04\n",
            "Epoch 67/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0547 - accuracy: 1.0000 - val_loss: 0.4600 - val_accuracy: 0.9100 - lr: 2.5000e-04\n",
            "Epoch 68/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.4610 - val_accuracy: 0.9055 - lr: 2.5000e-04\n",
            "Epoch 69/90\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0542 - accuracy: 1.0000\n",
            "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0542 - accuracy: 1.0000 - val_loss: 0.4626 - val_accuracy: 0.9064 - lr: 2.5000e-04\n",
            "Epoch 70/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0541 - accuracy: 1.0000 - val_loss: 0.4635 - val_accuracy: 0.9055 - lr: 1.2500e-04\n",
            "Epoch 71/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0539 - accuracy: 1.0000 - val_loss: 0.4644 - val_accuracy: 0.9055 - lr: 1.2500e-04\n",
            "Epoch 72/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0538 - accuracy: 1.0000 - val_loss: 0.4657 - val_accuracy: 0.9064 - lr: 1.2500e-04\n",
            "Epoch 73/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.4649 - val_accuracy: 0.9064 - lr: 1.2500e-04\n",
            "Epoch 74/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 0.4654 - val_accuracy: 0.9073 - lr: 1.2500e-04\n",
            "Epoch 75/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.4655 - val_accuracy: 0.9073 - lr: 1.2500e-04\n",
            "Epoch 76/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0533 - accuracy: 1.0000 - val_loss: 0.4648 - val_accuracy: 0.9100 - lr: 1.2500e-04\n",
            "Epoch 77/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0532 - accuracy: 1.0000 - val_loss: 0.4657 - val_accuracy: 0.9091 - lr: 1.2500e-04\n",
            "Epoch 78/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 0.4642 - val_accuracy: 0.9109 - lr: 1.2500e-04\n",
            "Epoch 79/90\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.0529 - accuracy: 1.0000\n",
            "Epoch 79: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 0.4646 - val_accuracy: 0.9118 - lr: 1.2500e-04\n",
            "Epoch 80/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.4660 - val_accuracy: 0.9091 - lr: 6.2500e-05\n",
            "Epoch 81/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0527 - accuracy: 1.0000 - val_loss: 0.4666 - val_accuracy: 0.9091 - lr: 6.2500e-05\n",
            "Epoch 82/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 0.4669 - val_accuracy: 0.9091 - lr: 6.2500e-05\n",
            "Epoch 83/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 0.4675 - val_accuracy: 0.9100 - lr: 6.2500e-05\n",
            "Epoch 84/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 0.4677 - val_accuracy: 0.9091 - lr: 6.2500e-05\n",
            "Epoch 85/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0524 - accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.9082 - lr: 6.2500e-05\n",
            "Epoch 86/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0523 - accuracy: 1.0000 - val_loss: 0.4689 - val_accuracy: 0.9082 - lr: 6.2500e-05\n",
            "Epoch 87/90\n",
            "35/35 [==============================] - 0s 12ms/step - loss: 0.0522 - accuracy: 1.0000 - val_loss: 0.4690 - val_accuracy: 0.9064 - lr: 6.2500e-05\n",
            "Epoch 88/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.4687 - val_accuracy: 0.9064 - lr: 6.2500e-05\n",
            "Epoch 89/90\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0521 - accuracy: 1.0000\n",
            "Epoch 89: ReduceLROnPlateau reducing learning rate to 5e-05.\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.4693 - val_accuracy: 0.9064 - lr: 6.2500e-05\n",
            "Epoch 90/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 0.4696 - val_accuracy: 0.9073 - lr: 5.0000e-05\n",
            "54/54 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "   Class A  Class B  Class C  Class D\n",
            "0      358        9       17       11\n",
            "1        3      265       23       10\n",
            "2       15       17      500       17\n",
            "3       11        4       12      446\n",
            "\n",
            "Metrics:\n",
            "     Class  Precision  Recall  F1 Score  Accuracy\n",
            "0  Class 0      0.925   0.906     0.916     0.913\n",
            "1  Class 1      0.898   0.880     0.889     0.913\n",
            "2  Class 2      0.906   0.911     0.908     0.913\n",
            "3  Class 3      0.921   0.943     0.932     0.913\n",
            "Model: \"sequential_55\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_200 (Conv1D)         (None, 257, 64)           5184      \n",
            "                                                                 \n",
            " batch_normalization_200 (Ba  (None, 257, 64)          256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_200 (MaxPooli  (None, 64, 64)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_201 (Conv1D)         (None, 64, 128)           24704     \n",
            "                                                                 \n",
            " batch_normalization_201 (Ba  (None, 64, 128)          512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_201 (MaxPooli  (None, 16, 128)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_202 (Conv1D)         (None, 16, 256)           98560     \n",
            "                                                                 \n",
            " batch_normalization_202 (Ba  (None, 16, 256)          1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_202 (MaxPooli  (None, 4, 256)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_203 (Conv1D)         (None, 4, 512)            393728    \n",
            "                                                                 \n",
            " batch_normalization_203 (Ba  (None, 4, 512)           2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_203 (MaxPooli  (None, 1, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_102 (Dense)           (None, 1, 16)             8208      \n",
            "                                                                 \n",
            " lambda_51 (Lambda)          (None, 16)                0         \n",
            "                                                                 \n",
            " dense_103 (Dense)           (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 534,292\n",
            "Trainable params: 532,372\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/90\n",
            "35/35 [==============================] - 5s 19ms/step - loss: 1.0939 - accuracy: 0.5793 - val_loss: 1.5653 - val_accuracy: 0.1618 - lr: 0.0010\n",
            "Epoch 2/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.6921 - accuracy: 0.7598 - val_loss: 1.7303 - val_accuracy: 0.2982 - lr: 0.0010\n",
            "Epoch 3/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.5209 - accuracy: 0.8285 - val_loss: 1.8216 - val_accuracy: 0.2991 - lr: 0.0010\n",
            "Epoch 4/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.3793 - accuracy: 0.8838 - val_loss: 1.8941 - val_accuracy: 0.1682 - lr: 0.0010\n",
            "Epoch 5/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.2754 - accuracy: 0.9254 - val_loss: 1.9907 - val_accuracy: 0.1618 - lr: 0.0010\n",
            "Epoch 6/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.2117 - accuracy: 0.9472 - val_loss: 2.2007 - val_accuracy: 0.3027 - lr: 0.0010\n",
            "Epoch 7/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.2224 - accuracy: 0.9420 - val_loss: 2.0770 - val_accuracy: 0.3118 - lr: 0.0010\n",
            "Epoch 8/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.2025 - accuracy: 0.9529 - val_loss: 1.8937 - val_accuracy: 0.3064 - lr: 0.0010\n",
            "Epoch 9/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1717 - accuracy: 0.9629 - val_loss: 2.3400 - val_accuracy: 0.3000 - lr: 0.0010\n",
            "Epoch 10/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1490 - accuracy: 0.9702 - val_loss: 2.1889 - val_accuracy: 0.3064 - lr: 0.0010\n",
            "Epoch 11/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1268 - accuracy: 0.9795 - val_loss: 1.7272 - val_accuracy: 0.3345 - lr: 0.0010\n",
            "Epoch 12/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1227 - accuracy: 0.9811 - val_loss: 1.5292 - val_accuracy: 0.4809 - lr: 0.0010\n",
            "Epoch 13/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1168 - accuracy: 0.9825 - val_loss: 1.6529 - val_accuracy: 0.4264 - lr: 0.0010\n",
            "Epoch 14/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0980 - accuracy: 0.9902 - val_loss: 0.9462 - val_accuracy: 0.6318 - lr: 0.0010\n",
            "Epoch 15/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0899 - accuracy: 0.9934 - val_loss: 0.8895 - val_accuracy: 0.6755 - lr: 0.0010\n",
            "Epoch 16/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0876 - accuracy: 0.9929 - val_loss: 1.1823 - val_accuracy: 0.5591 - lr: 0.0010\n",
            "Epoch 17/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0927 - accuracy: 0.9898 - val_loss: 0.9067 - val_accuracy: 0.6873 - lr: 0.0010\n",
            "Epoch 18/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0901 - accuracy: 0.9909 - val_loss: 0.7548 - val_accuracy: 0.7827 - lr: 0.0010\n",
            "Epoch 19/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1113 - accuracy: 0.9839 - val_loss: 0.7291 - val_accuracy: 0.7882 - lr: 0.0010\n",
            "Epoch 20/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1164 - accuracy: 0.9829 - val_loss: 0.4911 - val_accuracy: 0.8655 - lr: 0.0010\n",
            "Epoch 21/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1236 - accuracy: 0.9807 - val_loss: 0.8235 - val_accuracy: 0.8127 - lr: 0.0010\n",
            "Epoch 22/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1323 - accuracy: 0.9773 - val_loss: 0.8063 - val_accuracy: 0.7864 - lr: 0.0010\n",
            "Epoch 23/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1186 - accuracy: 0.9816 - val_loss: 0.9678 - val_accuracy: 0.7582 - lr: 0.0010\n",
            "Epoch 24/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1126 - accuracy: 0.9818 - val_loss: 0.7826 - val_accuracy: 0.7982 - lr: 0.0010\n",
            "Epoch 25/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0987 - accuracy: 0.9898 - val_loss: 0.8197 - val_accuracy: 0.7936 - lr: 0.0010\n",
            "Epoch 26/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0936 - accuracy: 0.9904 - val_loss: 0.9090 - val_accuracy: 0.7645 - lr: 0.0010\n",
            "Epoch 27/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1056 - accuracy: 0.9861 - val_loss: 0.8689 - val_accuracy: 0.7982 - lr: 0.0010\n",
            "Epoch 28/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0951 - accuracy: 0.9895 - val_loss: 1.1570 - val_accuracy: 0.7545 - lr: 0.0010\n",
            "Epoch 29/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0890 - accuracy: 0.9927 - val_loss: 1.0921 - val_accuracy: 0.7373 - lr: 0.0010\n",
            "Epoch 30/90\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0910 - accuracy: 0.9922\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0907 - accuracy: 0.9920 - val_loss: 1.0161 - val_accuracy: 0.7482 - lr: 0.0010\n",
            "Epoch 31/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0751 - accuracy: 0.9964 - val_loss: 0.6461 - val_accuracy: 0.8536 - lr: 5.0000e-04\n",
            "Epoch 32/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0687 - accuracy: 0.9984 - val_loss: 0.3394 - val_accuracy: 0.9236 - lr: 5.0000e-04\n",
            "Epoch 33/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0689 - accuracy: 0.9984 - val_loss: 0.4026 - val_accuracy: 0.9073 - lr: 5.0000e-04\n",
            "Epoch 34/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0647 - accuracy: 0.9995 - val_loss: 0.4538 - val_accuracy: 0.8936 - lr: 5.0000e-04\n",
            "Epoch 35/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0635 - accuracy: 0.9995 - val_loss: 0.4103 - val_accuracy: 0.9100 - lr: 5.0000e-04\n",
            "Epoch 36/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0630 - accuracy: 1.0000 - val_loss: 0.3331 - val_accuracy: 0.9227 - lr: 5.0000e-04\n",
            "Epoch 37/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0623 - accuracy: 1.0000 - val_loss: 0.3631 - val_accuracy: 0.9164 - lr: 5.0000e-04\n",
            "Epoch 38/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0616 - accuracy: 1.0000 - val_loss: 0.3423 - val_accuracy: 0.9227 - lr: 5.0000e-04\n",
            "Epoch 39/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0610 - accuracy: 1.0000 - val_loss: 0.3320 - val_accuracy: 0.9209 - lr: 5.0000e-04\n",
            "Epoch 40/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0605 - accuracy: 1.0000 - val_loss: 0.3402 - val_accuracy: 0.9218 - lr: 5.0000e-04\n",
            "Epoch 41/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.3236 - val_accuracy: 0.9264 - lr: 5.0000e-04\n",
            "Epoch 42/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.3392 - val_accuracy: 0.9245 - lr: 5.0000e-04\n",
            "Epoch 43/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.3297 - val_accuracy: 0.9282 - lr: 5.0000e-04\n",
            "Epoch 44/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.3309 - val_accuracy: 0.9264 - lr: 5.0000e-04\n",
            "Epoch 45/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0582 - accuracy: 1.0000 - val_loss: 0.3300 - val_accuracy: 0.9264 - lr: 5.0000e-04\n",
            "Epoch 46/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.3281 - val_accuracy: 0.9273 - lr: 5.0000e-04\n",
            "Epoch 47/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 0.3235 - val_accuracy: 0.9273 - lr: 5.0000e-04\n",
            "Epoch 48/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.3262 - val_accuracy: 0.9264 - lr: 5.0000e-04\n",
            "Epoch 49/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0563 - accuracy: 1.0000 - val_loss: 0.3271 - val_accuracy: 0.9273 - lr: 5.0000e-04\n",
            "Epoch 50/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0559 - accuracy: 1.0000 - val_loss: 0.3254 - val_accuracy: 0.9273 - lr: 5.0000e-04\n",
            "Epoch 51/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.3438 - val_accuracy: 0.9191 - lr: 5.0000e-04\n",
            "Epoch 52/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.3338 - val_accuracy: 0.9255 - lr: 5.0000e-04\n",
            "Epoch 53/90\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.0545 - accuracy: 1.0000\n",
            "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.3339 - val_accuracy: 0.9282 - lr: 5.0000e-04\n",
            "Epoch 54/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0541 - accuracy: 1.0000 - val_loss: 0.3349 - val_accuracy: 0.9300 - lr: 2.5000e-04\n",
            "Epoch 55/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0538 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.9273 - lr: 2.5000e-04\n",
            "Epoch 56/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0536 - accuracy: 1.0000 - val_loss: 0.3333 - val_accuracy: 0.9273 - lr: 2.5000e-04\n",
            "Epoch 57/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.3319 - val_accuracy: 0.9264 - lr: 2.5000e-04\n",
            "Epoch 58/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0531 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.9273 - lr: 2.5000e-04\n",
            "Epoch 59/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 0.3340 - val_accuracy: 0.9264 - lr: 2.5000e-04\n",
            "Epoch 60/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 0.3346 - val_accuracy: 0.9264 - lr: 2.5000e-04\n",
            "Epoch 61/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0524 - accuracy: 1.0000 - val_loss: 0.3353 - val_accuracy: 0.9264 - lr: 2.5000e-04\n",
            "Epoch 62/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.3338 - val_accuracy: 0.9273 - lr: 2.5000e-04\n",
            "Epoch 63/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0518 - accuracy: 1.0000 - val_loss: 0.3343 - val_accuracy: 0.9264 - lr: 2.5000e-04\n",
            "Epoch 64/90\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0516 - accuracy: 1.0000\n",
            "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0516 - accuracy: 1.0000 - val_loss: 0.3352 - val_accuracy: 0.9245 - lr: 2.5000e-04\n",
            "Epoch 65/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 0.3340 - val_accuracy: 0.9264 - lr: 1.2500e-04\n",
            "Epoch 66/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.9264 - lr: 1.2500e-04\n",
            "Epoch 67/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.3350 - val_accuracy: 0.9282 - lr: 1.2500e-04\n",
            "Epoch 68/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.3349 - val_accuracy: 0.9245 - lr: 1.2500e-04\n",
            "Epoch 69/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 0.3413 - val_accuracy: 0.9255 - lr: 1.2500e-04\n",
            "Epoch 70/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0507 - accuracy: 1.0000 - val_loss: 0.3385 - val_accuracy: 0.9282 - lr: 1.2500e-04\n",
            "Epoch 71/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0505 - accuracy: 1.0000 - val_loss: 0.3368 - val_accuracy: 0.9264 - lr: 1.2500e-04\n",
            "Epoch 72/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0504 - accuracy: 1.0000 - val_loss: 0.3360 - val_accuracy: 0.9264 - lr: 1.2500e-04\n",
            "Epoch 73/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0502 - accuracy: 1.0000 - val_loss: 0.3351 - val_accuracy: 0.9282 - lr: 1.2500e-04\n",
            "Epoch 74/90\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0501 - accuracy: 1.0000\n",
            "Epoch 74: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0501 - accuracy: 1.0000 - val_loss: 0.3352 - val_accuracy: 0.9264 - lr: 1.2500e-04\n",
            "Epoch 75/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.3352 - val_accuracy: 0.9264 - lr: 6.2500e-05\n",
            "Epoch 76/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0499 - accuracy: 1.0000 - val_loss: 0.3351 - val_accuracy: 0.9273 - lr: 6.2500e-05\n",
            "Epoch 77/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0498 - accuracy: 1.0000 - val_loss: 0.3349 - val_accuracy: 0.9264 - lr: 6.2500e-05\n",
            "Epoch 78/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0497 - accuracy: 1.0000 - val_loss: 0.3353 - val_accuracy: 0.9255 - lr: 6.2500e-05\n",
            "Epoch 79/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0497 - accuracy: 1.0000 - val_loss: 0.3353 - val_accuracy: 0.9255 - lr: 6.2500e-05\n",
            "Epoch 80/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.3356 - val_accuracy: 0.9264 - lr: 6.2500e-05\n",
            "Epoch 81/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.3349 - val_accuracy: 0.9245 - lr: 6.2500e-05\n",
            "Epoch 82/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 0.3352 - val_accuracy: 0.9236 - lr: 6.2500e-05\n",
            "Epoch 83/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0493 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.9218 - lr: 6.2500e-05\n",
            "Epoch 84/90\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0493 - accuracy: 1.0000\n",
            "Epoch 84: ReduceLROnPlateau reducing learning rate to 5e-05.\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0493 - accuracy: 1.0000 - val_loss: 0.3348 - val_accuracy: 0.9245 - lr: 6.2500e-05\n",
            "Epoch 85/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.3346 - val_accuracy: 0.9245 - lr: 5.0000e-05\n",
            "Epoch 86/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0491 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.9245 - lr: 5.0000e-05\n",
            "Epoch 87/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 0.3349 - val_accuracy: 0.9245 - lr: 5.0000e-05\n",
            "Epoch 88/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0489 - accuracy: 1.0000 - val_loss: 0.3353 - val_accuracy: 0.9245 - lr: 5.0000e-05\n",
            "Epoch 89/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0489 - accuracy: 1.0000 - val_loss: 0.3363 - val_accuracy: 0.9245 - lr: 5.0000e-05\n",
            "Epoch 90/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0488 - accuracy: 1.0000 - val_loss: 0.3394 - val_accuracy: 0.9264 - lr: 5.0000e-05\n",
            "54/54 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "   Class A  Class B  Class C  Class D\n",
            "0      352        6       10       15\n",
            "1        7      269       23       12\n",
            "2       24       18      490       22\n",
            "3       10        2        7      451\n",
            "\n",
            "Metrics:\n",
            "     Class  Precision  Recall  F1 Score  Accuracy\n",
            "0  Class 0      0.896   0.919     0.907     0.909\n",
            "1  Class 1      0.912   0.865     0.888     0.909\n",
            "2  Class 2      0.925   0.884     0.904     0.909\n",
            "3  Class 3      0.902   0.960     0.930     0.909\n"
          ]
        }
      ],
      "source": [
        "#@title 5.2 Test results extraction\n",
        "\n",
        "# Metric activator\n",
        "raw = 0\n",
        "mfcc = 0\n",
        "psd = 1\n",
        "\n",
        "\n",
        "metrics_raw1 = []\n",
        "metrics_mfcc1 = []\n",
        "metrics_psd1 = []\n",
        "matrix_raw = []\n",
        "matrix_mfcc = []\n",
        "matrix_psd = []\n",
        "val = 1\n",
        "data = ['data5.pkl','data2.pkl','data3.pkl','data4.pkl','data1.pkl']\n",
        "\n",
        "for d in data:\n",
        "  X_train, X_test, X_val, y_train, y_test, y_val = dataload(d)\n",
        "\n",
        "  if raw == 1:\n",
        "  # Get raw data\n",
        "    metrics, matrix = get_CNN_raw(val)\n",
        "    metrics_raw1.append(metrics)\n",
        "    matrix_raw.append(matrix)\n",
        "  if mfcc == 1:\n",
        "  # Get mfcc data\n",
        "    mfcc_train, mfcc_val, mfcc_test = get_mfcc()\n",
        "    metrics1, matrix1 = get_CNN_mfcc(val)\n",
        "    metrics_mfcc1.append(metrics1)\n",
        "    matrix_mfcc.append(matrix1)\n",
        " # Get psd data\n",
        "  if psd == 1:\n",
        "    psd_train, psd_val, psd_test = get_psd()\n",
        "    metrics2, matrix2 = get_CNN_psd(val)\n",
        "    metrics_psd1.append(metrics2)\n",
        "    matrix_psd.append(matrix2)\n",
        "  val = val + 1\n",
        "\n",
        "pd.options.display.float_format = '{:.3f}'.format\n",
        "\n",
        "if raw == 1:\n",
        "  metrics_raw = metrics_avg_var(metrics_raw1)\n",
        "if mfcc == 1:\n",
        "  metrics_mfcc = metrics_avg_var(metrics_mfcc1)\n",
        "if psd == 1:\n",
        "  metrics_psd = metrics_avg_var(metrics_psd1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IFqGTQyyh0_i",
        "outputId": "2b7f1788-0c08-4aa6-acda-fa7ebdb7ac6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class A                           & 0.898                               & (0.028)     & 0.901                         & (0.015)         & 0.899                  & (0.018)                   \\\\ \\rowcolor[HTML]{EFEFEF} Class B                           & 0.906                               & (0.018)      & 0.869                         & (0.021)         & 0.887                  & (0.003)                  \\\\Class C                           & 0.913                               & (0.013)      & 0.896                        & (0.013)         & 0.905                  & (0.002)                  \\\\\n",
            "\\rowcolor[HTML]{EFEFEF} Class D                           & \\highest{0.914}                              & (0.01)      & \\highest{0.954}                         & (0.007)         & \\highest{0.933}                  & (0.006)                 \\\\ \\midrule\\multicolumn{1}{c}{\\textbf{Accuracy($\\sigma$)}} & \\multicolumn{1}{c}{\\textbf{}}       &            & \\multicolumn{1}{l}{}          &               & \\textbf{0.909}         & \\textbf{(0.005)}  \n"
          ]
        }
      ],
      "source": [
        "#@title Print Table\n",
        "\n",
        "def get_number(row,col, metrics):\n",
        " cols = ['Precision','Recall','F1 Score']\n",
        " a = metrics.at[row,col]\n",
        " highest = 0\n",
        " if col in cols:\n",
        "  for value in metrics[col]:\n",
        "    if value > a:\n",
        "      highest = 1\n",
        "  if highest == 0:\n",
        "    a = \"\\highest{\" + str(a) + \"}\"\n",
        " return str(a)\n",
        "\n",
        "def print_table(metrics):\n",
        "\n",
        "#metrics table formatting\n",
        "\n",
        "\n",
        "  columns_to_format = ['Precision',\n",
        "                        'Recall',\n",
        "                        'F1 Score',\n",
        "                          'Accuracy']\n",
        "  metrics[columns_to_format] = metrics[columns_to_format].round(3)\n",
        "  columns_to_format = ['P_std','R_std','F1_std','Acc_std']\n",
        "  metrics[columns_to_format] = metrics[columns_to_format].round(3)\n",
        "\n",
        "\n",
        "  print(\n",
        "  \"Class A                           & \" + get_number(0,'Precision',metrics) + \"                               & (\" + get_number(0,'P_std',metrics) + \")     & \" + get_number(0,'Recall',metrics) + \"                         & (\" + get_number(0,'R_std',metrics) + \")         & \" + get_number(0,'F1 Score',metrics) + \"                  & (\" + get_number(0,'F1_std',metrics) + \")                   \\\\\\\\\"\n",
        "  \" \\\\rowcolor[HTML]{EFEFEF} Class B                           & \" + get_number(1,'Precision',metrics) + \"                               & (\" + get_number(1,'P_std',metrics) + \")      & \" + get_number(1,'Recall',metrics) + \"                         & (\" + get_number(1,'R_std',metrics) + \")         & \" + get_number(1,'F1 Score',metrics) + \"                  & (\" + get_number(1,'F1_std',metrics) + \")                  \\\\\\\\\"\n",
        "  \"Class C                           & \" + get_number(2,'Precision',metrics) + \"                               & (\" + get_number(2,'P_std',metrics) + \")      & \" + get_number(2,'Recall',metrics) + \"                        & (\" + get_number(2,'R_std',metrics) + \")         & \" + get_number(2,'F1 Score',metrics) + \"                  & (\" + get_number(2,'F1_std',metrics) + \")                  \\\\\\\\\")\n",
        "  print(\"\\\\rowcolor[HTML]{EFEFEF} \"\n",
        "  \"Class D                           & \" + get_number(3,'Precision',metrics) + \"                              & (\" + get_number(3,'P_std',metrics) + \")      & \" + get_number(3,'Recall',metrics) + \"                         & (\" + get_number(3,'R_std',metrics) + \")         & \" + get_number(3,'F1 Score',metrics) + \"                  & (\" + get_number(3,'F1_std',metrics) + \")                 \\\\\\\\ \\midrule\"\n",
        "  \"\\\\multicolumn{1}{c}{\\\\textbf{Accuracy($\\sigma$)}} & \\multicolumn{1}{c}{\\\\textbf{}}       &            & \\multicolumn{1}{l}{}          &               & \\\\textbf{\" + get_number(3,'Accuracy',metrics) + \"}         & \\\\textbf{(\" + get_number(2,'Acc_std',metrics) + \")}  \")\n",
        "  return\n",
        "\n",
        "\n",
        "print_table(metrics_psd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2ETw8xXKhUg7",
        "outputId": "c81092f8-a5a5-4432-d1db-6b763c3c5de2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x y C\n",
            "0 0 358\n",
            "1 0 9\n",
            "2 0 17\n",
            "3 0 11\n",
            "0 1 3\n",
            "1 1 265\n",
            "2 1 23\n",
            "3 1 10\n",
            "0 2 15\n",
            "1 2 17\n",
            "2 2 500\n",
            "3 2 17\n",
            "0 3 11\n",
            "1 3 4\n",
            "2 3 12\n",
            "3 3 446\n"
          ]
        }
      ],
      "source": [
        "#@title Print Matrix\n",
        "\n",
        "def get_max_matrix(matrix):\n",
        "  a = 0\n",
        "  pos = 5\n",
        "  tp_max = 0\n",
        "  for m in matrix:\n",
        "    tp = sum(np.diagonal(m))\n",
        "    if tp_max < tp:\n",
        "      tp_max = tp\n",
        "      pos = a\n",
        "    a = a+1\n",
        "  return pos\n",
        "\n",
        "def get_matrix(matrix):\n",
        "  matrix = matrix[get_max_matrix(matrix)]\n",
        "  col = ['Class A','Class B','Class C','Class D']\n",
        "  for i in list(range(4)):\n",
        "    for j in list(range(4)):\n",
        "      print(j,i,matrix.at[i,col[j]])\n",
        "\n",
        "print(\"x y C\")\n",
        "get_matrix(matrix_psd)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NOT INCLUDED IN FDP 3.0 Feature extraction: MFCC (image 15 X 101 pixels)\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "sr = 52734\n",
        "width = 101\n",
        "n_mfcc = 101\n",
        "\n",
        "def create_mfcc(audio_array, sampling_rate, n_mfcc=n_mfcc, n_fft=100, hop_length=50):\n",
        "\n",
        "    # Compute the Short-Time Fourier Transform (STFT)\n",
        "    stft = librosa.stft(audio_array, n_fft=n_fft, hop_length=hop_length)\n",
        "\n",
        "    # Convert magnitude spectrogram to MFCCs\n",
        "    mfccs = librosa.feature.mfcc(S=np.abs(stft)**2, sr=sampling_rate, n_mfcc=n_mfcc)\n",
        "\n",
        "    return mfccs\n",
        "\n",
        "def mfcctoimg(arr, samplerate):\n",
        "  nested = []\n",
        "  sr = samplerate\n",
        "  for x in range(len(arr)):\n",
        "\n",
        "    ad = arr[x].flatten().astype(float)\n",
        "\n",
        "    mfccs = create_mfcc(ad, sr)\n",
        "\n",
        "    # Plot the MFCCs without color bar and set the size to 15 x 21 pixels\n",
        "    plt.figure(figsize=(n_mfcc/100, width/100), dpi=100)\n",
        "    img = librosa.display.specshow(mfccs, x_axis='time', sr=sr, hop_length=512,cmap='gray')\n",
        "    plt.axis('off')  # Turn off axis labels and ticks\n",
        "    plt.tight_layout()\n",
        "    # Ensure the plot is drawn\n",
        "    plt.draw()\n",
        "    plt.show()\n",
        "\n",
        "    # Get the pixel values of the grayscale plot directly\n",
        "    plt_img_gray = img.get_array()\n",
        "\n",
        "     # Normalize the image array (optional but recommended for training deep learning models)\n",
        "    plt_img_gray = plt_img_gray.astype(float) / 255.0\n",
        "\n",
        "    # Add the grayscale image to the list\n",
        "    nested.append(plt_img_gray)\n",
        "\n",
        "    # Close the plot to free up memory\n",
        "    plt.close()\n",
        "  return nested\n",
        "\n",
        "\n",
        "X_train_img = mfcctoimg(X_train,sr)\n",
        "X_val_img = mfcctoimg(X_val,sr)\n",
        "\n",
        "\n",
        "# Convert X_val_img list to a 4D numpy array\n",
        "X_val_img = np.array(X_val_img)\n",
        "\n",
        "# Reshape X_val_img to have the shape (number_of_samples, height, width, channels)\n",
        "X_val_img = X_val_img.reshape(-1, 100, width, 1)\n",
        "\n",
        "# Convert X_train_img list to a 4D numpy array\n",
        "X_train_img = np.array(X_train_img)\n",
        "\n",
        "# Reshape X_train_img to have the shape (number_of_samples, height, width, channels)\n",
        "X_train_img = X_train_img.reshape(-1, 100, width, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "IcrPZRDrrZlw",
        "outputId": "218d5603-1f0d-4914-f5f9-16d15cf2da86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4.0 2D MFCC Convolutional model\n",
        "\n",
        "input_shape=(15,101,1)\n",
        "CNNmodel = models.Sequential()\n",
        "CNNmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "CNNmodel.add(layers.MaxPooling2D((2, 2)))\n",
        "CNNmodel.add(layers.Dropout(0.2))\n",
        "CNNmodel.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "CNNmodel.add(layers.MaxPooling2D((2, 2)))\n",
        "CNNmodel.add(layers.Dropout(0.2))\n",
        "CNNmodel.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "CNNmodel.add(layers.Flatten())\n",
        "CNNmodel.add(layers.Dense(32, activation='relu'))\n",
        "CNNmodel.add(layers.Dense(4, activation='softmax'))\n",
        "\n",
        "CNNmodel.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "SsCLRm4iEuXP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "88d4f780-f847-4986-9faa-60bade5fb44f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-e592fbb3e36f>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mCNNmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mCNNmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mCNNmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mCNNmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mCNNmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/trackable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[1;32m   1971\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1973\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m   \u001b[0;31m# Record the current Python stack trace as the creating stacktrace of this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"conv2d_2\" (type Conv2D).\n\nNegative dimension size caused by subtracting 3 from 2 for '{{node conv2d_2/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_2/Conv2D/ReadVariableOp)' with input shapes: [?,2,23,32], [3,3,32,32].\n\nCall arguments received by layer \"conv2d_2\" (type Conv2D):\n  • inputs=tf.Tensor(shape=(None, 2, 23, 32), dtype=float32)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = CNNmodel.fit(X_train_img, y_train, epochs=20, validation_data= (X_val_img, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "id": "c0mRpSO9-jtc",
        "outputId": "5a71c46d-b623-4e4e-ccd8-a08e541abe60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 5s 20ms/step - loss: nan - accuracy: 0.2230 - val_loss: nan - val_accuracy: 0.2153\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 2s 11ms/step - loss: nan - accuracy: 0.2187 - val_loss: nan - val_accuracy: 0.2153\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 2s 11ms/step - loss: nan - accuracy: 0.2187 - val_loss: nan - val_accuracy: 0.2153\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 2s 11ms/step - loss: nan - accuracy: 0.2187 - val_loss: nan - val_accuracy: 0.2153\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 2s 11ms/step - loss: nan - accuracy: 0.2187 - val_loss: nan - val_accuracy: 0.2153\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 2s 11ms/step - loss: nan - accuracy: 0.2187 - val_loss: nan - val_accuracy: 0.2153\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 3s 17ms/step - loss: nan - accuracy: 0.2187 - val_loss: nan - val_accuracy: 0.2153\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 3s 15ms/step - loss: nan - accuracy: 0.2187 - val_loss: nan - val_accuracy: 0.2153\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 2s 11ms/step - loss: nan - accuracy: 0.2187 - val_loss: nan - val_accuracy: 0.2153\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 2s 11ms/step - loss: nan - accuracy: 0.2187 - val_loss: nan - val_accuracy: 0.2153\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 2s 11ms/step - loss: nan - accuracy: 0.2187 - val_loss: nan - val_accuracy: 0.2153\n",
            "Epoch 12/20\n",
            " 41/172 [======>.......................] - ETA: 1s - loss: nan - accuracy: 0.2111"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-1a1b6777680d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNNmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_val_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, X_val, y_train, y_test, y_val = dataload('data4.pkl')\n",
        "psd_train, psd_val, psd_test = get_psd()\n",
        "m_psd = Sequential()\n",
        "m_psd.add(Conv1D(64,\n",
        "              input_shape=[1025, 1],\n",
        "              kernel_size=80,\n",
        "              strides=4,\n",
        "              padding='same',\n",
        "              kernel_initializer='glorot_uniform',\n",
        "              kernel_regularizer=regularizers.l2(l=0.0001),\n",
        "              activation='relu'))\n",
        "m_psd.add(BatchNormalization())\n",
        "m_psd.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "m_psd.add(Conv1D(128,\n",
        "              kernel_size=3,\n",
        "              strides=1,\n",
        "              padding='same',\n",
        "              kernel_initializer='glorot_uniform',\n",
        "              kernel_regularizer=regularizers.l2(l=0.0001),\n",
        "              activation='relu'))\n",
        "m_psd.add(BatchNormalization())\n",
        "m_psd.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "m_psd.add(Conv1D(256,\n",
        "              kernel_size=3,\n",
        "              strides=1,\n",
        "              padding='same',\n",
        "              kernel_initializer='glorot_uniform',\n",
        "              kernel_regularizer=regularizers.l2(l=0.0001),\n",
        "              activation='relu'))\n",
        "m_psd.add(BatchNormalization())\n",
        "m_psd.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "m_psd.add(Conv1D(512,\n",
        "              kernel_size=3,\n",
        "              strides=1,\n",
        "              padding='same',\n",
        "              kernel_initializer='glorot_uniform',\n",
        "              kernel_regularizer=regularizers.l2(l=0.0001),\n",
        "              activation='relu'))\n",
        "m_psd.add(BatchNormalization())\n",
        "m_psd.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "m_psd.add(Dense(16, activation='relu')) #vlad added\n",
        "m_psd.add(Lambda(lambda x: K.mean(x, axis=1)))  # Same as GAP for 1D Conv Layer\n",
        "m_psd.add(Dense(4, activation='softmax'))\n",
        "m_psd.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "print(m_psd.summary())\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=10, min_lr=0.00005, verbose=1)\n",
        "\n",
        "X_train, X_test, X_val, y_train, y_test, y_val = dataload('data1.pkl')\n",
        "psd_train, psd_val, psd_test = get_psd()\n",
        "m_psd.fit(psd_train, y_train, batch_size = 128, epochs = 90, validation_split=0.2, callbacks = [reduce_lr])\n",
        "\n",
        "y_pred = m_psd.predict(psd_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\n",
        "metrics, matrix = plot_class_acc(y_test,y_pred,'CNN')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S0sPkZIsDrTd",
        "outputId": "5e9e0fb0-0bc0-4a4f-b541-1fa0e2f3f1a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_117 (Conv1D)         (None, 257, 64)           5184      \n",
            "                                                                 \n",
            " batch_normalization_117 (Ba  (None, 257, 64)          256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_117 (MaxPooli  (None, 64, 64)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_118 (Conv1D)         (None, 64, 128)           24704     \n",
            "                                                                 \n",
            " batch_normalization_118 (Ba  (None, 64, 128)          512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_118 (MaxPooli  (None, 16, 128)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_119 (Conv1D)         (None, 16, 256)           98560     \n",
            "                                                                 \n",
            " batch_normalization_119 (Ba  (None, 16, 256)          1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_119 (MaxPooli  (None, 4, 256)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_120 (Conv1D)         (None, 4, 512)            393728    \n",
            "                                                                 \n",
            " batch_normalization_120 (Ba  (None, 4, 512)           2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_120 (MaxPooli  (None, 1, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 1, 16)             8208      \n",
            "                                                                 \n",
            " lambda_29 (Lambda)          (None, 16)                0         \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 534,292\n",
            "Trainable params: 532,372\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/90\n",
            "35/35 [==============================] - 5s 19ms/step - loss: 1.2057 - accuracy: 0.5799 - val_loss: 1.9577 - val_accuracy: 0.1618 - lr: 0.0010\n",
            "Epoch 2/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.6111 - accuracy: 0.7880 - val_loss: 2.8462 - val_accuracy: 0.1618 - lr: 0.0010\n",
            "Epoch 3/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.4969 - accuracy: 0.8299 - val_loss: 3.3528 - val_accuracy: 0.1618 - lr: 0.0010\n",
            "Epoch 4/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.3899 - accuracy: 0.8817 - val_loss: 3.6764 - val_accuracy: 0.1618 - lr: 0.0010\n",
            "Epoch 5/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.3125 - accuracy: 0.9145 - val_loss: 4.0890 - val_accuracy: 0.1618 - lr: 0.0010\n",
            "Epoch 6/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.2334 - accuracy: 0.9365 - val_loss: 4.2995 - val_accuracy: 0.1618 - lr: 0.0010\n",
            "Epoch 7/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.2177 - accuracy: 0.9422 - val_loss: 3.2389 - val_accuracy: 0.1618 - lr: 0.0010\n",
            "Epoch 8/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1897 - accuracy: 0.9552 - val_loss: 3.8636 - val_accuracy: 0.1618 - lr: 0.0010\n",
            "Epoch 9/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1602 - accuracy: 0.9650 - val_loss: 3.9055 - val_accuracy: 0.1618 - lr: 0.0010\n",
            "Epoch 10/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1426 - accuracy: 0.9732 - val_loss: 4.4245 - val_accuracy: 0.1618 - lr: 0.0010\n",
            "Epoch 11/90\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.1375 - accuracy: 0.9756\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1373 - accuracy: 0.9745 - val_loss: 3.8722 - val_accuracy: 0.1618 - lr: 0.0010\n",
            "Epoch 12/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1065 - accuracy: 0.9861 - val_loss: 4.1105 - val_accuracy: 0.1636 - lr: 5.0000e-04\n",
            "Epoch 13/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0846 - accuracy: 0.9939 - val_loss: 3.9380 - val_accuracy: 0.1655 - lr: 5.0000e-04\n",
            "Epoch 14/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0762 - accuracy: 0.9961 - val_loss: 3.8247 - val_accuracy: 0.1818 - lr: 5.0000e-04\n",
            "Epoch 15/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0761 - accuracy: 0.9966 - val_loss: 3.0618 - val_accuracy: 0.2345 - lr: 5.0000e-04\n",
            "Epoch 16/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0858 - accuracy: 0.9925 - val_loss: 2.0028 - val_accuracy: 0.5182 - lr: 5.0000e-04\n",
            "Epoch 17/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0717 - accuracy: 0.9989 - val_loss: 1.5379 - val_accuracy: 0.6200 - lr: 5.0000e-04\n",
            "Epoch 18/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0719 - accuracy: 0.9973 - val_loss: 1.1349 - val_accuracy: 0.6909 - lr: 5.0000e-04\n",
            "Epoch 19/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0688 - accuracy: 0.9980 - val_loss: 0.8273 - val_accuracy: 0.7582 - lr: 5.0000e-04\n",
            "Epoch 20/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0663 - accuracy: 0.9991 - val_loss: 0.6346 - val_accuracy: 0.8109 - lr: 5.0000e-04\n",
            "Epoch 21/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0669 - accuracy: 0.9986 - val_loss: 0.5067 - val_accuracy: 0.8609 - lr: 5.0000e-04\n",
            "Epoch 22/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0673 - accuracy: 0.9984 - val_loss: 0.4239 - val_accuracy: 0.8891 - lr: 5.0000e-04\n",
            "Epoch 23/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0694 - accuracy: 0.9977 - val_loss: 0.3627 - val_accuracy: 0.9082 - lr: 5.0000e-04\n",
            "Epoch 24/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0667 - accuracy: 0.9989 - val_loss: 0.3616 - val_accuracy: 0.9073 - lr: 5.0000e-04\n",
            "Epoch 25/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0697 - accuracy: 0.9970 - val_loss: 0.4214 - val_accuracy: 0.8955 - lr: 5.0000e-04\n",
            "Epoch 26/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0736 - accuracy: 0.9961 - val_loss: 0.3973 - val_accuracy: 0.9036 - lr: 5.0000e-04\n",
            "Epoch 27/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0689 - accuracy: 0.9973 - val_loss: 0.4035 - val_accuracy: 0.9118 - lr: 5.0000e-04\n",
            "Epoch 28/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0719 - accuracy: 0.9964 - val_loss: 0.5059 - val_accuracy: 0.8973 - lr: 5.0000e-04\n",
            "Epoch 29/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0742 - accuracy: 0.9943 - val_loss: 0.5867 - val_accuracy: 0.8736 - lr: 5.0000e-04\n",
            "Epoch 30/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0862 - accuracy: 0.9918 - val_loss: 0.7221 - val_accuracy: 0.8436 - lr: 5.0000e-04\n",
            "Epoch 31/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.1016 - accuracy: 0.9864 - val_loss: 0.8934 - val_accuracy: 0.7936 - lr: 5.0000e-04\n",
            "Epoch 32/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1131 - accuracy: 0.9825 - val_loss: 1.2306 - val_accuracy: 0.7591 - lr: 5.0000e-04\n",
            "Epoch 33/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.1109 - accuracy: 0.9827 - val_loss: 0.8088 - val_accuracy: 0.8245 - lr: 5.0000e-04\n",
            "Epoch 34/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0953 - accuracy: 0.9884 - val_loss: 0.9638 - val_accuracy: 0.7918 - lr: 5.0000e-04\n",
            "Epoch 35/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0745 - accuracy: 0.9961 - val_loss: 0.6075 - val_accuracy: 0.8627 - lr: 5.0000e-04\n",
            "Epoch 36/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0653 - accuracy: 0.9989 - val_loss: 0.6086 - val_accuracy: 0.8518 - lr: 5.0000e-04\n",
            "Epoch 37/90\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0631 - accuracy: 0.9992\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0629 - accuracy: 0.9993 - val_loss: 0.5175 - val_accuracy: 0.8718 - lr: 5.0000e-04\n",
            "Epoch 38/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0610 - accuracy: 0.9993 - val_loss: 0.4077 - val_accuracy: 0.9045 - lr: 2.5000e-04\n",
            "Epoch 39/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.3926 - val_accuracy: 0.9027 - lr: 2.5000e-04\n",
            "Epoch 40/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0596 - accuracy: 0.9998 - val_loss: 0.3882 - val_accuracy: 0.9064 - lr: 2.5000e-04\n",
            "Epoch 41/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0592 - accuracy: 1.0000 - val_loss: 0.3779 - val_accuracy: 0.9091 - lr: 2.5000e-04\n",
            "Epoch 42/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0586 - accuracy: 1.0000 - val_loss: 0.3810 - val_accuracy: 0.9027 - lr: 2.5000e-04\n",
            "Epoch 43/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.3800 - val_accuracy: 0.9073 - lr: 2.5000e-04\n",
            "Epoch 44/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0583 - accuracy: 1.0000 - val_loss: 0.3812 - val_accuracy: 0.9045 - lr: 2.5000e-04\n",
            "Epoch 45/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0580 - accuracy: 0.9998 - val_loss: 0.3824 - val_accuracy: 0.9082 - lr: 2.5000e-04\n",
            "Epoch 46/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.3936 - val_accuracy: 0.9036 - lr: 2.5000e-04\n",
            "Epoch 47/90\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.0574 - accuracy: 1.0000\n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.3840 - val_accuracy: 0.9027 - lr: 2.5000e-04\n",
            "Epoch 48/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 0.3819 - val_accuracy: 0.9055 - lr: 1.2500e-04\n",
            "Epoch 49/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0570 - accuracy: 1.0000 - val_loss: 0.3854 - val_accuracy: 0.9073 - lr: 1.2500e-04\n",
            "Epoch 50/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.3857 - val_accuracy: 0.9064 - lr: 1.2500e-04\n",
            "Epoch 51/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0568 - accuracy: 1.0000 - val_loss: 0.3865 - val_accuracy: 0.9064 - lr: 1.2500e-04\n",
            "Epoch 52/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0567 - accuracy: 1.0000 - val_loss: 0.3857 - val_accuracy: 0.9073 - lr: 1.2500e-04\n",
            "Epoch 53/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 0.3895 - val_accuracy: 0.9073 - lr: 1.2500e-04\n",
            "Epoch 54/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.3897 - val_accuracy: 0.9064 - lr: 1.2500e-04\n",
            "Epoch 55/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.3899 - val_accuracy: 0.9091 - lr: 1.2500e-04\n",
            "Epoch 56/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0561 - accuracy: 1.0000 - val_loss: 0.3898 - val_accuracy: 0.9073 - lr: 1.2500e-04\n",
            "Epoch 57/90\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.0561 - accuracy: 1.0000\n",
            "Epoch 57: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0560 - accuracy: 1.0000 - val_loss: 0.3911 - val_accuracy: 0.9064 - lr: 1.2500e-04\n",
            "Epoch 58/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0559 - accuracy: 1.0000 - val_loss: 0.3904 - val_accuracy: 0.9064 - lr: 6.2500e-05\n",
            "Epoch 59/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0559 - accuracy: 1.0000 - val_loss: 0.3885 - val_accuracy: 0.9064 - lr: 6.2500e-05\n",
            "Epoch 60/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0558 - accuracy: 1.0000 - val_loss: 0.3883 - val_accuracy: 0.9045 - lr: 6.2500e-05\n",
            "Epoch 61/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 0.3886 - val_accuracy: 0.9045 - lr: 6.2500e-05\n",
            "Epoch 62/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0556 - accuracy: 1.0000 - val_loss: 0.3887 - val_accuracy: 0.9036 - lr: 6.2500e-05\n",
            "Epoch 63/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0556 - accuracy: 1.0000 - val_loss: 0.3888 - val_accuracy: 0.9045 - lr: 6.2500e-05\n",
            "Epoch 64/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.3897 - val_accuracy: 0.9055 - lr: 6.2500e-05\n",
            "Epoch 65/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.3890 - val_accuracy: 0.9045 - lr: 6.2500e-05\n",
            "Epoch 66/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.3901 - val_accuracy: 0.9055 - lr: 6.2500e-05\n",
            "Epoch 67/90\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.0553 - accuracy: 1.0000\n",
            "Epoch 67: ReduceLROnPlateau reducing learning rate to 5e-05.\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.3908 - val_accuracy: 0.9045 - lr: 6.2500e-05\n",
            "Epoch 68/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.3912 - val_accuracy: 0.9045 - lr: 5.0000e-05\n",
            "Epoch 69/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0551 - accuracy: 1.0000 - val_loss: 0.3913 - val_accuracy: 0.9045 - lr: 5.0000e-05\n",
            "Epoch 70/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0551 - accuracy: 1.0000 - val_loss: 0.3915 - val_accuracy: 0.9045 - lr: 5.0000e-05\n",
            "Epoch 71/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0550 - accuracy: 1.0000 - val_loss: 0.3927 - val_accuracy: 0.9045 - lr: 5.0000e-05\n",
            "Epoch 72/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.3917 - val_accuracy: 0.9045 - lr: 5.0000e-05\n",
            "Epoch 73/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0548 - accuracy: 1.0000 - val_loss: 0.3914 - val_accuracy: 0.9045 - lr: 5.0000e-05\n",
            "Epoch 74/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0548 - accuracy: 1.0000 - val_loss: 0.3919 - val_accuracy: 0.9045 - lr: 5.0000e-05\n",
            "Epoch 75/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0547 - accuracy: 1.0000 - val_loss: 0.3908 - val_accuracy: 0.9055 - lr: 5.0000e-05\n",
            "Epoch 76/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0547 - accuracy: 1.0000 - val_loss: 0.3911 - val_accuracy: 0.9073 - lr: 5.0000e-05\n",
            "Epoch 77/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0546 - accuracy: 1.0000 - val_loss: 0.3916 - val_accuracy: 0.9064 - lr: 5.0000e-05\n",
            "Epoch 78/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.3923 - val_accuracy: 0.9073 - lr: 5.0000e-05\n",
            "Epoch 79/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0544 - accuracy: 1.0000 - val_loss: 0.3926 - val_accuracy: 0.9073 - lr: 5.0000e-05\n",
            "Epoch 80/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0543 - accuracy: 1.0000 - val_loss: 0.3925 - val_accuracy: 0.9082 - lr: 5.0000e-05\n",
            "Epoch 81/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0543 - accuracy: 1.0000 - val_loss: 0.3927 - val_accuracy: 0.9082 - lr: 5.0000e-05\n",
            "Epoch 82/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0542 - accuracy: 1.0000 - val_loss: 0.3927 - val_accuracy: 0.9055 - lr: 5.0000e-05\n",
            "Epoch 83/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0541 - accuracy: 1.0000 - val_loss: 0.3934 - val_accuracy: 0.9073 - lr: 5.0000e-05\n",
            "Epoch 84/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0541 - accuracy: 1.0000 - val_loss: 0.3948 - val_accuracy: 0.9064 - lr: 5.0000e-05\n",
            "Epoch 85/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0539 - accuracy: 1.0000 - val_loss: 0.3944 - val_accuracy: 0.9064 - lr: 5.0000e-05\n",
            "Epoch 86/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0539 - accuracy: 1.0000 - val_loss: 0.3954 - val_accuracy: 0.9064 - lr: 5.0000e-05\n",
            "Epoch 87/90\n",
            "35/35 [==============================] - 0s 11ms/step - loss: 0.0538 - accuracy: 1.0000 - val_loss: 0.3945 - val_accuracy: 0.9073 - lr: 5.0000e-05\n",
            "Epoch 88/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.3941 - val_accuracy: 0.9073 - lr: 5.0000e-05\n",
            "Epoch 89/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0536 - accuracy: 1.0000 - val_loss: 0.3949 - val_accuracy: 0.9073 - lr: 5.0000e-05\n",
            "Epoch 90/90\n",
            "35/35 [==============================] - 0s 10ms/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 0.3962 - val_accuracy: 0.9073 - lr: 5.0000e-05\n",
            "54/54 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "   Class A  Class B  Class C  Class D\n",
            "0      340        5       19       19\n",
            "1       15      257       31        8\n",
            "2       26       15      491       22\n",
            "3       10        1       16      443\n",
            "\n",
            "Metrics:\n",
            "     Class  Precision  Recall  F1 Score  Accuracy\n",
            "0  Class 0      0.870   0.888     0.879     0.891\n",
            "1  Class 1      0.924   0.826     0.873     0.891\n",
            "2  Class 2      0.882   0.886     0.884     0.891\n",
            "3  Class 3      0.900   0.943     0.921     0.891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Adapted from Deep Learning with Python by Francois Chollet, 2018\n",
        "history_dict=history.history\n",
        "loss_values=history_dict['loss']\n",
        "acc_values=history_dict['accuracy']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "val_acc_values=history_dict['val_accuracy']\n",
        "epochs=range(1,21)\n",
        "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(15,5))\n",
        "ax1.plot(epochs,loss_values,'bo',label='Training Loss')\n",
        "ax1.plot(epochs,val_loss_values,'orange', label='Validation Loss')\n",
        "ax1.set_title('Training and validation loss')\n",
        "ax1.set_xlabel('Epochs')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.legend()\n",
        "ax2.plot(epochs,acc_values,'bo', label='Training accuracy')\n",
        "ax2.plot(epochs,val_acc_values,'orange',label='Validation accuracy')\n",
        "ax2.set_title('Training and validation accuracy')\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax2.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3k2AKLtVHOIv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "a652c908-eae9-4dea-a444-27981ea0613b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-5091285fa09a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Adapted from Deep Learning with Python by Francois Chollet, 2018\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mloss_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0macc_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_loss_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Adapted from Deep Learning with Python by Francois Chollet, 2018\n",
        "history_dict=history.history\n",
        "loss_values=history_dict['loss']\n",
        "acc_values=history_dict['accuracy']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "val_acc_values=history_dict['val_accuracy']\n",
        "epochs=range(1,21)\n",
        "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(15,5))\n",
        "ax1.plot(epochs,loss_values,'bo',label='Training Loss')\n",
        "ax1.plot(epochs,val_loss_values,'orange', label='Validation Loss')\n",
        "ax1.set_title('Training and validation loss')\n",
        "ax1.set_xlabel('Epochs')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.legend()\n",
        "ax2.plot(epochs,acc_values,'bo', label='Training accuracy')\n",
        "ax2.plot(epochs,val_acc_values,'orange',label='Validation accuracy')\n",
        "ax2.set_title('Training and validation accuracy')\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax2.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJrKwQJBQZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Randomized Search CNN\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from tensorflow.keras.layers import BatchNormalization, Lambda\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import backend as K\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "def create_model(f1=128, kernel_size=3, strides=4, l = 0.0001, dense_units = 16):\n",
        "  m = Sequential()\n",
        "  m.add(Conv1D(f1,\n",
        "                input_shape=[5000, 1],\n",
        "                kernel_size=kernel_size,\n",
        "                strides=strides,\n",
        "                padding='same',\n",
        "                kernel_initializer='glorot_uniform',\n",
        "                kernel_regularizer=regularizers.l2(l=l),\n",
        "                activation='relu'))\n",
        "  m.add(BatchNormalization())\n",
        "  m.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "  m.add(Conv1D(128,\n",
        "                kernel_size=3,\n",
        "                strides=1,\n",
        "                padding='same',\n",
        "                kernel_initializer='glorot_uniform',\n",
        "                kernel_regularizer=regularizers.l2(l=0.0001),\n",
        "                activation='relu'))\n",
        "  m.add(BatchNormalization())\n",
        "  m.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "  m.add(Conv1D(256,\n",
        "                kernel_size=3,\n",
        "                strides=1,\n",
        "                padding='same',\n",
        "                kernel_initializer='glorot_uniform',\n",
        "                kernel_regularizer=regularizers.l2(l=0.0001),\n",
        "                activation='relu'))\n",
        "  m.add(BatchNormalization())\n",
        "  m.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "  m.add(Conv1D(512, #original 512\n",
        "                kernel_size=3,\n",
        "                strides=1,\n",
        "                padding='same',\n",
        "                kernel_initializer='glorot_uniform',\n",
        "                kernel_regularizer=regularizers.l2(l=0.0001),\n",
        "                activation='relu'))\n",
        "  m.add(BatchNormalization())\n",
        "  m.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "  m.add(Dense(dense_units, activation='relu')) #vlad added\n",
        "  m.add(Lambda(lambda x: K.mean(x, axis=1)))  # Same as GAP for 1D Conv Layer\n",
        "  m.add(Dense(4, activation='softmax'))\n",
        "  m.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "  print(m.summary())\n",
        "  return m\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "param_grid = {\n",
        "    'f1': [64, 128, 254],\n",
        "    'kernel_size': [60, 80, 100],\n",
        "    'strides': [1,2,3,4],\n",
        "    'dense_units': [10, 16, 20, 24],\n",
        "    'l' : [0.0001, 0.00008, 0.00012]\n",
        "}\n",
        "X_train, X_test, X_val, y_train, y_test, y_val = dataload(\"data1.pkl\")\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=10, min_lr=0.0001, verbose=1)\n",
        "\n",
        "grid_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, scoring='accuracy', cv=3, n_iter = 24)\n",
        "grid_search.fit(X_train, y_train, batch_size = 128, epochs = 50)\n",
        "\n",
        "#m.fit(X_train, y_train, batch_size = 128, epochs = 100, validation_split=0.2, callbacks = [reduce_lr])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "5YI4wnpJAftg",
        "outputId": "525e6709-a5d9-404c-c4aa-e92160acedc5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-53-cf7e02a34aeb>:58: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(build_fn=create_model, verbose=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_91 (Conv1D)          (None, 2500, 128)         7808      \n",
            "                                                                 \n",
            " batch_normalization_91 (Bat  (None, 2500, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling1d_91 (MaxPoolin  (None, 625, 128)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_92 (Conv1D)          (None, 625, 128)          49280     \n",
            "                                                                 \n",
            " batch_normalization_92 (Bat  (None, 625, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling1d_92 (MaxPoolin  (None, 156, 128)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_93 (Conv1D)          (None, 156, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_93 (Bat  (None, 156, 256)         1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling1d_93 (MaxPoolin  (None, 39, 256)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_94 (Conv1D)          (None, 39, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_94 (Bat  (None, 39, 512)          2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling1d_94 (MaxPoolin  (None, 9, 512)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 9, 10)             5130      \n",
            "                                                                 \n",
            " lambda_23 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 558,646\n",
            "Trainable params: 556,598\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 4ms/step\n",
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_95 (Conv1D)          (None, 2500, 128)         7808      \n",
            "                                                                 \n",
            " batch_normalization_95 (Bat  (None, 2500, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling1d_95 (MaxPoolin  (None, 625, 128)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_96 (Conv1D)          (None, 625, 128)          49280     \n",
            "                                                                 \n",
            " batch_normalization_96 (Bat  (None, 625, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling1d_96 (MaxPoolin  (None, 156, 128)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_97 (Conv1D)          (None, 156, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_97 (Bat  (None, 156, 256)         1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling1d_97 (MaxPoolin  (None, 39, 256)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_98 (Conv1D)          (None, 39, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_98 (Bat  (None, 39, 512)          2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling1d_98 (MaxPoolin  (None, 9, 512)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 9, 10)             5130      \n",
            "                                                                 \n",
            " lambda_24 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 558,646\n",
            "Trainable params: 556,598\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 4ms/step\n",
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_99 (Conv1D)          (None, 2500, 128)         7808      \n",
            "                                                                 \n",
            " batch_normalization_99 (Bat  (None, 2500, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling1d_99 (MaxPoolin  (None, 625, 128)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_100 (Conv1D)         (None, 625, 128)          49280     \n",
            "                                                                 \n",
            " batch_normalization_100 (Ba  (None, 625, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_100 (MaxPooli  (None, 156, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_101 (Conv1D)         (None, 156, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_101 (Ba  (None, 156, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_101 (MaxPooli  (None, 39, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_102 (Conv1D)         (None, 39, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_102 (Ba  (None, 39, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_102 (MaxPooli  (None, 9, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 9, 10)             5130      \n",
            "                                                                 \n",
            " lambda_25 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 558,646\n",
            "Trainable params: 556,598\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_103 (Conv1D)         (None, 1250, 64)          3904      \n",
            "                                                                 \n",
            " batch_normalization_103 (Ba  (None, 1250, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_103 (MaxPooli  (None, 312, 64)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_104 (Conv1D)         (None, 312, 128)          24704     \n",
            "                                                                 \n",
            " batch_normalization_104 (Ba  (None, 312, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_104 (MaxPooli  (None, 78, 128)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_105 (Conv1D)         (None, 78, 256)           98560     \n",
            "                                                                 \n",
            " batch_normalization_105 (Ba  (None, 78, 256)          1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_105 (MaxPooli  (None, 19, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_106 (Conv1D)         (None, 19, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_106 (Ba  (None, 19, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_106 (MaxPooli  (None, 4, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 4, 10)             5130      \n",
            "                                                                 \n",
            " lambda_26 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 529,910\n",
            "Trainable params: 527,990\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_107 (Conv1D)         (None, 1250, 64)          3904      \n",
            "                                                                 \n",
            " batch_normalization_107 (Ba  (None, 1250, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_107 (MaxPooli  (None, 312, 64)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_108 (Conv1D)         (None, 312, 128)          24704     \n",
            "                                                                 \n",
            " batch_normalization_108 (Ba  (None, 312, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_108 (MaxPooli  (None, 78, 128)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_109 (Conv1D)         (None, 78, 256)           98560     \n",
            "                                                                 \n",
            " batch_normalization_109 (Ba  (None, 78, 256)          1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_109 (MaxPooli  (None, 19, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_110 (Conv1D)         (None, 19, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_110 (Ba  (None, 19, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_110 (MaxPooli  (None, 4, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 4, 10)             5130      \n",
            "                                                                 \n",
            " lambda_27 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 529,910\n",
            "Trainable params: 527,990\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_111 (Conv1D)         (None, 1250, 64)          3904      \n",
            "                                                                 \n",
            " batch_normalization_111 (Ba  (None, 1250, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_111 (MaxPooli  (None, 312, 64)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_112 (Conv1D)         (None, 312, 128)          24704     \n",
            "                                                                 \n",
            " batch_normalization_112 (Ba  (None, 312, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_112 (MaxPooli  (None, 78, 128)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_113 (Conv1D)         (None, 78, 256)           98560     \n",
            "                                                                 \n",
            " batch_normalization_113 (Ba  (None, 78, 256)          1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_113 (MaxPooli  (None, 19, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_114 (Conv1D)         (None, 19, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_114 (Ba  (None, 19, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_114 (MaxPooli  (None, 4, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 4, 10)             5130      \n",
            "                                                                 \n",
            " lambda_28 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 529,910\n",
            "Trainable params: 527,990\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_115 (Conv1D)         (None, 2500, 254)         25654     \n",
            "                                                                 \n",
            " batch_normalization_115 (Ba  (None, 2500, 254)        1016      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_115 (MaxPooli  (None, 625, 254)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_116 (Conv1D)         (None, 625, 128)          97664     \n",
            "                                                                 \n",
            " batch_normalization_116 (Ba  (None, 625, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_116 (MaxPooli  (None, 156, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_117 (Conv1D)         (None, 156, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_117 (Ba  (None, 156, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_117 (MaxPooli  (None, 39, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_118 (Conv1D)         (None, 39, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_118 (Ba  (None, 39, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_118 (MaxPooli  (None, 9, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 9, 10)             5130      \n",
            "                                                                 \n",
            " lambda_29 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 625,380\n",
            "Trainable params: 623,080\n",
            "Non-trainable params: 2,300\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 4ms/step\n",
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_119 (Conv1D)         (None, 2500, 254)         25654     \n",
            "                                                                 \n",
            " batch_normalization_119 (Ba  (None, 2500, 254)        1016      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_119 (MaxPooli  (None, 625, 254)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_120 (Conv1D)         (None, 625, 128)          97664     \n",
            "                                                                 \n",
            " batch_normalization_120 (Ba  (None, 625, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_120 (MaxPooli  (None, 156, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_121 (Conv1D)         (None, 156, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_121 (Ba  (None, 156, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_121 (MaxPooli  (None, 39, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_122 (Conv1D)         (None, 39, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_122 (Ba  (None, 39, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_122 (MaxPooli  (None, 9, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 9, 10)             5130      \n",
            "                                                                 \n",
            " lambda_30 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 625,380\n",
            "Trainable params: 623,080\n",
            "Non-trainable params: 2,300\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 4ms/step\n",
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_123 (Conv1D)         (None, 2500, 254)         25654     \n",
            "                                                                 \n",
            " batch_normalization_123 (Ba  (None, 2500, 254)        1016      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_123 (MaxPooli  (None, 625, 254)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_124 (Conv1D)         (None, 625, 128)          97664     \n",
            "                                                                 \n",
            " batch_normalization_124 (Ba  (None, 625, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_124 (MaxPooli  (None, 156, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_125 (Conv1D)         (None, 156, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_125 (Ba  (None, 156, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_125 (MaxPooli  (None, 39, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_126 (Conv1D)         (None, 39, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_126 (Ba  (None, 39, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_126 (MaxPooli  (None, 9, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 9, 10)             5130      \n",
            "                                                                 \n",
            " lambda_31 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 625,380\n",
            "Trainable params: 623,080\n",
            "Non-trainable params: 2,300\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_127 (Conv1D)         (None, 1250, 64)          3904      \n",
            "                                                                 \n",
            " batch_normalization_127 (Ba  (None, 1250, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_127 (MaxPooli  (None, 312, 64)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_128 (Conv1D)         (None, 312, 128)          24704     \n",
            "                                                                 \n",
            " batch_normalization_128 (Ba  (None, 312, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_128 (MaxPooli  (None, 78, 128)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_129 (Conv1D)         (None, 78, 256)           98560     \n",
            "                                                                 \n",
            " batch_normalization_129 (Ba  (None, 78, 256)          1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_129 (MaxPooli  (None, 19, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_130 (Conv1D)         (None, 19, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_130 (Ba  (None, 19, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_130 (MaxPooli  (None, 4, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 4, 10)             5130      \n",
            "                                                                 \n",
            " lambda_32 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 529,910\n",
            "Trainable params: 527,990\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_131 (Conv1D)         (None, 1250, 64)          3904      \n",
            "                                                                 \n",
            " batch_normalization_131 (Ba  (None, 1250, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_131 (MaxPooli  (None, 312, 64)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_132 (Conv1D)         (None, 312, 128)          24704     \n",
            "                                                                 \n",
            " batch_normalization_132 (Ba  (None, 312, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_132 (MaxPooli  (None, 78, 128)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_133 (Conv1D)         (None, 78, 256)           98560     \n",
            "                                                                 \n",
            " batch_normalization_133 (Ba  (None, 78, 256)          1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_133 (MaxPooli  (None, 19, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_134 (Conv1D)         (None, 19, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_134 (Ba  (None, 19, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_134 (MaxPooli  (None, 4, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 4, 10)             5130      \n",
            "                                                                 \n",
            " lambda_33 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 529,910\n",
            "Trainable params: 527,990\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_135 (Conv1D)         (None, 1250, 64)          3904      \n",
            "                                                                 \n",
            " batch_normalization_135 (Ba  (None, 1250, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_135 (MaxPooli  (None, 312, 64)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_136 (Conv1D)         (None, 312, 128)          24704     \n",
            "                                                                 \n",
            " batch_normalization_136 (Ba  (None, 312, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_136 (MaxPooli  (None, 78, 128)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_137 (Conv1D)         (None, 78, 256)           98560     \n",
            "                                                                 \n",
            " batch_normalization_137 (Ba  (None, 78, 256)          1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_137 (MaxPooli  (None, 19, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_138 (Conv1D)         (None, 19, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_138 (Ba  (None, 19, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_138 (MaxPooli  (None, 4, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, 4, 10)             5130      \n",
            "                                                                 \n",
            " lambda_34 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 529,910\n",
            "Trainable params: 527,990\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_139 (Conv1D)         (None, 2500, 254)         20574     \n",
            "                                                                 \n",
            " batch_normalization_139 (Ba  (None, 2500, 254)        1016      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_139 (MaxPooli  (None, 625, 254)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_140 (Conv1D)         (None, 625, 128)          97664     \n",
            "                                                                 \n",
            " batch_normalization_140 (Ba  (None, 625, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_140 (MaxPooli  (None, 156, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_141 (Conv1D)         (None, 156, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_141 (Ba  (None, 156, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_141 (MaxPooli  (None, 39, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_142 (Conv1D)         (None, 39, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_142 (Ba  (None, 39, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_142 (MaxPooli  (None, 9, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 9, 10)             5130      \n",
            "                                                                 \n",
            " lambda_35 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,300\n",
            "Trainable params: 618,000\n",
            "Non-trainable params: 2,300\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 4ms/step\n",
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_143 (Conv1D)         (None, 2500, 254)         20574     \n",
            "                                                                 \n",
            " batch_normalization_143 (Ba  (None, 2500, 254)        1016      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_143 (MaxPooli  (None, 625, 254)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_144 (Conv1D)         (None, 625, 128)          97664     \n",
            "                                                                 \n",
            " batch_normalization_144 (Ba  (None, 625, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_144 (MaxPooli  (None, 156, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_145 (Conv1D)         (None, 156, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_145 (Ba  (None, 156, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_145 (MaxPooli  (None, 39, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_146 (Conv1D)         (None, 39, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_146 (Ba  (None, 39, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_146 (MaxPooli  (None, 9, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_60 (Dense)            (None, 9, 10)             5130      \n",
            "                                                                 \n",
            " lambda_36 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,300\n",
            "Trainable params: 618,000\n",
            "Non-trainable params: 2,300\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_147 (Conv1D)         (None, 2500, 254)         20574     \n",
            "                                                                 \n",
            " batch_normalization_147 (Ba  (None, 2500, 254)        1016      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_147 (MaxPooli  (None, 625, 254)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_148 (Conv1D)         (None, 625, 128)          97664     \n",
            "                                                                 \n",
            " batch_normalization_148 (Ba  (None, 625, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_148 (MaxPooli  (None, 156, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_149 (Conv1D)         (None, 156, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_149 (Ba  (None, 156, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_149 (MaxPooli  (None, 39, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_150 (Conv1D)         (None, 39, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_150 (Ba  (None, 39, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_150 (MaxPooli  (None, 9, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 9, 10)             5130      \n",
            "                                                                 \n",
            " lambda_37 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,300\n",
            "Trainable params: 618,000\n",
            "Non-trainable params: 2,300\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_151 (Conv1D)         (None, 5000, 64)          5184      \n",
            "                                                                 \n",
            " batch_normalization_151 (Ba  (None, 5000, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_151 (MaxPooli  (None, 1250, 64)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_152 (Conv1D)         (None, 1250, 128)         24704     \n",
            "                                                                 \n",
            " batch_normalization_152 (Ba  (None, 1250, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_152 (MaxPooli  (None, 312, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_153 (Conv1D)         (None, 312, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_153 (Ba  (None, 312, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_153 (MaxPooli  (None, 78, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_154 (Conv1D)         (None, 78, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_154 (Ba  (None, 78, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_154 (MaxPooli  (None, 19, 512)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_64 (Dense)            (None, 19, 20)            10260     \n",
            "                                                                 \n",
            " lambda_38 (Lambda)          (None, 20)                0         \n",
            "                                                                 \n",
            " dense_65 (Dense)            (None, 4)                 84        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 536,360\n",
            "Trainable params: 534,440\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 4ms/step\n",
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_155 (Conv1D)         (None, 5000, 64)          5184      \n",
            "                                                                 \n",
            " batch_normalization_155 (Ba  (None, 5000, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_155 (MaxPooli  (None, 1250, 64)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_156 (Conv1D)         (None, 1250, 128)         24704     \n",
            "                                                                 \n",
            " batch_normalization_156 (Ba  (None, 1250, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_156 (MaxPooli  (None, 312, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_157 (Conv1D)         (None, 312, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_157 (Ba  (None, 312, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_157 (MaxPooli  (None, 78, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_158 (Conv1D)         (None, 78, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_158 (Ba  (None, 78, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_158 (MaxPooli  (None, 19, 512)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_66 (Dense)            (None, 19, 20)            10260     \n",
            "                                                                 \n",
            " lambda_39 (Lambda)          (None, 20)                0         \n",
            "                                                                 \n",
            " dense_67 (Dense)            (None, 4)                 84        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 536,360\n",
            "Trainable params: 534,440\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 4ms/step\n",
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_159 (Conv1D)         (None, 5000, 64)          5184      \n",
            "                                                                 \n",
            " batch_normalization_159 (Ba  (None, 5000, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_159 (MaxPooli  (None, 1250, 64)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_160 (Conv1D)         (None, 1250, 128)         24704     \n",
            "                                                                 \n",
            " batch_normalization_160 (Ba  (None, 1250, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_160 (MaxPooli  (None, 312, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_161 (Conv1D)         (None, 312, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_161 (Ba  (None, 312, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_161 (MaxPooli  (None, 78, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_162 (Conv1D)         (None, 78, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_162 (Ba  (None, 78, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_162 (MaxPooli  (None, 19, 512)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_68 (Dense)            (None, 19, 20)            10260     \n",
            "                                                                 \n",
            " lambda_40 (Lambda)          (None, 20)                0         \n",
            "                                                                 \n",
            " dense_69 (Dense)            (None, 4)                 84        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 536,360\n",
            "Trainable params: 534,440\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_41\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_163 (Conv1D)         (None, 5000, 64)          6464      \n",
            "                                                                 \n",
            " batch_normalization_163 (Ba  (None, 5000, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_163 (MaxPooli  (None, 1250, 64)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_164 (Conv1D)         (None, 1250, 128)         24704     \n",
            "                                                                 \n",
            " batch_normalization_164 (Ba  (None, 1250, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_164 (MaxPooli  (None, 312, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_165 (Conv1D)         (None, 312, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_165 (Ba  (None, 312, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_165 (MaxPooli  (None, 78, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_166 (Conv1D)         (None, 78, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_166 (Ba  (None, 78, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_166 (MaxPooli  (None, 19, 512)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_70 (Dense)            (None, 19, 24)            12312     \n",
            "                                                                 \n",
            " lambda_41 (Lambda)          (None, 24)                0         \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 4)                 100       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 539,708\n",
            "Trainable params: 537,788\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_42\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_167 (Conv1D)         (None, 5000, 64)          6464      \n",
            "                                                                 \n",
            " batch_normalization_167 (Ba  (None, 5000, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_167 (MaxPooli  (None, 1250, 64)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_168 (Conv1D)         (None, 1250, 128)         24704     \n",
            "                                                                 \n",
            " batch_normalization_168 (Ba  (None, 1250, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_168 (MaxPooli  (None, 312, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_169 (Conv1D)         (None, 312, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_169 (Ba  (None, 312, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_169 (MaxPooli  (None, 78, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_170 (Conv1D)         (None, 78, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_170 (Ba  (None, 78, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_170 (MaxPooli  (None, 19, 512)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_72 (Dense)            (None, 19, 24)            12312     \n",
            "                                                                 \n",
            " lambda_42 (Lambda)          (None, 24)                0         \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 4)                 100       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 539,708\n",
            "Trainable params: 537,788\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_171 (Conv1D)         (None, 5000, 64)          6464      \n",
            "                                                                 \n",
            " batch_normalization_171 (Ba  (None, 5000, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_171 (MaxPooli  (None, 1250, 64)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_172 (Conv1D)         (None, 1250, 128)         24704     \n",
            "                                                                 \n",
            " batch_normalization_172 (Ba  (None, 1250, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_172 (MaxPooli  (None, 312, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_173 (Conv1D)         (None, 312, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_173 (Ba  (None, 312, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_173 (MaxPooli  (None, 78, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_174 (Conv1D)         (None, 78, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_174 (Ba  (None, 78, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_174 (MaxPooli  (None, 19, 512)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 19, 24)            12312     \n",
            "                                                                 \n",
            " lambda_43 (Lambda)          (None, 24)                0         \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 4)                 100       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 539,708\n",
            "Trainable params: 537,788\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_44\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_175 (Conv1D)         (None, 1250, 254)         15494     \n",
            "                                                                 \n",
            " batch_normalization_175 (Ba  (None, 1250, 254)        1016      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_175 (MaxPooli  (None, 312, 254)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_176 (Conv1D)         (None, 312, 128)          97664     \n",
            "                                                                 \n",
            " batch_normalization_176 (Ba  (None, 312, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_176 (MaxPooli  (None, 78, 128)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_177 (Conv1D)         (None, 78, 256)           98560     \n",
            "                                                                 \n",
            " batch_normalization_177 (Ba  (None, 78, 256)          1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_177 (MaxPooli  (None, 19, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_178 (Conv1D)         (None, 19, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_178 (Ba  (None, 19, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_178 (MaxPooli  (None, 4, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_76 (Dense)            (None, 4, 20)             10260     \n",
            "                                                                 \n",
            " lambda_44 (Lambda)          (None, 20)                0         \n",
            "                                                                 \n",
            " dense_77 (Dense)            (None, 4)                 84        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,390\n",
            "Trainable params: 618,090\n",
            "Non-trainable params: 2,300\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_45\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_179 (Conv1D)         (None, 1250, 254)         15494     \n",
            "                                                                 \n",
            " batch_normalization_179 (Ba  (None, 1250, 254)        1016      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_179 (MaxPooli  (None, 312, 254)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_180 (Conv1D)         (None, 312, 128)          97664     \n",
            "                                                                 \n",
            " batch_normalization_180 (Ba  (None, 312, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_180 (MaxPooli  (None, 78, 128)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_181 (Conv1D)         (None, 78, 256)           98560     \n",
            "                                                                 \n",
            " batch_normalization_181 (Ba  (None, 78, 256)          1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_181 (MaxPooli  (None, 19, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_182 (Conv1D)         (None, 19, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_182 (Ba  (None, 19, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_182 (MaxPooli  (None, 4, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_78 (Dense)            (None, 4, 20)             10260     \n",
            "                                                                 \n",
            " lambda_45 (Lambda)          (None, 20)                0         \n",
            "                                                                 \n",
            " dense_79 (Dense)            (None, 4)                 84        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,390\n",
            "Trainable params: 618,090\n",
            "Non-trainable params: 2,300\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_46\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_183 (Conv1D)         (None, 1250, 254)         15494     \n",
            "                                                                 \n",
            " batch_normalization_183 (Ba  (None, 1250, 254)        1016      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_183 (MaxPooli  (None, 312, 254)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_184 (Conv1D)         (None, 312, 128)          97664     \n",
            "                                                                 \n",
            " batch_normalization_184 (Ba  (None, 312, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_184 (MaxPooli  (None, 78, 128)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_185 (Conv1D)         (None, 78, 256)           98560     \n",
            "                                                                 \n",
            " batch_normalization_185 (Ba  (None, 78, 256)          1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_185 (MaxPooli  (None, 19, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_186 (Conv1D)         (None, 19, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_186 (Ba  (None, 19, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_186 (MaxPooli  (None, 4, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_80 (Dense)            (None, 4, 20)             10260     \n",
            "                                                                 \n",
            " lambda_46 (Lambda)          (None, 20)                0         \n",
            "                                                                 \n",
            " dense_81 (Dense)            (None, 4)                 84        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,390\n",
            "Trainable params: 618,090\n",
            "Non-trainable params: 2,300\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_47\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_187 (Conv1D)         (None, 1667, 64)          5184      \n",
            "                                                                 \n",
            " batch_normalization_187 (Ba  (None, 1667, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_187 (MaxPooli  (None, 416, 64)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_188 (Conv1D)         (None, 416, 128)          24704     \n",
            "                                                                 \n",
            " batch_normalization_188 (Ba  (None, 416, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_188 (MaxPooli  (None, 104, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_189 (Conv1D)         (None, 104, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_189 (Ba  (None, 104, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_189 (MaxPooli  (None, 26, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_190 (Conv1D)         (None, 26, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_190 (Ba  (None, 26, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_190 (MaxPooli  (None, 6, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_82 (Dense)            (None, 6, 16)             8208      \n",
            "                                                                 \n",
            " lambda_47 (Lambda)          (None, 16)                0         \n",
            "                                                                 \n",
            " dense_83 (Dense)            (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 534,292\n",
            "Trainable params: 532,372\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_48\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_191 (Conv1D)         (None, 1667, 64)          5184      \n",
            "                                                                 \n",
            " batch_normalization_191 (Ba  (None, 1667, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_191 (MaxPooli  (None, 416, 64)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_192 (Conv1D)         (None, 416, 128)          24704     \n",
            "                                                                 \n",
            " batch_normalization_192 (Ba  (None, 416, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_192 (MaxPooli  (None, 104, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_193 (Conv1D)         (None, 104, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_193 (Ba  (None, 104, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_193 (MaxPooli  (None, 26, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_194 (Conv1D)         (None, 26, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_194 (Ba  (None, 26, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_194 (MaxPooli  (None, 6, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_84 (Dense)            (None, 6, 16)             8208      \n",
            "                                                                 \n",
            " lambda_48 (Lambda)          (None, 16)                0         \n",
            "                                                                 \n",
            " dense_85 (Dense)            (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 534,292\n",
            "Trainable params: 532,372\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_49\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_195 (Conv1D)         (None, 1667, 64)          5184      \n",
            "                                                                 \n",
            " batch_normalization_195 (Ba  (None, 1667, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_195 (MaxPooli  (None, 416, 64)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_196 (Conv1D)         (None, 416, 128)          24704     \n",
            "                                                                 \n",
            " batch_normalization_196 (Ba  (None, 416, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_196 (MaxPooli  (None, 104, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_197 (Conv1D)         (None, 104, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_197 (Ba  (None, 104, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_197 (MaxPooli  (None, 26, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_198 (Conv1D)         (None, 26, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_198 (Ba  (None, 26, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_198 (MaxPooli  (None, 6, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_86 (Dense)            (None, 6, 16)             8208      \n",
            "                                                                 \n",
            " lambda_49 (Lambda)          (None, 16)                0         \n",
            "                                                                 \n",
            " dense_87 (Dense)            (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 534,292\n",
            "Trainable params: 532,372\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 2ms/step\n",
            "Model: \"sequential_50\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_199 (Conv1D)         (None, 5000, 254)         20574     \n",
            "                                                                 \n",
            " batch_normalization_199 (Ba  (None, 5000, 254)        1016      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_199 (MaxPooli  (None, 1250, 254)        0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_200 (Conv1D)         (None, 1250, 128)         97664     \n",
            "                                                                 \n",
            " batch_normalization_200 (Ba  (None, 1250, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_200 (MaxPooli  (None, 312, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_201 (Conv1D)         (None, 312, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_201 (Ba  (None, 312, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_201 (MaxPooli  (None, 78, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_202 (Conv1D)         (None, 78, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_202 (Ba  (None, 78, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_202 (MaxPooli  (None, 19, 512)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_88 (Dense)            (None, 19, 10)            5130      \n",
            "                                                                 \n",
            " lambda_50 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_89 (Dense)            (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,300\n",
            "Trainable params: 618,000\n",
            "Non-trainable params: 2,300\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 1s 5ms/step\n",
            "Model: \"sequential_51\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_203 (Conv1D)         (None, 5000, 254)         20574     \n",
            "                                                                 \n",
            " batch_normalization_203 (Ba  (None, 5000, 254)        1016      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_203 (MaxPooli  (None, 1250, 254)        0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_204 (Conv1D)         (None, 1250, 128)         97664     \n",
            "                                                                 \n",
            " batch_normalization_204 (Ba  (None, 1250, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_204 (MaxPooli  (None, 312, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_205 (Conv1D)         (None, 312, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_205 (Ba  (None, 312, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_205 (MaxPooli  (None, 78, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_206 (Conv1D)         (None, 78, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_206 (Ba  (None, 78, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_206 (MaxPooli  (None, 19, 512)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_90 (Dense)            (None, 19, 10)            5130      \n",
            "                                                                 \n",
            " lambda_51 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_91 (Dense)            (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,300\n",
            "Trainable params: 618,000\n",
            "Non-trainable params: 2,300\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 5ms/step\n",
            "Model: \"sequential_52\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_207 (Conv1D)         (None, 5000, 254)         20574     \n",
            "                                                                 \n",
            " batch_normalization_207 (Ba  (None, 5000, 254)        1016      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_207 (MaxPooli  (None, 1250, 254)        0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_208 (Conv1D)         (None, 1250, 128)         97664     \n",
            "                                                                 \n",
            " batch_normalization_208 (Ba  (None, 1250, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_208 (MaxPooli  (None, 312, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_209 (Conv1D)         (None, 312, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_209 (Ba  (None, 312, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_209 (MaxPooli  (None, 78, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_210 (Conv1D)         (None, 78, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_210 (Ba  (None, 78, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_210 (MaxPooli  (None, 19, 512)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_92 (Dense)            (None, 19, 10)            5130      \n",
            "                                                                 \n",
            " lambda_52 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_93 (Dense)            (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 620,300\n",
            "Trainable params: 618,000\n",
            "Non-trainable params: 2,300\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 4ms/step\n",
            "Model: \"sequential_53\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_211 (Conv1D)         (None, 1667, 128)         10368     \n",
            "                                                                 \n",
            " batch_normalization_211 (Ba  (None, 1667, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_211 (MaxPooli  (None, 416, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_212 (Conv1D)         (None, 416, 128)          49280     \n",
            "                                                                 \n",
            " batch_normalization_212 (Ba  (None, 416, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_212 (MaxPooli  (None, 104, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_213 (Conv1D)         (None, 104, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_213 (Ba  (None, 104, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_213 (MaxPooli  (None, 26, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_214 (Conv1D)         (None, 26, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_214 (Ba  (None, 26, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_214 (MaxPooli  (None, 6, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_94 (Dense)            (None, 6, 24)             12312     \n",
            "                                                                 \n",
            " lambda_53 (Lambda)          (None, 24)                0         \n",
            "                                                                 \n",
            " dense_95 (Dense)            (None, 4)                 100       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 568,444\n",
            "Trainable params: 566,396\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_54\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_215 (Conv1D)         (None, 1667, 128)         10368     \n",
            "                                                                 \n",
            " batch_normalization_215 (Ba  (None, 1667, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_215 (MaxPooli  (None, 416, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_216 (Conv1D)         (None, 416, 128)          49280     \n",
            "                                                                 \n",
            " batch_normalization_216 (Ba  (None, 416, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_216 (MaxPooli  (None, 104, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_217 (Conv1D)         (None, 104, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_217 (Ba  (None, 104, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_217 (MaxPooli  (None, 26, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_218 (Conv1D)         (None, 26, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_218 (Ba  (None, 26, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_218 (MaxPooli  (None, 6, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_96 (Dense)            (None, 6, 24)             12312     \n",
            "                                                                 \n",
            " lambda_54 (Lambda)          (None, 24)                0         \n",
            "                                                                 \n",
            " dense_97 (Dense)            (None, 4)                 100       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 568,444\n",
            "Trainable params: 566,396\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_55\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_219 (Conv1D)         (None, 1667, 128)         10368     \n",
            "                                                                 \n",
            " batch_normalization_219 (Ba  (None, 1667, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_219 (MaxPooli  (None, 416, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_220 (Conv1D)         (None, 416, 128)          49280     \n",
            "                                                                 \n",
            " batch_normalization_220 (Ba  (None, 416, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_220 (MaxPooli  (None, 104, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_221 (Conv1D)         (None, 104, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_221 (Ba  (None, 104, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_221 (MaxPooli  (None, 26, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_222 (Conv1D)         (None, 26, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_222 (Ba  (None, 26, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_222 (MaxPooli  (None, 6, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_98 (Dense)            (None, 6, 24)             12312     \n",
            "                                                                 \n",
            " lambda_55 (Lambda)          (None, 24)                0         \n",
            "                                                                 \n",
            " dense_99 (Dense)            (None, 4)                 100       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 568,444\n",
            "Trainable params: 566,396\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_56\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_223 (Conv1D)         (None, 1667, 128)         7808      \n",
            "                                                                 \n",
            " batch_normalization_223 (Ba  (None, 1667, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_223 (MaxPooli  (None, 416, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_224 (Conv1D)         (None, 416, 128)          49280     \n",
            "                                                                 \n",
            " batch_normalization_224 (Ba  (None, 416, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_224 (MaxPooli  (None, 104, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_225 (Conv1D)         (None, 104, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_225 (Ba  (None, 104, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_225 (MaxPooli  (None, 26, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_226 (Conv1D)         (None, 26, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_226 (Ba  (None, 26, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_226 (MaxPooli  (None, 6, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_100 (Dense)           (None, 6, 24)             12312     \n",
            "                                                                 \n",
            " lambda_56 (Lambda)          (None, 24)                0         \n",
            "                                                                 \n",
            " dense_101 (Dense)           (None, 4)                 100       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 565,884\n",
            "Trainable params: 563,836\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_57\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_227 (Conv1D)         (None, 1667, 128)         7808      \n",
            "                                                                 \n",
            " batch_normalization_227 (Ba  (None, 1667, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_227 (MaxPooli  (None, 416, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_228 (Conv1D)         (None, 416, 128)          49280     \n",
            "                                                                 \n",
            " batch_normalization_228 (Ba  (None, 416, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_228 (MaxPooli  (None, 104, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_229 (Conv1D)         (None, 104, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_229 (Ba  (None, 104, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_229 (MaxPooli  (None, 26, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_230 (Conv1D)         (None, 26, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_230 (Ba  (None, 26, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_230 (MaxPooli  (None, 6, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_102 (Dense)           (None, 6, 24)             12312     \n",
            "                                                                 \n",
            " lambda_57 (Lambda)          (None, 24)                0         \n",
            "                                                                 \n",
            " dense_103 (Dense)           (None, 4)                 100       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 565,884\n",
            "Trainable params: 563,836\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_58\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_231 (Conv1D)         (None, 1667, 128)         7808      \n",
            "                                                                 \n",
            " batch_normalization_231 (Ba  (None, 1667, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_231 (MaxPooli  (None, 416, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_232 (Conv1D)         (None, 416, 128)          49280     \n",
            "                                                                 \n",
            " batch_normalization_232 (Ba  (None, 416, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_232 (MaxPooli  (None, 104, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_233 (Conv1D)         (None, 104, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_233 (Ba  (None, 104, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_233 (MaxPooli  (None, 26, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_234 (Conv1D)         (None, 26, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_234 (Ba  (None, 26, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_234 (MaxPooli  (None, 6, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_104 (Dense)           (None, 6, 24)             12312     \n",
            "                                                                 \n",
            " lambda_58 (Lambda)          (None, 24)                0         \n",
            "                                                                 \n",
            " dense_105 (Dense)           (None, 4)                 100       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 565,884\n",
            "Trainable params: 563,836\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_59\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_235 (Conv1D)         (None, 1667, 128)         12928     \n",
            "                                                                 \n",
            " batch_normalization_235 (Ba  (None, 1667, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_235 (MaxPooli  (None, 416, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_236 (Conv1D)         (None, 416, 128)          49280     \n",
            "                                                                 \n",
            " batch_normalization_236 (Ba  (None, 416, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_236 (MaxPooli  (None, 104, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_237 (Conv1D)         (None, 104, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_237 (Ba  (None, 104, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_237 (MaxPooli  (None, 26, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_238 (Conv1D)         (None, 26, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_238 (Ba  (None, 26, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_238 (MaxPooli  (None, 6, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_106 (Dense)           (None, 6, 24)             12312     \n",
            "                                                                 \n",
            " lambda_59 (Lambda)          (None, 24)                0         \n",
            "                                                                 \n",
            " dense_107 (Dense)           (None, 4)                 100       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 571,004\n",
            "Trainable params: 568,956\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_60\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_239 (Conv1D)         (None, 1667, 128)         12928     \n",
            "                                                                 \n",
            " batch_normalization_239 (Ba  (None, 1667, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_239 (MaxPooli  (None, 416, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_240 (Conv1D)         (None, 416, 128)          49280     \n",
            "                                                                 \n",
            " batch_normalization_240 (Ba  (None, 416, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_240 (MaxPooli  (None, 104, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_241 (Conv1D)         (None, 104, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_241 (Ba  (None, 104, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_241 (MaxPooli  (None, 26, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_242 (Conv1D)         (None, 26, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_242 (Ba  (None, 26, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_242 (MaxPooli  (None, 6, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_108 (Dense)           (None, 6, 24)             12312     \n",
            "                                                                 \n",
            " lambda_60 (Lambda)          (None, 24)                0         \n",
            "                                                                 \n",
            " dense_109 (Dense)           (None, 4)                 100       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 571,004\n",
            "Trainable params: 568,956\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_61\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_243 (Conv1D)         (None, 1667, 128)         12928     \n",
            "                                                                 \n",
            " batch_normalization_243 (Ba  (None, 1667, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_243 (MaxPooli  (None, 416, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_244 (Conv1D)         (None, 416, 128)          49280     \n",
            "                                                                 \n",
            " batch_normalization_244 (Ba  (None, 416, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_244 (MaxPooli  (None, 104, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_245 (Conv1D)         (None, 104, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_245 (Ba  (None, 104, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_245 (MaxPooli  (None, 26, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_246 (Conv1D)         (None, 26, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_246 (Ba  (None, 26, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_246 (MaxPooli  (None, 6, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_110 (Dense)           (None, 6, 24)             12312     \n",
            "                                                                 \n",
            " lambda_61 (Lambda)          (None, 24)                0         \n",
            "                                                                 \n",
            " dense_111 (Dense)           (None, 4)                 100       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 571,004\n",
            "Trainable params: 568,956\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_62\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_247 (Conv1D)         (None, 2500, 254)         15494     \n",
            "                                                                 \n",
            " batch_normalization_247 (Ba  (None, 2500, 254)        1016      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_247 (MaxPooli  (None, 625, 254)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_248 (Conv1D)         (None, 625, 128)          97664     \n",
            "                                                                 \n",
            " batch_normalization_248 (Ba  (None, 625, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_248 (MaxPooli  (None, 156, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_249 (Conv1D)         (None, 156, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_249 (Ba  (None, 156, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_249 (MaxPooli  (None, 39, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_250 (Conv1D)         (None, 39, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_250 (Ba  (None, 39, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_250 (MaxPooli  (None, 9, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_112 (Dense)           (None, 9, 10)             5130      \n",
            "                                                                 \n",
            " lambda_62 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_113 (Dense)           (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 615,220\n",
            "Trainable params: 612,920\n",
            "Non-trainable params: 2,300\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_63\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_251 (Conv1D)         (None, 2500, 254)         15494     \n",
            "                                                                 \n",
            " batch_normalization_251 (Ba  (None, 2500, 254)        1016      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_251 (MaxPooli  (None, 625, 254)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_252 (Conv1D)         (None, 625, 128)          97664     \n",
            "                                                                 \n",
            " batch_normalization_252 (Ba  (None, 625, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_252 (MaxPooli  (None, 156, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_253 (Conv1D)         (None, 156, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_253 (Ba  (None, 156, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_253 (MaxPooli  (None, 39, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_254 (Conv1D)         (None, 39, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_254 (Ba  (None, 39, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_254 (MaxPooli  (None, 9, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_114 (Dense)           (None, 9, 10)             5130      \n",
            "                                                                 \n",
            " lambda_63 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_115 (Dense)           (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 615,220\n",
            "Trainable params: 612,920\n",
            "Non-trainable params: 2,300\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_64\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_255 (Conv1D)         (None, 2500, 254)         15494     \n",
            "                                                                 \n",
            " batch_normalization_255 (Ba  (None, 2500, 254)        1016      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_255 (MaxPooli  (None, 625, 254)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_256 (Conv1D)         (None, 625, 128)          97664     \n",
            "                                                                 \n",
            " batch_normalization_256 (Ba  (None, 625, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_256 (MaxPooli  (None, 156, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_257 (Conv1D)         (None, 156, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_257 (Ba  (None, 156, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_257 (MaxPooli  (None, 39, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_258 (Conv1D)         (None, 39, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_258 (Ba  (None, 39, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_258 (MaxPooli  (None, 9, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_116 (Dense)           (None, 9, 10)             5130      \n",
            "                                                                 \n",
            " lambda_64 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_117 (Dense)           (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 615,220\n",
            "Trainable params: 612,920\n",
            "Non-trainable params: 2,300\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_65\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_259 (Conv1D)         (None, 1667, 128)         12928     \n",
            "                                                                 \n",
            " batch_normalization_259 (Ba  (None, 1667, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_259 (MaxPooli  (None, 416, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_260 (Conv1D)         (None, 416, 128)          49280     \n",
            "                                                                 \n",
            " batch_normalization_260 (Ba  (None, 416, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_260 (MaxPooli  (None, 104, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_261 (Conv1D)         (None, 104, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_261 (Ba  (None, 104, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_261 (MaxPooli  (None, 26, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_262 (Conv1D)         (None, 26, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_262 (Ba  (None, 26, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_262 (MaxPooli  (None, 6, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_118 (Dense)           (None, 6, 16)             8208      \n",
            "                                                                 \n",
            " lambda_65 (Lambda)          (None, 16)                0         \n",
            "                                                                 \n",
            " dense_119 (Dense)           (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 566,868\n",
            "Trainable params: 564,820\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_66\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_263 (Conv1D)         (None, 1667, 128)         12928     \n",
            "                                                                 \n",
            " batch_normalization_263 (Ba  (None, 1667, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_263 (MaxPooli  (None, 416, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_264 (Conv1D)         (None, 416, 128)          49280     \n",
            "                                                                 \n",
            " batch_normalization_264 (Ba  (None, 416, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_264 (MaxPooli  (None, 104, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_265 (Conv1D)         (None, 104, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_265 (Ba  (None, 104, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_265 (MaxPooli  (None, 26, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_266 (Conv1D)         (None, 26, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_266 (Ba  (None, 26, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_266 (MaxPooli  (None, 6, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_120 (Dense)           (None, 6, 16)             8208      \n",
            "                                                                 \n",
            " lambda_66 (Lambda)          (None, 16)                0         \n",
            "                                                                 \n",
            " dense_121 (Dense)           (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 566,868\n",
            "Trainable params: 564,820\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_67\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_267 (Conv1D)         (None, 1667, 128)         12928     \n",
            "                                                                 \n",
            " batch_normalization_267 (Ba  (None, 1667, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_267 (MaxPooli  (None, 416, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_268 (Conv1D)         (None, 416, 128)          49280     \n",
            "                                                                 \n",
            " batch_normalization_268 (Ba  (None, 416, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_268 (MaxPooli  (None, 104, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_269 (Conv1D)         (None, 104, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_269 (Ba  (None, 104, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_269 (MaxPooli  (None, 26, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_270 (Conv1D)         (None, 26, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_270 (Ba  (None, 26, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_270 (MaxPooli  (None, 6, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_122 (Dense)           (None, 6, 16)             8208      \n",
            "                                                                 \n",
            " lambda_67 (Lambda)          (None, 16)                0         \n",
            "                                                                 \n",
            " dense_123 (Dense)           (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 566,868\n",
            "Trainable params: 564,820\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_68\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_271 (Conv1D)         (None, 2500, 64)          6464      \n",
            "                                                                 \n",
            " batch_normalization_271 (Ba  (None, 2500, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_271 (MaxPooli  (None, 625, 64)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_272 (Conv1D)         (None, 625, 128)          24704     \n",
            "                                                                 \n",
            " batch_normalization_272 (Ba  (None, 625, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_272 (MaxPooli  (None, 156, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_273 (Conv1D)         (None, 156, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_273 (Ba  (None, 156, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_273 (MaxPooli  (None, 39, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_274 (Conv1D)         (None, 39, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_274 (Ba  (None, 39, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_274 (MaxPooli  (None, 9, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_124 (Dense)           (None, 9, 16)             8208      \n",
            "                                                                 \n",
            " lambda_68 (Lambda)          (None, 16)                0         \n",
            "                                                                 \n",
            " dense_125 (Dense)           (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 535,572\n",
            "Trainable params: 533,652\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_69\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_275 (Conv1D)         (None, 2500, 64)          6464      \n",
            "                                                                 \n",
            " batch_normalization_275 (Ba  (None, 2500, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_275 (MaxPooli  (None, 625, 64)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_276 (Conv1D)         (None, 625, 128)          24704     \n",
            "                                                                 \n",
            " batch_normalization_276 (Ba  (None, 625, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_276 (MaxPooli  (None, 156, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_277 (Conv1D)         (None, 156, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_277 (Ba  (None, 156, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_277 (MaxPooli  (None, 39, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_278 (Conv1D)         (None, 39, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_278 (Ba  (None, 39, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_278 (MaxPooli  (None, 9, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_126 (Dense)           (None, 9, 16)             8208      \n",
            "                                                                 \n",
            " lambda_69 (Lambda)          (None, 16)                0         \n",
            "                                                                 \n",
            " dense_127 (Dense)           (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 535,572\n",
            "Trainable params: 533,652\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_70\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_279 (Conv1D)         (None, 2500, 64)          6464      \n",
            "                                                                 \n",
            " batch_normalization_279 (Ba  (None, 2500, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_279 (MaxPooli  (None, 625, 64)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_280 (Conv1D)         (None, 625, 128)          24704     \n",
            "                                                                 \n",
            " batch_normalization_280 (Ba  (None, 625, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_280 (MaxPooli  (None, 156, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_281 (Conv1D)         (None, 156, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_281 (Ba  (None, 156, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_281 (MaxPooli  (None, 39, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_282 (Conv1D)         (None, 39, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_282 (Ba  (None, 39, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_282 (MaxPooli  (None, 9, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_128 (Dense)           (None, 9, 16)             8208      \n",
            "                                                                 \n",
            " lambda_70 (Lambda)          (None, 16)                0         \n",
            "                                                                 \n",
            " dense_129 (Dense)           (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 535,572\n",
            "Trainable params: 533,652\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_71\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_283 (Conv1D)         (None, 1667, 128)         10368     \n",
            "                                                                 \n",
            " batch_normalization_283 (Ba  (None, 1667, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_283 (MaxPooli  (None, 416, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_284 (Conv1D)         (None, 416, 128)          49280     \n",
            "                                                                 \n",
            " batch_normalization_284 (Ba  (None, 416, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_284 (MaxPooli  (None, 104, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_285 (Conv1D)         (None, 104, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_285 (Ba  (None, 104, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_285 (MaxPooli  (None, 26, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_286 (Conv1D)         (None, 26, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_286 (Ba  (None, 26, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_286 (MaxPooli  (None, 6, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_130 (Dense)           (None, 6, 16)             8208      \n",
            "                                                                 \n",
            " lambda_71 (Lambda)          (None, 16)                0         \n",
            "                                                                 \n",
            " dense_131 (Dense)           (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 564,308\n",
            "Trainable params: 562,260\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_72\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_287 (Conv1D)         (None, 1667, 128)         10368     \n",
            "                                                                 \n",
            " batch_normalization_287 (Ba  (None, 1667, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_287 (MaxPooli  (None, 416, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_288 (Conv1D)         (None, 416, 128)          49280     \n",
            "                                                                 \n",
            " batch_normalization_288 (Ba  (None, 416, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_288 (MaxPooli  (None, 104, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_289 (Conv1D)         (None, 104, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_289 (Ba  (None, 104, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_289 (MaxPooli  (None, 26, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_290 (Conv1D)         (None, 26, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_290 (Ba  (None, 26, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_290 (MaxPooli  (None, 6, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_132 (Dense)           (None, 6, 16)             8208      \n",
            "                                                                 \n",
            " lambda_72 (Lambda)          (None, 16)                0         \n",
            "                                                                 \n",
            " dense_133 (Dense)           (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 564,308\n",
            "Trainable params: 562,260\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_73\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_291 (Conv1D)         (None, 1667, 128)         10368     \n",
            "                                                                 \n",
            " batch_normalization_291 (Ba  (None, 1667, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_291 (MaxPooli  (None, 416, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_292 (Conv1D)         (None, 416, 128)          49280     \n",
            "                                                                 \n",
            " batch_normalization_292 (Ba  (None, 416, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_292 (MaxPooli  (None, 104, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_293 (Conv1D)         (None, 104, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_293 (Ba  (None, 104, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_293 (MaxPooli  (None, 26, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_294 (Conv1D)         (None, 26, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_294 (Ba  (None, 26, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_294 (MaxPooli  (None, 6, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_134 (Dense)           (None, 6, 16)             8208      \n",
            "                                                                 \n",
            " lambda_73 (Lambda)          (None, 16)                0         \n",
            "                                                                 \n",
            " dense_135 (Dense)           (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 564,308\n",
            "Trainable params: 562,260\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_74\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_295 (Conv1D)         (None, 5000, 128)         12928     \n",
            "                                                                 \n",
            " batch_normalization_295 (Ba  (None, 5000, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_295 (MaxPooli  (None, 1250, 128)        0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_296 (Conv1D)         (None, 1250, 128)         49280     \n",
            "                                                                 \n",
            " batch_normalization_296 (Ba  (None, 1250, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_296 (MaxPooli  (None, 312, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_297 (Conv1D)         (None, 312, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_297 (Ba  (None, 312, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_297 (MaxPooli  (None, 78, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_298 (Conv1D)         (None, 78, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_298 (Ba  (None, 78, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_298 (MaxPooli  (None, 19, 512)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_136 (Dense)           (None, 19, 10)            5130      \n",
            "                                                                 \n",
            " lambda_74 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_137 (Dense)           (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 563,766\n",
            "Trainable params: 561,718\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 4ms/step\n",
            "Model: \"sequential_75\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_299 (Conv1D)         (None, 5000, 128)         12928     \n",
            "                                                                 \n",
            " batch_normalization_299 (Ba  (None, 5000, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_299 (MaxPooli  (None, 1250, 128)        0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_300 (Conv1D)         (None, 1250, 128)         49280     \n",
            "                                                                 \n",
            " batch_normalization_300 (Ba  (None, 1250, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_300 (MaxPooli  (None, 312, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_301 (Conv1D)         (None, 312, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_301 (Ba  (None, 312, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_301 (MaxPooli  (None, 78, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_302 (Conv1D)         (None, 78, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_302 (Ba  (None, 78, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_302 (MaxPooli  (None, 19, 512)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_138 (Dense)           (None, 19, 10)            5130      \n",
            "                                                                 \n",
            " lambda_75 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_139 (Dense)           (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 563,766\n",
            "Trainable params: 561,718\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 4ms/step\n",
            "Model: \"sequential_76\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_303 (Conv1D)         (None, 5000, 128)         12928     \n",
            "                                                                 \n",
            " batch_normalization_303 (Ba  (None, 5000, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_303 (MaxPooli  (None, 1250, 128)        0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_304 (Conv1D)         (None, 1250, 128)         49280     \n",
            "                                                                 \n",
            " batch_normalization_304 (Ba  (None, 1250, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_304 (MaxPooli  (None, 312, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_305 (Conv1D)         (None, 312, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_305 (Ba  (None, 312, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_305 (MaxPooli  (None, 78, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_306 (Conv1D)         (None, 78, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_306 (Ba  (None, 78, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_306 (MaxPooli  (None, 19, 512)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_140 (Dense)           (None, 19, 10)            5130      \n",
            "                                                                 \n",
            " lambda_76 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_141 (Dense)           (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 563,766\n",
            "Trainable params: 561,718\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_77\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_307 (Conv1D)         (None, 2500, 64)          3904      \n",
            "                                                                 \n",
            " batch_normalization_307 (Ba  (None, 2500, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_307 (MaxPooli  (None, 625, 64)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_308 (Conv1D)         (None, 625, 128)          24704     \n",
            "                                                                 \n",
            " batch_normalization_308 (Ba  (None, 625, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_308 (MaxPooli  (None, 156, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_309 (Conv1D)         (None, 156, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_309 (Ba  (None, 156, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_309 (MaxPooli  (None, 39, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_310 (Conv1D)         (None, 39, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_310 (Ba  (None, 39, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_310 (MaxPooli  (None, 9, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_142 (Dense)           (None, 9, 20)             10260     \n",
            "                                                                 \n",
            " lambda_77 (Lambda)          (None, 20)                0         \n",
            "                                                                 \n",
            " dense_143 (Dense)           (None, 4)                 84        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 535,080\n",
            "Trainable params: 533,160\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_78\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_311 (Conv1D)         (None, 2500, 64)          3904      \n",
            "                                                                 \n",
            " batch_normalization_311 (Ba  (None, 2500, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_311 (MaxPooli  (None, 625, 64)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_312 (Conv1D)         (None, 625, 128)          24704     \n",
            "                                                                 \n",
            " batch_normalization_312 (Ba  (None, 625, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_312 (MaxPooli  (None, 156, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_313 (Conv1D)         (None, 156, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_313 (Ba  (None, 156, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_313 (MaxPooli  (None, 39, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_314 (Conv1D)         (None, 39, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_314 (Ba  (None, 39, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_314 (MaxPooli  (None, 9, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_144 (Dense)           (None, 9, 20)             10260     \n",
            "                                                                 \n",
            " lambda_78 (Lambda)          (None, 20)                0         \n",
            "                                                                 \n",
            " dense_145 (Dense)           (None, 4)                 84        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 535,080\n",
            "Trainable params: 533,160\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_79\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_315 (Conv1D)         (None, 2500, 64)          3904      \n",
            "                                                                 \n",
            " batch_normalization_315 (Ba  (None, 2500, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_315 (MaxPooli  (None, 625, 64)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_316 (Conv1D)         (None, 625, 128)          24704     \n",
            "                                                                 \n",
            " batch_normalization_316 (Ba  (None, 625, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_316 (MaxPooli  (None, 156, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_317 (Conv1D)         (None, 156, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_317 (Ba  (None, 156, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_317 (MaxPooli  (None, 39, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_318 (Conv1D)         (None, 39, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_318 (Ba  (None, 39, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_318 (MaxPooli  (None, 9, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_146 (Dense)           (None, 9, 20)             10260     \n",
            "                                                                 \n",
            " lambda_79 (Lambda)          (None, 20)                0         \n",
            "                                                                 \n",
            " dense_147 (Dense)           (None, 4)                 84        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 535,080\n",
            "Trainable params: 533,160\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_80\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_319 (Conv1D)         (None, 2500, 64)          5184      \n",
            "                                                                 \n",
            " batch_normalization_319 (Ba  (None, 2500, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_319 (MaxPooli  (None, 625, 64)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_320 (Conv1D)         (None, 625, 128)          24704     \n",
            "                                                                 \n",
            " batch_normalization_320 (Ba  (None, 625, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_320 (MaxPooli  (None, 156, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_321 (Conv1D)         (None, 156, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_321 (Ba  (None, 156, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_321 (MaxPooli  (None, 39, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_322 (Conv1D)         (None, 39, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_322 (Ba  (None, 39, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_322 (MaxPooli  (None, 9, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_148 (Dense)           (None, 9, 16)             8208      \n",
            "                                                                 \n",
            " lambda_80 (Lambda)          (None, 16)                0         \n",
            "                                                                 \n",
            " dense_149 (Dense)           (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 534,292\n",
            "Trainable params: 532,372\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_81\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_323 (Conv1D)         (None, 2500, 64)          5184      \n",
            "                                                                 \n",
            " batch_normalization_323 (Ba  (None, 2500, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_323 (MaxPooli  (None, 625, 64)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_324 (Conv1D)         (None, 625, 128)          24704     \n",
            "                                                                 \n",
            " batch_normalization_324 (Ba  (None, 625, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_324 (MaxPooli  (None, 156, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_325 (Conv1D)         (None, 156, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_325 (Ba  (None, 156, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_325 (MaxPooli  (None, 39, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_326 (Conv1D)         (None, 39, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_326 (Ba  (None, 39, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_326 (MaxPooli  (None, 9, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_150 (Dense)           (None, 9, 16)             8208      \n",
            "                                                                 \n",
            " lambda_81 (Lambda)          (None, 16)                0         \n",
            "                                                                 \n",
            " dense_151 (Dense)           (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 534,292\n",
            "Trainable params: 532,372\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_82\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_327 (Conv1D)         (None, 2500, 64)          5184      \n",
            "                                                                 \n",
            " batch_normalization_327 (Ba  (None, 2500, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_327 (MaxPooli  (None, 625, 64)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_328 (Conv1D)         (None, 625, 128)          24704     \n",
            "                                                                 \n",
            " batch_normalization_328 (Ba  (None, 625, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_328 (MaxPooli  (None, 156, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_329 (Conv1D)         (None, 156, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_329 (Ba  (None, 156, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_329 (MaxPooli  (None, 39, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_330 (Conv1D)         (None, 39, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_330 (Ba  (None, 39, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_330 (MaxPooli  (None, 9, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_152 (Dense)           (None, 9, 16)             8208      \n",
            "                                                                 \n",
            " lambda_82 (Lambda)          (None, 16)                0         \n",
            "                                                                 \n",
            " dense_153 (Dense)           (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 534,292\n",
            "Trainable params: 532,372\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_83\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_331 (Conv1D)         (None, 5000, 64)          6464      \n",
            "                                                                 \n",
            " batch_normalization_331 (Ba  (None, 5000, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_331 (MaxPooli  (None, 1250, 64)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_332 (Conv1D)         (None, 1250, 128)         24704     \n",
            "                                                                 \n",
            " batch_normalization_332 (Ba  (None, 1250, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_332 (MaxPooli  (None, 312, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_333 (Conv1D)         (None, 312, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_333 (Ba  (None, 312, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_333 (MaxPooli  (None, 78, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_334 (Conv1D)         (None, 78, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_334 (Ba  (None, 78, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_334 (MaxPooli  (None, 19, 512)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_154 (Dense)           (None, 19, 16)            8208      \n",
            "                                                                 \n",
            " lambda_83 (Lambda)          (None, 16)                0         \n",
            "                                                                 \n",
            " dense_155 (Dense)           (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 535,572\n",
            "Trainable params: 533,652\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_84\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_335 (Conv1D)         (None, 5000, 64)          6464      \n",
            "                                                                 \n",
            " batch_normalization_335 (Ba  (None, 5000, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_335 (MaxPooli  (None, 1250, 64)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_336 (Conv1D)         (None, 1250, 128)         24704     \n",
            "                                                                 \n",
            " batch_normalization_336 (Ba  (None, 1250, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_336 (MaxPooli  (None, 312, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_337 (Conv1D)         (None, 312, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_337 (Ba  (None, 312, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_337 (MaxPooli  (None, 78, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_338 (Conv1D)         (None, 78, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_338 (Ba  (None, 78, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_338 (MaxPooli  (None, 19, 512)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_156 (Dense)           (None, 19, 16)            8208      \n",
            "                                                                 \n",
            " lambda_84 (Lambda)          (None, 16)                0         \n",
            "                                                                 \n",
            " dense_157 (Dense)           (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 535,572\n",
            "Trainable params: 533,652\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_85\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_339 (Conv1D)         (None, 5000, 64)          6464      \n",
            "                                                                 \n",
            " batch_normalization_339 (Ba  (None, 5000, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_339 (MaxPooli  (None, 1250, 64)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_340 (Conv1D)         (None, 1250, 128)         24704     \n",
            "                                                                 \n",
            " batch_normalization_340 (Ba  (None, 1250, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_340 (MaxPooli  (None, 312, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_341 (Conv1D)         (None, 312, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_341 (Ba  (None, 312, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_341 (MaxPooli  (None, 78, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_342 (Conv1D)         (None, 78, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_342 (Ba  (None, 78, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_342 (MaxPooli  (None, 19, 512)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_158 (Dense)           (None, 19, 16)            8208      \n",
            "                                                                 \n",
            " lambda_85 (Lambda)          (None, 16)                0         \n",
            "                                                                 \n",
            " dense_159 (Dense)           (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 535,572\n",
            "Trainable params: 533,652\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_86\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_343 (Conv1D)         (None, 5000, 64)          5184      \n",
            "                                                                 \n",
            " batch_normalization_343 (Ba  (None, 5000, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_343 (MaxPooli  (None, 1250, 64)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_344 (Conv1D)         (None, 1250, 128)         24704     \n",
            "                                                                 \n",
            " batch_normalization_344 (Ba  (None, 1250, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_344 (MaxPooli  (None, 312, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_345 (Conv1D)         (None, 312, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_345 (Ba  (None, 312, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_345 (MaxPooli  (None, 78, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_346 (Conv1D)         (None, 78, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_346 (Ba  (None, 78, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_346 (MaxPooli  (None, 19, 512)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_160 (Dense)           (None, 19, 10)            5130      \n",
            "                                                                 \n",
            " lambda_86 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_161 (Dense)           (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 531,190\n",
            "Trainable params: 529,270\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_87\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_347 (Conv1D)         (None, 5000, 64)          5184      \n",
            "                                                                 \n",
            " batch_normalization_347 (Ba  (None, 5000, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_347 (MaxPooli  (None, 1250, 64)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_348 (Conv1D)         (None, 1250, 128)         24704     \n",
            "                                                                 \n",
            " batch_normalization_348 (Ba  (None, 1250, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_348 (MaxPooli  (None, 312, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_349 (Conv1D)         (None, 312, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_349 (Ba  (None, 312, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_349 (MaxPooli  (None, 78, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_350 (Conv1D)         (None, 78, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_350 (Ba  (None, 78, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_350 (MaxPooli  (None, 19, 512)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_162 (Dense)           (None, 19, 10)            5130      \n",
            "                                                                 \n",
            " lambda_87 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_163 (Dense)           (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 531,190\n",
            "Trainable params: 529,270\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_88\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_351 (Conv1D)         (None, 5000, 64)          5184      \n",
            "                                                                 \n",
            " batch_normalization_351 (Ba  (None, 5000, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_351 (MaxPooli  (None, 1250, 64)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_352 (Conv1D)         (None, 1250, 128)         24704     \n",
            "                                                                 \n",
            " batch_normalization_352 (Ba  (None, 1250, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_352 (MaxPooli  (None, 312, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_353 (Conv1D)         (None, 312, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_353 (Ba  (None, 312, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_353 (MaxPooli  (None, 78, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_354 (Conv1D)         (None, 78, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_354 (Ba  (None, 78, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_354 (MaxPooli  (None, 19, 512)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_164 (Dense)           (None, 19, 10)            5130      \n",
            "                                                                 \n",
            " lambda_88 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_165 (Dense)           (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 531,190\n",
            "Trainable params: 529,270\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_89\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_355 (Conv1D)         (None, 2500, 254)         15494     \n",
            "                                                                 \n",
            " batch_normalization_355 (Ba  (None, 2500, 254)        1016      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_355 (MaxPooli  (None, 625, 254)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_356 (Conv1D)         (None, 625, 128)          97664     \n",
            "                                                                 \n",
            " batch_normalization_356 (Ba  (None, 625, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_356 (MaxPooli  (None, 156, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_357 (Conv1D)         (None, 156, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_357 (Ba  (None, 156, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_357 (MaxPooli  (None, 39, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_358 (Conv1D)         (None, 39, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_358 (Ba  (None, 39, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_358 (MaxPooli  (None, 9, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_166 (Dense)           (None, 9, 10)             5130      \n",
            "                                                                 \n",
            " lambda_89 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_167 (Dense)           (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 615,220\n",
            "Trainable params: 612,920\n",
            "Non-trainable params: 2,300\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_90\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_359 (Conv1D)         (None, 2500, 254)         15494     \n",
            "                                                                 \n",
            " batch_normalization_359 (Ba  (None, 2500, 254)        1016      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_359 (MaxPooli  (None, 625, 254)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_360 (Conv1D)         (None, 625, 128)          97664     \n",
            "                                                                 \n",
            " batch_normalization_360 (Ba  (None, 625, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_360 (MaxPooli  (None, 156, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_361 (Conv1D)         (None, 156, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_361 (Ba  (None, 156, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_361 (MaxPooli  (None, 39, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_362 (Conv1D)         (None, 39, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_362 (Ba  (None, 39, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_362 (MaxPooli  (None, 9, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_168 (Dense)           (None, 9, 10)             5130      \n",
            "                                                                 \n",
            " lambda_90 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_169 (Dense)           (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 615,220\n",
            "Trainable params: 612,920\n",
            "Non-trainable params: 2,300\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_91\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_363 (Conv1D)         (None, 2500, 254)         15494     \n",
            "                                                                 \n",
            " batch_normalization_363 (Ba  (None, 2500, 254)        1016      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_363 (MaxPooli  (None, 625, 254)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_364 (Conv1D)         (None, 625, 128)          97664     \n",
            "                                                                 \n",
            " batch_normalization_364 (Ba  (None, 625, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_364 (MaxPooli  (None, 156, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_365 (Conv1D)         (None, 156, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_365 (Ba  (None, 156, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_365 (MaxPooli  (None, 39, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_366 (Conv1D)         (None, 39, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_366 (Ba  (None, 39, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_366 (MaxPooli  (None, 9, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_170 (Dense)           (None, 9, 10)             5130      \n",
            "                                                                 \n",
            " lambda_91 (Lambda)          (None, 10)                0         \n",
            "                                                                 \n",
            " dense_171 (Dense)           (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 615,220\n",
            "Trainable params: 612,920\n",
            "Non-trainable params: 2,300\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_92\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_367 (Conv1D)         (None, 5000, 128)         12928     \n",
            "                                                                 \n",
            " batch_normalization_367 (Ba  (None, 5000, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_367 (MaxPooli  (None, 1250, 128)        0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_368 (Conv1D)         (None, 1250, 128)         49280     \n",
            "                                                                 \n",
            " batch_normalization_368 (Ba  (None, 1250, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_368 (MaxPooli  (None, 312, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_369 (Conv1D)         (None, 312, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_369 (Ba  (None, 312, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_369 (MaxPooli  (None, 78, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_370 (Conv1D)         (None, 78, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_370 (Ba  (None, 78, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_370 (MaxPooli  (None, 19, 512)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_172 (Dense)           (None, 19, 20)            10260     \n",
            "                                                                 \n",
            " lambda_92 (Lambda)          (None, 20)                0         \n",
            "                                                                 \n",
            " dense_173 (Dense)           (None, 4)                 84        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 568,936\n",
            "Trainable params: 566,888\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 3ms/step\n",
            "Model: \"sequential_93\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_371 (Conv1D)         (None, 5000, 128)         12928     \n",
            "                                                                 \n",
            " batch_normalization_371 (Ba  (None, 5000, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_371 (MaxPooli  (None, 1250, 128)        0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_372 (Conv1D)         (None, 1250, 128)         49280     \n",
            "                                                                 \n",
            " batch_normalization_372 (Ba  (None, 1250, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_372 (MaxPooli  (None, 312, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_373 (Conv1D)         (None, 312, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_373 (Ba  (None, 312, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_373 (MaxPooli  (None, 78, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_374 (Conv1D)         (None, 78, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_374 (Ba  (None, 78, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_374 (MaxPooli  (None, 19, 512)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_174 (Dense)           (None, 19, 20)            10260     \n",
            "                                                                 \n",
            " lambda_93 (Lambda)          (None, 20)                0         \n",
            "                                                                 \n",
            " dense_175 (Dense)           (None, 4)                 84        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 568,936\n",
            "Trainable params: 566,888\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 4ms/step\n",
            "Model: \"sequential_94\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_375 (Conv1D)         (None, 5000, 128)         12928     \n",
            "                                                                 \n",
            " batch_normalization_375 (Ba  (None, 5000, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_375 (MaxPooli  (None, 1250, 128)        0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_376 (Conv1D)         (None, 1250, 128)         49280     \n",
            "                                                                 \n",
            " batch_normalization_376 (Ba  (None, 1250, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_376 (MaxPooli  (None, 312, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_377 (Conv1D)         (None, 312, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_377 (Ba  (None, 312, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_377 (MaxPooli  (None, 78, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_378 (Conv1D)         (None, 78, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_378 (Ba  (None, 78, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_378 (MaxPooli  (None, 19, 512)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_176 (Dense)           (None, 19, 20)            10260     \n",
            "                                                                 \n",
            " lambda_94 (Lambda)          (None, 20)                0         \n",
            "                                                                 \n",
            " dense_177 (Dense)           (None, 4)                 84        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 568,936\n",
            "Trainable params: 566,888\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n",
            "58/58 [==============================] - 0s 4ms/step\n",
            "Model: \"sequential_95\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_379 (Conv1D)         (None, 2500, 64)          5184      \n",
            "                                                                 \n",
            " batch_normalization_379 (Ba  (None, 2500, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_379 (MaxPooli  (None, 625, 64)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_380 (Conv1D)         (None, 625, 128)          24704     \n",
            "                                                                 \n",
            " batch_normalization_380 (Ba  (None, 625, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_380 (MaxPooli  (None, 156, 128)         0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_381 (Conv1D)         (None, 156, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_381 (Ba  (None, 156, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_381 (MaxPooli  (None, 39, 256)          0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_382 (Conv1D)         (None, 39, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_382 (Ba  (None, 39, 512)          2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling1d_382 (MaxPooli  (None, 9, 512)           0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " dense_178 (Dense)           (None, 9, 16)             8208      \n",
            "                                                                 \n",
            " lambda_95 (Lambda)          (None, 16)                0         \n",
            "                                                                 \n",
            " dense_179 (Dense)           (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 534,292\n",
            "Trainable params: 532,372\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3,\n",
              "                   estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7dafec185960>,\n",
              "                   n_iter=24,\n",
              "                   param_distributions={'dense_units': [10, 16, 20, 24],\n",
              "                                        'f1': [64, 128, 254],\n",
              "                                        'kernel_size': [60, 80, 100],\n",
              "                                        'l': [0.0001, 8e-05, 0.00012],\n",
              "                                        'strides': [1, 2, 3, 4]},\n",
              "                   scoring='accuracy')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
              "                   estimator=&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x7dafec185960&gt;,\n",
              "                   n_iter=24,\n",
              "                   param_distributions={&#x27;dense_units&#x27;: [10, 16, 20, 24],\n",
              "                                        &#x27;f1&#x27;: [64, 128, 254],\n",
              "                                        &#x27;kernel_size&#x27;: [60, 80, 100],\n",
              "                                        &#x27;l&#x27;: [0.0001, 8e-05, 0.00012],\n",
              "                                        &#x27;strides&#x27;: [1, 2, 3, 4]},\n",
              "                   scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
              "                   estimator=&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x7dafec185960&gt;,\n",
              "                   n_iter=24,\n",
              "                   param_distributions={&#x27;dense_units&#x27;: [10, 16, 20, 24],\n",
              "                                        &#x27;f1&#x27;: [64, 128, 254],\n",
              "                                        &#x27;kernel_size&#x27;: [60, 80, 100],\n",
              "                                        &#x27;l&#x27;: [0.0001, 8e-05, 0.00012],\n",
              "                                        &#x27;strides&#x27;: [1, 2, 3, 4]},\n",
              "                   scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x7dafec185960&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x7dafec185960&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Randomized Search\n",
        "print(\"Best Parameters: \", grid_search.best_params_)\n",
        "print(\"Best Accuracy: {:.2f}%\".format(grid_search.best_score_ * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8EOO5ifFURr",
        "outputId": "7ed83c1b-d3ed-48fd-c0fe-663e7b561c3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters:  {'strides': 2, 'l': 0.0001, 'kernel_size': 80, 'f1': 64, 'dense_units': 16}\n",
            "Best Accuracy: 85.26%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m_raw = Sequential()\n",
        "m_raw.add(Conv1D(64,\n",
        "              input_shape=[5000, 1],\n",
        "              kernel_size=80,\n",
        "              strides=2,\n",
        "              padding='same',\n",
        "              kernel_initializer='glorot_uniform',\n",
        "              kernel_regularizer=regularizers.l2(l=0.0001),\n",
        "              activation='relu'))\n",
        "m_raw.add(BatchNormalization())\n",
        "m_raw.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "m_raw.add(Conv1D(128,\n",
        "              kernel_size=3,\n",
        "              strides=1,\n",
        "              padding='same',\n",
        "              kernel_initializer='glorot_uniform',\n",
        "              kernel_regularizer=regularizers.l2(l=0.0001),\n",
        "              activation='relu'))\n",
        "m_raw.add(BatchNormalization())\n",
        "m_raw.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "m_raw.add(Conv1D(256,\n",
        "              kernel_size=3,\n",
        "              strides=1,\n",
        "              padding='same',\n",
        "              kernel_initializer='glorot_uniform',\n",
        "              kernel_regularizer=regularizers.l2(l=0.0001),\n",
        "              activation='relu'))\n",
        "m_raw.add(BatchNormalization())\n",
        "m_raw.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "m_raw.add(Conv1D(512, #original 512\n",
        "              kernel_size=3,\n",
        "              strides=1,\n",
        "              padding='same',\n",
        "              kernel_initializer='glorot_uniform',\n",
        "              kernel_regularizer=regularizers.l2(l=0.0001),\n",
        "              activation='relu'))\n",
        "m_raw.add(BatchNormalization())\n",
        "m_raw.add(MaxPooling1D(pool_size=4, strides=None))\n",
        "m_raw.add(Dense(16, activation='relu')) #vlad added\n",
        "m_raw.add(Lambda(lambda x: K.mean(x, axis=1)))  # Same as GAP for 1D Conv Layer\n",
        "m_raw.add(Dense(4, activation='softmax'))\n",
        "m_raw.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "print(m_raw.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bF6vUF2WM_ci",
        "outputId": "c884e83a-927b-4995-d5b1-5c3ef7ae8a32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 2500, 64)          5184      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 2500, 64)         256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 625, 64)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 625, 128)          24704     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 625, 128)         512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 156, 128)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 156, 256)          98560     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 156, 256)         1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 39, 256)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 39, 512)           393728    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 39, 512)          2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPooling  (None, 9, 512)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dense (Dense)               (None, 9, 16)             8208      \n",
            "                                                                 \n",
            " lambda (Lambda)             (None, 16)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 534,292\n",
            "Trainable params: 532,372\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    }
  ]
}